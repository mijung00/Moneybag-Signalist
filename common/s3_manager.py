import boto3
import os
import time
import re
from datetime import datetime, timedelta
from botocore.exceptions import NoCredentialsError, ClientError

class S3Manager:
    def __init__(self, bucket_name="fincore-output-storage"):
        """
        AWS S3 ì—°ê²° ê´€ë¦¬ì (Moneybag & Signalist ê³µìš©)
        """
        self.bucket_name = bucket_name
        self.s3 = boto3.client('s3', region_name='ap-northeast-2')

    def upload_file(self, local_file_path, s3_file_path):
        """ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë“œ"""
        if not os.path.exists(local_file_path):
            print(f"âŒ [Fail] íŒŒì¼ ì—†ìŒ: {local_file_path}")
            return False
        try:
            s3_key = s3_file_path.replace("\\", "/") 
            print(f"â˜ï¸ [Upload] {local_file_path} -> {s3_key}")
            self.s3.upload_file(local_file_path, self.bucket_name, s3_key)
            return True
        except Exception as e:
            print(f"âŒ [Error] {e}")
            return False
        
    def get_text_content(self, s3_key):
        """
        [NEW] S3ì— ìˆëŠ” íŒŒì¼ì„ í…ìŠ¤íŠ¸(String)ë¡œ ì½ì–´ì˜µë‹ˆë‹¤. (ì›¹ ë·°ì–´ìš©)
        """
        try:
            s3_key = s3_key.replace("\\", "/")
            response = self.s3.get_object(Bucket=self.bucket_name, Key=s3_key)
            return response['Body'].read().decode('utf-8')
        except self.s3.exceptions.NoSuchKey:
            return None
        except Exception as e:
            print(f"âŒ [Read Error] {e}")
            return None

    def download_file(self, s3_file_path, local_file_path):
        """ë‹¨ì¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            s3_key = s3_file_path.replace("\\", "/")
            local_dir = os.path.dirname(local_file_path)
            if local_dir and not os.path.exists(local_dir):
                os.makedirs(local_dir)
            
            print(f"ğŸ“¥ [Download] {s3_key} -> {local_file_path}")
            self.s3.download_file(self.bucket_name, s3_key, local_file_path)
            return True
        except ClientError:
            return False
        except Exception as e:
            print(f"âŒ [Error] {e}")
            return False

    def get_latest_file_in_prefix(self, prefix):
        """
        [NEW] íŠ¹ì • ê²½ë¡œ(prefix)ì— ìˆëŠ” íŒŒì¼ ì¤‘ ê°€ì¥ ìµœì‹ (íŒŒì¼ëª… ì •ë ¬ ê¸°ì¤€) íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
        """
        try:
            paginator = self.s3.get_paginator('list_objects_v2')
            page_iterator = paginator.paginate(Bucket=self.bucket_name, Prefix=prefix)
            
            all_files = []
            for page in page_iterator:
                if "Contents" in page:
                    for obj in page["Contents"]:
                        key = obj["Key"]
                        if not key.endswith("/"):
                            all_files.append(key)
            
            if not all_files:
                return None
            
            # [ìˆ˜ì •] ë‹¨ìˆœ ë¬¸ìì—´ ì •ë ¬ì´ ì•„ë‹Œ, 'ë‚ ì§œ'ë¥¼ ì¶”ì¶œí•´ì„œ ì •ë ¬
            def _extract_date(fname):
                # YYYY-MM-DD íŒ¨í„´ ì°¾ê¸°
                match = re.search(r'(\d{4}-\d{2}-\d{2})', fname)
                if match:
                    return match.group(1)
                return "0000-00-00" # ë‚ ì§œ ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ

            # ë‚ ì§œ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ -> ê°™ì€ ë‚ ì§œë©´ íŒŒì¼ëª…(Morning/Night) ìˆœ
            sorted_files = sorted(all_files, key=lambda x: (_extract_date(x), x))
            return sorted_files[-1]
        except Exception as e:
            print(f"âŒ [S3 List Error] {e}")
            return None

    def get_latest_file_in_prefix(self, prefix):
        """
        [NEW] íŠ¹ì • ê²½ë¡œ(prefix)ì— ìˆëŠ” íŒŒì¼ ì¤‘ ê°€ì¥ ìµœì‹ (íŒŒì¼ëª… ì •ë ¬ ê¸°ì¤€) íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
        """
        try:
            paginator = self.s3.get_paginator('list_objects_v2')
            page_iterator = paginator.paginate(Bucket=self.bucket_name, Prefix=prefix)
            
            all_files = []
            for page in page_iterator:
                if "Contents" in page:
                    for obj in page["Contents"]:
                        key = obj["Key"]
                        if not key.endswith("/"):
                            all_files.append(key)
            
            return sorted(all_files)[-1] if all_files else None
        except Exception as e:
            print(f"âŒ [S3 List Error] {e}")
            return None

    def upload_directory(self, local_dir, s3_prefix, recent_days=2):
        """
        ğŸ“ [ìŠ¤ë§ˆíŠ¸ ë™ê¸°í™”] í•˜ìœ„ í´ë” í¬í•¨, ë‚ ì§œ ê¸°ì¤€ ì—…ë¡œë“œ
        :param recent_days: 0=ë‹¹ì¼(ìì • ì´í›„), N=ìµœê·¼ Nì¼, None=ì „ì²´
        """
        if not os.path.exists(local_dir):
            print(f"âš ï¸ [Skip] ë¡œì»¬ í´ë” ì—†ìŒ: {local_dir}")
            return

        print(f"\nğŸ“¦ [Sync Start] {local_dir} (í•˜ìœ„ í´ë” í¬í•¨) -> {s3_prefix}")
        
        # ê¸°ì¤€ ì‹œê°„ ì„¤ì •
        if recent_days is not None:
            if recent_days == 0:
                cutoff_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
                print(f"   ğŸ‘‰ ì˜µì…˜: [ë‹¹ì¼] {cutoff_time.strftime('%Y-%m-%d %H:%M:%S')} ì´í›„ íŒŒì¼ë§Œ ì—…ë¡œë“œ")
            else:
                cutoff_time = datetime.now() - timedelta(days=recent_days)
                print(f"   ğŸ‘‰ ì˜µì…˜: [ìµœê·¼ {recent_days}ì¼] {cutoff_time.strftime('%Y-%m-%d')} ì´í›„ íŒŒì¼ë§Œ ì—…ë¡œë“œ")
        else:
            cutoff_time = None
            print("   ğŸ‘‰ ì˜µì…˜: ëª¨ë“  íŒŒì¼ ì—…ë¡œë“œ")
        
        count = 0
        skip_count = 0
        
        # os.walkë¡œ ëª¨ë“  í•˜ìœ„ í´ë” ì¬ê·€ íƒìƒ‰
        for root, dirs, files in os.walk(local_dir):
            # ë¶ˆí•„ìš”í•œ ì‹œìŠ¤í…œ í´ë” ì œì™¸
            if 'venv' in root or '.git' in root or '__pycache__' in root:
                continue

            for filename in files:
                local_path = os.path.join(root, filename)
                
                # ë‚ ì§œ í•„í„°ë§
                if cutoff_time:
                    mtime = datetime.fromtimestamp(os.path.getmtime(local_path))
                    if mtime < cutoff_time:
                        skip_count += 1
                        continue 

                # S3 ê²½ë¡œ ê³„ì‚° (ìƒëŒ€ ê²½ë¡œ ìœ ì§€)
                relative_path = os.path.relpath(local_path, local_dir)
                s3_path = os.path.join(s3_prefix, relative_path).replace("\\", "/")
                
                if self.upload_file(local_path, s3_path):
                    count += 1
        
        print(f"âœ… [Sync Done] ì—…ë¡œë“œ: {count}ê°œ / ê±´ë„ˆëœ€(êµ¬í˜•): {skip_count}ê°œ")


# --- ğŸ‘‡ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ì—­ ---
if __name__ == "__main__":
    manager = S3Manager()
    
    # í…ŒìŠ¤íŠ¸í•  í´ë” ëª©ë¡ (í•˜ìœ„ í´ë”ê¹Œì§€ ì‹¹ ë‹¤ ë’¤ì§)
    target_folders = [
        "iceage/data",
        "iceage/out",
        "moneybag/data"
    ]
    
    print("\nğŸš€ [í…ŒìŠ¤íŠ¸ ì‹œì‘] ë‹¹ì¼(ì˜¤ëŠ˜ 0ì‹œ ì´í›„) ìƒì„±ëœ íŒŒì¼ë§Œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.\n")
    
    for folder in target_folders:
        # recent_days=0 : ì˜¤ëŠ˜ ë§Œë“  ê²ƒë§Œ!
        manager.upload_directory(folder, folder, recent_days=0)