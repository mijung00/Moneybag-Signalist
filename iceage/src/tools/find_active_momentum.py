# iceage/src/tools/find_active_momentum.py
import pandas as pd
import numpy as np
import glob
import os
import sys
from pathlib import Path
from datetime import datetime, timedelta

# ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

DATA_DIR = PROJECT_ROOT / "iceage" / "data"

def _normalize_code(x):
    try: return str(int(float(x))).zfill(6)
    except: return str(x).strip().zfill(6)

def run_active_momentum_test():
    print("ğŸ‰ [Signalist 6.0] 'ì ë£¡ ìŠ¹ì²œ(Active Momentum)' ì „ëµ í…ŒìŠ¤íŠ¸")
    print("   íƒ€ê²Ÿ: Large & Mid (ì¤‘ëŒ€í˜•ì£¼)")
    print("   ì¡°ê±´: 60ì¼ê°„ ê´´ë¦¬ìœ¨ 2Ïƒ+ ë°œìƒ ë¹ˆë„ 3íšŒ ì´ìƒ + ìš°ìƒí–¥ ì¶”ì„¸")
    
    # 1. íŒŒì¼ ë¡œë“œ (ì „ì²´ ê¸°ê°„)
    # ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•´ ì „ì²´ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•´ì„œ ì¢…ëª©ë³„ë¡œ ì •ë ¬í•´ì•¼ í•©ë‹ˆë‹¤.
    files = sorted(glob.glob(str(DATA_DIR / "processed" / "volume_anomaly_v2_*.csv")))
    
    if not files:
        print("âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"â³ ëŒ€ê·œëª¨ ë°ì´í„° ë¡œë”© ë° ë³‘í•© ì¤‘... ({len(files)}ì¼ì¹˜)")
    
    data_frames = []
    for f in files:
        try:
            df = pd.read_csv(f)
            # ë‚ ì§œ ì¶”ì¶œ
            date_str = os.path.basename(f).replace("volume_anomaly_v2_", "").replace(".csv", "")
            df['date'] = pd.to_datetime(date_str)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ë©”ëª¨ë¦¬ ì ˆì•½)
            cols = ['date', 'code', 'name', 'close', 'open', 'vol_sigma', 'tv_z', 'size_bucket']
            # íŒŒì¼ ë²„ì „ì— ë”°ë¼ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ ì²˜ë¦¬
            if 'tv_z' not in df.columns: 
                if 'vol_sigma' in df.columns: df['tv_z'] = df['vol_sigma']
                else: continue
            
            if 'code' in df.columns:
                 df['code'] = df['code'].apply(_normalize_code)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            available_cols = [c for c in cols if c in df.columns]
            data_frames.append(df[available_cols])
            
        except Exception:
            continue
            
    if not data_frames:
        print("âŒ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì „ì²´ í†µí•©
    full_df = pd.concat(data_frames)
    full_df = full_df.sort_values(['code', 'date']).reset_index(drop=True)
    
    print(f"âœ… í†µí•© ì™„ë£Œ: {len(full_df)}í–‰. ì§€í‘œ ê³„ì‚° ì‹œì‘...")

    # 2. ë¡¤ë§ ì§€í‘œ ê³„ì‚° (ì¢…ëª©ë³„)
    # (1) Energy: ìµœê·¼ 60ì¼ê°„ sigma > 2.0 ì¸ ë‚ ì˜ íšŸìˆ˜
    # (2) Momentum: 60ì¼ ì „ ëŒ€ë¹„ ìˆ˜ìµë¥ 
    
    full_df['is_spike'] = (full_df['tv_z'] >= 2.0).astype(int)
    
    # GroupBy Rollingì€ ëŠë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, transform ì‚¬ìš©í•˜ê±°ë‚˜ loop ìµœì†Œí™”
    # ì—¬ê¸°ì„œëŠ” ì§ê´€ì ì¸ group apply ì‚¬ìš© (ì†ë„ ê°œì„  í•„ìš”ì‹œ ë³€ê²½ ê°€ëŠ¥)
    grouped = full_df.groupby('code')
    
    # 60ì¼ê°„ ìŠ¤íŒŒì´í¬ íšŸìˆ˜ í•©ê³„
    full_df['spike_count_60d'] = grouped['is_spike'].transform(lambda x: x.rolling(60, min_periods=30).sum())
    
    # 60ì¼ ì „ ê°€ê²© (Shift)
    full_df['price_60d_ago'] = grouped['close'].transform(lambda x: x.shift(60))
    
    # 5ì¼ í›„ ê°€ê²© (ìˆ˜ìµë¥  ê²€ì¦ìš©)
    full_df['close_next_5d'] = grouped['close'].transform(lambda x: x.shift(-5))
    
    # 3. ì „ëµ í•„í„°ë§
    # ì¡°ê±´ A: ëŒ€í˜•ì£¼/ì¤‘í˜•ì£¼ ë§Œ (ì†Œí˜•ì£¼ ì œì™¸)
    mask_size = full_df['size_bucket'].isin(['large', 'mid'])
    
    # ì¡°ê±´ B: ì—ë„ˆì§€ (60ì¼ ë‚´ 2ë°°ìˆ˜ í­ë°œì´ 3ë²ˆ ì´ìƒ ìˆì—ˆë˜ ë†ˆ = ë¼ ìˆëŠ” ë†ˆ)
    mask_energy = full_df['spike_count_60d'] >= 3
    
    # ì¡°ê±´ C: ì¶”ì„¸ (60ì¼ ì „ë³´ë‹¤ í˜„ì¬ê°€ê°€ ë†’ì•„ì•¼ í•¨ = ìš°ìƒí–¥)
    mask_trend = full_df['close'] > full_df['price_60d_ago']
    
    # ì¡°ê±´ D: ì˜¤ëŠ˜ ë§¤ìˆ˜ ì‹ í˜¸ (ì–‘ë´‰ + ê±°ë˜ëŸ‰ ì‚´ì§ ì¦ê°€)
    # ë„ˆë¬´ í„°ì§€ë©´(10ë°°) ê³ ì ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì ë‹¹íˆ(1.0 ~ 5.0)
    mask_trigger_vol = (full_df['tv_z'] >= 1.0) & (full_df['tv_z'] <= 5.0)
    mask_trigger_candle = full_df['close'] > full_df['open'] # ì–‘ë´‰
    
    # ìµœì¢… ì‹œê·¸ë„
    signals = full_df[mask_size & mask_energy & mask_trend & mask_trigger_vol & mask_trigger_candle].copy()
    
    # 4. ì„±ê³¼ ë¶„ì„
    if signals.empty:
        print("âŒ ì¡°ê±´ì— ë§ëŠ” ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìˆ˜ìµë¥  ê³„ì‚° (D+5)
    signals['ret_5d'] = (signals['close_next_5d'] - signals['close']) / signals['close'] * 100
    signals.dropna(subset=['ret_5d'], inplace=True) # ë¯¸ë˜ ë°ì´í„° ì—†ëŠ” ìµœê·¼ì¼ ì œì™¸
    
    signals['win'] = (signals['ret_5d'] > 0).astype(int)

    print("\n" + "="*60)
    print(f"ğŸ§ª [Signalist 6.0] ì¤‘/ëŒ€í˜•ì£¼ 'ë§¥ë°• ë§¤ë§¤' ê²°ê³¼ (ì´ {len(signals)}ê±´)")
    print("="*60)
    
    print(f"\nğŸ“Œ ì „ì²´ ì„±ê³¼ (D+5ì¼)")
    print(f"   - ìŠ¹ë¥ : {signals['win'].mean()*100:.1f}%")
    print(f"   - í‰ê·  ìˆ˜ìµ: {signals['ret_5d'].mean():.2f}%")
    
    print(f"\nâš–ï¸ ì²´ê¸‰ë³„ ì„±ê³¼")
    print("-" * 50)
    summary = signals.groupby('size_bucket').agg(
        count=('date', 'count'),
        win_rate=('win', lambda x: x.mean() * 100),
        avg_return=('ret_5d', 'mean')
    ).sort_values('avg_return', ascending=False)
    print(summary.round(2))
    
    print(f"\nğŸ† ë² ìŠ¤íŠ¸ ì¼€ì´ìŠ¤")
    print(signals.sort_values('ret_5d', ascending=False).head(5)[['date', 'name', 'size_bucket', 'ret_5d']])

if __name__ == "__main__":
    run_active_momentum_test()