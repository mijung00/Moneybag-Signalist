# iceage/src/tools/analyze_winning_factors.py
import pandas as pd
import numpy as np
import glob
import os
import sys
from pathlib import Path

# ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

DATA_DIR = PROJECT_ROOT / "iceage" / "data"

def _normalize_code(x):
    try: return str(int(float(x))).zfill(6)
    except: return str(x).strip().zfill(6)

def run_analysis():
    print("ğŸ•µï¸ [Reverse Engineering] ëŒ€í˜•ì£¼ ìŠ¹ë¦¬ íŒ¨í„´ ë¶„ì„ ì‹œì‘")
    print("   ëª©í‘œ: D+20ì¼ ìˆ˜ìµë¥  10% ì´ìƒ ê¸°ë¡í•œ 'ëŒ€í˜•ì£¼'ë“¤ì˜ ê³µí†µì  ì°¾ê¸°")
    
    files = sorted(glob.glob(str(DATA_DIR / "processed" / "volume_anomaly_v2_*.csv")))
    if not files:
        print("âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"â³ ë°ì´í„° ë¡œë”© ì¤‘... ({len(files)}ì¼ì¹˜)")
    
    dfs = []
    for f in files:
        try:
            df = pd.read_csv(f)
            date_str = os.path.basename(f).replace("volume_anomaly_v2_", "").replace(".csv", "")
            df['date'] = pd.to_datetime(date_str)
            
            # ì»¬ëŸ¼ í†µì¼
            if 'tv_z' not in df.columns and 'vol_sigma' in df.columns:
                df['tv_z'] = df['vol_sigma']
            
            if 'code' in df.columns:
                 df['code'] = df['code'].apply(_normalize_code)
            
            if 'change_rate' in df.columns:
                df['chg'] = pd.to_numeric(df['change_rate'], errors='coerce')
            
            # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
            required = {'close', 'open', 'high', 'low', 'tv_z', 'size_bucket', 'chg'}
            if not required.issubset(df.columns):
                continue
                
            dfs.append(df[['date', 'code', 'name', 'close', 'open', 'high', 'low', 'chg', 'tv_z', 'size_bucket']])
        except:
            continue
            
    if not dfs: return

    full_df = pd.concat(dfs).sort_values(['code', 'date']).reset_index(drop=True)
    
    # ---------------------------------------------------------
    # 1. ì§€í‘œ ê³„ì‚° (ìš°ë¦¬ê°€ ì˜ì‹¬í•˜ëŠ” ë²”ì¸ë“¤)
    # ---------------------------------------------------------
    print("âœ… ì§€í‘œ ê³„ì‚° ì¤‘...")
    
    # (1) ê±°ë˜ëŸ‰ ê°•ë„
    full_df['is_spike'] = (full_df['tv_z'] >= 2.0).astype(int)
    
    grouped = full_df.groupby('code')
    
    # (2) ì—ë„ˆì§€ ëˆ„ì  (60ì¼ê°„ ìŠ¤íŒŒì´í¬ íšŸìˆ˜)
    full_df['spike_cnt'] = grouped['is_spike'].transform(lambda x: x.rolling(60, min_periods=30).sum())
    
    # (3) ì¶”ì„¸ ê´´ë¦¬ìœ¨ (í˜„ì¬ê°€ / 60ì¼ ì´í‰ì„ )
    full_df['ma60'] = grouped['close'].transform(lambda x: x.rolling(60, min_periods=40).mean())
    full_df['dist_ma60'] = (full_df['close'] - full_df['ma60']) / full_df['ma60'] * 100
    
    # (4) ìº”ë“¤ ëª¨ì–‘ (ìœ—ê¼¬ë¦¬ ë¹„ìœ¨)
    full_df['body'] = (full_df['close'] - full_df['open']).abs()
    full_df['upper_shadow'] = full_df['high'] - full_df[['close', 'open']].max(axis=1)
    full_df['shadow_ratio'] = full_df['upper_shadow'] / full_df['close'] * 100  # ì£¼ê°€ ëŒ€ë¹„ ìœ—ê¼¬ë¦¬ ê¸¸ì´ %
    
    # (5) ë¯¸ë˜ ìˆ˜ìµë¥  (Target)
    full_df['close_next_20d'] = grouped['close'].transform(lambda x: x.shift(-20))
    full_df['ret_20d'] = (full_df['close_next_20d'] - full_df['close']) / full_df['close'] * 100
    
    # ---------------------------------------------------------
    # 2. ìŠ¹ì vs íŒ¨ì ê·¸ë£¹ ë¶„ë¦¬ (Large Only)
    # ---------------------------------------------------------
    target_df = full_df[
        (full_df['size_bucket'] == 'large') & 
        (full_df['close_next_20d'].notnull())
    ].copy()
    
    # ìŠ¹ì: 20ì¼ ë’¤ 10% ì´ìƒ ìƒìŠ¹
    winners = target_df[target_df['ret_20d'] >= 10.0]
    
    # íŒ¨ì: 20ì¼ ë’¤ -5% ì´í•˜ í•˜ë½ (ì†ì‹¤ ê·¸ë£¹)
    losers = target_df[target_df['ret_20d'] <= -5.0]
    
    # ì¼ë°˜: ë‚˜ë¨¸ì§€
    others = target_df[(target_df['ret_20d'] > -5.0) & (target_df['ret_20d'] < 10.0)]

    print(f"\nğŸ“Š ë¶„ì„ ëŒ€ìƒ: ëŒ€í˜•ì£¼ ì´ {len(target_df):,}ê±´")
    print(f"   - ğŸ† ìŠ¹ì ê·¸ë£¹ (ìˆ˜ìµ >= 10%): {len(winners):,}ê±´")
    print(f"   - â˜ ï¸ íŒ¨ì ê·¸ë£¹ (ìˆ˜ìµ <= -5%): {len(losers):,}ê±´")
    
    # ---------------------------------------------------------
    # 3. í†µê³„ ë¹„êµ
    # ---------------------------------------------------------
    metrics = ['tv_z', 'spike_cnt', 'dist_ma60', 'chg', 'shadow_ratio']
    
    print("\nğŸ§ [ìŠ¹ì vs íŒ¨ì] í•µì‹¬ ì§€í‘œ í‰ê·  ë¹„êµ")
    print("="*60)
    print(f"{'ì§€í‘œ (Feature)':<20} | {'ğŸ† ìŠ¹ì í‰ê· ':<15} | {'â˜ ï¸ íŒ¨ì í‰ê· ':<15} | {'ì°¨ì´':<10}")
    print("-" * 60)
    
    for m in metrics:
        w_mean = winners[m].mean()
        l_mean = losers[m].mean()
        diff = w_mean - l_mean
        print(f"{m:<20} | {w_mean:10.2f}      | {l_mean:10.2f}      | {diff:+10.2f}")
    print("="*60)
    
    # ---------------------------------------------------------
    # 4. ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    # ---------------------------------------------------------
    print("\nğŸ’¡ [ìë™ ë¶„ì„ ì½”ë©˜íŠ¸]")
    
    # Spike Count ë¶„ì„
    if winners['spike_cnt'].mean() < losers['spike_cnt'].mean():
        print("ğŸ‘‰ ìŠ¤íŒŒì´í¬ íšŸìˆ˜: ìŠ¹ìê°€ ë” ì ìŠµë‹ˆë‹¤. ë„ˆë¬´ ì¦ì€ ê±°ë˜ëŸ‰ í­ë°œì€ 'ê³ ì ' ì§•í›„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("ğŸ‘‰ ìŠ¤íŒŒì´í¬ íšŸìˆ˜: ìŠ¹ìê°€ ë” ë§ìŠµë‹ˆë‹¤. ì—ë„ˆì§€ê°€ ì¶©ë¶„íˆ ì¶•ì ëœ ì¢…ëª©ì´ ê°‘ë‹ˆë‹¤.")
        
    # TV_Z ë¶„ì„
    if winners['tv_z'].mean() < 2.0:
        print("ğŸ‘‰ ë‹¹ì¼ ê±°ë˜ëŸ‰: ìŠ¹ìë“¤ì€ ë‹¹ì¼ ê±°ë˜ëŸ‰ì´ í­ë°œì (2.0 ì´ìƒ)ì´ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì€ê·¼í•œ ìƒìŠ¹ì´ ë” ë¬´ì„­ìŠµë‹ˆë‹¤.")
        
    # MA60 ì´ê²©ë„
    if winners['dist_ma60'].mean() < 5.0:
        print("ğŸ‘‰ ì´ê²©ë„: ìŠ¹ìë“¤ì€ 60ì¼ì„ ì— ê°€ê¹ê²Œ ë¶™ì–´ìˆì—ˆìŠµë‹ˆë‹¤. ë„ˆë¬´ ëœ¬ ì¢…ëª©ì€ ìœ„í—˜í•©ë‹ˆë‹¤.")
    else:
        print("ğŸ‘‰ ì´ê²©ë„: ìŠ¹ìë“¤ì€ ì´ë¯¸ ì¶”ì„¸ê°€ í„°ì ¸ì„œ ì´í‰ì„  ìœ„ì— ë– ìˆëŠ” ìƒíƒœì˜€ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_analysis()