# iceage/src/tools/find_hyper_active.py
import pandas as pd
import numpy as np
import glob
import os
import sys
from pathlib import Path
from datetime import datetime, timedelta

# ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

DATA_DIR = PROJECT_ROOT / "iceage" / "data"

def _normalize_code(x):
    try: return str(int(float(x))).zfill(6)
    except: return str(x).strip().zfill(6)

def run_hyper_active_test():
    print("ğŸ”¥ [Signalist 8.0] 'ê´‘ê¸° í¬ì°©(Hyper-Active)' ì „ëµ í…ŒìŠ¤íŠ¸")
    print("   ì»¨ì…‰: ì¶”ì„¸ ë¬´ì‹œ. ì˜¤ì§ 'ë¼(Energy)'ë§Œ ë³¸ë‹¤.")
    print("   ì¡°ê±´: 60ì¼ê°„ ê´´ë¦¬ìœ¨ 2Ïƒ+ ë°œìƒ ë¹ˆë„ 10íšŒ ì´ìƒ + ì˜¤ëŠ˜ ì–‘ë´‰")
    
    files = sorted(glob.glob(str(DATA_DIR / "processed" / "volume_anomaly_v2_*.csv")))
    if not files:
        print("âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"â³ ë°ì´í„° ë¡œë”© ë° ë³‘í•© ì¤‘... ({len(files)}ì¼ì¹˜)")
    
    data_frames = []
    for f in files:
        try:
            df = pd.read_csv(f)
            date_str = os.path.basename(f).replace("volume_anomaly_v2_", "").replace(".csv", "")
            df['date'] = pd.to_datetime(date_str)
            
            # ì»¬ëŸ¼ ë§¤í•‘
            if 'tv_z' not in df.columns: 
                if 'vol_sigma' in df.columns: df['tv_z'] = df['vol_sigma']
                else: continue
            
            if 'code' in df.columns:
                 df['code'] = df['code'].apply(_normalize_code)
            
            # ë“±ë½ë¥  í™•ì¸ (ì–‘ë´‰ ì²´í¬ìš©)
            if 'change_rate' not in df.columns: continue
            df['chg'] = pd.to_numeric(df['change_rate'], errors='coerce')

            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ (ë©”ëª¨ë¦¬ ìµœì í™”)
            cols = ['date', 'code', 'name', 'close', 'chg', 'tv_z', 'size_bucket']
            available_cols = [c for c in cols if c in df.columns]
            data_frames.append(df[available_cols])
            
        except Exception:
            continue

    if not data_frames:
        print("âŒ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    full_df = pd.concat(data_frames)
    full_df = full_df.sort_values(['code', 'date']).reset_index(drop=True)
    
    print(f"âœ… í†µí•© ì™„ë£Œ: {len(full_df)}í–‰. 'ë¼' ì¸¡ì • ì‹œì‘...")

    # 2. 'ë¼' ì§€í‘œ ê³„ì‚° (Rolling Spike Count)
    # 2.0 sigma ì´ìƒ í„°ì§„ ë‚ ì„ 1ë¡œ í‘œì‹œ
    full_df['is_spike'] = (full_df['tv_z'] >= 2.0).astype(int)
    
    grouped = full_df.groupby('code')
    
    # ìµœê·¼ 60ì¼ê°„ spike íšŸìˆ˜ í•©ê³„
    full_df['spike_count_60d'] = grouped['is_spike'].transform(lambda x: x.rolling(60, min_periods=30).sum())
    
    # 5ì¼ í›„ ê°€ê²© (ìˆ˜ìµë¥  í™•ì¸ìš©)
    full_df['close_next_5d'] = grouped['close'].transform(lambda x: x.shift(-5))
    
    # 3. í•„í„°ë§ (Hyper Active ì¡°ê±´)
    # A. ë¼: 60ì¼ê°„ 10íšŒ ì´ìƒ í­ë°œ (ì£¼êµ°ì˜ ëª…ë ¹ëŒ€ë¡œ 'í™• ìª¼ì„')
    mask_energy = full_df['spike_count_60d'] >= 10
    
    # B. íŠ¸ë¦¬ê±°: ì˜¤ëŠ˜ë„ í­ë°œ (2.0 ì´ìƒ) + ì–‘ë´‰ (0% ì´ˆê³¼)
    mask_trigger = (full_df['tv_z'] >= 2.0) & (full_df['chg'] > 0)
    
    signals = full_df[mask_energy & mask_trigger].copy()
    
    if signals.empty:
        print("âŒ ì¡°ê±´ì— ë§ëŠ” ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤. (ì¡°ê±´ì´ ë„ˆë¬´ ë¹¡ë¹¡í•  ìˆ˜ ìˆìŒ)")
        return

    # 4. ì„±ê³¼ ë¶„ì„
    signals['ret_5d'] = (signals['close_next_5d'] - signals['close']) / signals['close'] * 100
    signals.dropna(subset=['ret_5d'], inplace=True)
    
    signals['win'] = (signals['ret_5d'] > 0).astype(int)

    print("\n" + "="*60)
    print(f"ğŸ§ª [Signalist 8.0] 'ê´‘ê¸° í¬ì°©' ê²°ê³¼ (ì´ {len(signals)}ê±´)")
    print("   (ìµœê·¼ 60ì¼ ì¤‘ 10ì¼ ì´ìƒ ê±°ë˜ëŸ‰ í­ë°œí•œ ì¢…ëª©)")
    print("="*60)
    
    print(f"\nğŸ“Œ ì „ì²´ ì„±ê³¼ (D+5ì¼)")
    print(f"   - ìŠ¹ë¥ : {signals['win'].mean()*100:.1f}%")
    print(f"   - í‰ê·  ìˆ˜ìµ: {signals['ret_5d'].mean():.2f}%")
    
    print(f"\nâš–ï¸ ì²´ê¸‰ë³„ ì„±ê³¼")
    print("-" * 50)
    summary = signals.groupby('size_bucket').agg(
        count=('date', 'count'),
        win_rate=('win', lambda x: x.mean() * 100),
        avg_return=('ret_5d', 'mean')
    ).sort_values('avg_return', ascending=False)
    print(summary.round(2))

    # ì¶”ê°€ ë¶„ì„: ë¹ˆë„ê°€ ë†’ì„ìˆ˜ë¡ ìˆ˜ìµë¥ ì´ ì¢‹ì€ê°€? (10~15íšŒ vs 15íšŒ ì´ìƒ)
    signals['freq_group'] = pd.cut(signals['spike_count_60d'], bins=[10, 15, 20, 60], labels=['10-15íšŒ', '15-20íšŒ', '20íšŒ+'])
    print(f"\nğŸ”¥ í­ë°œ ë¹ˆë„ë³„ ì„±ê³¼ (ë§ì´ í„°ì§ˆìˆ˜ë¡ ì¢‹ì€ê°€?)")
    print(signals.groupby('freq_group', observed=True)[['win', 'ret_5d']].mean().round(2))
    
    print(f"\nğŸ† ë² ìŠ¤íŠ¸ ì¼€ì´ìŠ¤")
    print(signals.sort_values('ret_5d', ascending=False).head(5)[['date', 'name', 'spike_count_60d', 'ret_5d']])

if __name__ == "__main__":
    run_hyper_active_test()