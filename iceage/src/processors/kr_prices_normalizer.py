# iceage/src/processors/kr_prices_normalizer.py
# -*- coding: utf-8 -*-
from __future__ import annotations

from datetime import date, timedelta
from pathlib import Path
from typing import Dict

import numpy as np
import pandas as pd

from iceage.src.data_schemas import KR_PRICE_COLUMNS, validate_kr_price_columns


# ë„¤ì´ë²„ ì‹œì„¸_í€€íŠ¸ í¬ë§· ê¸°ì¤€ ì»¬ëŸ¼ ë§¤í•‘
# ì™¼ìª½: ìš°ë¦¬ í‘œì¤€ ì´ë¦„ / ì˜¤ë¥¸ìª½: raw csv ì»¬ëŸ¼ëª…
COLUMN_MAPPING: Dict[str, str] = {
    "name": "ì¢…ëª©ëª…",
    "close": "í˜„ì¬ê°€",
    "change_pct": "ë“±ë½ë¥ ",
    "volume": "ê±°ë˜ëŸ‰",
    "turnover": "ê±°ë˜ëŒ€ê¸ˆ",  # í•„ìš”ì‹œ ì°¸ê³ ìš© (í‘œì¤€ ìŠ¤í‚¤ë§ˆì—” ì•ˆ ì¨ë„ ë¨)
}


def _raw_path(ref_date: date) -> Path:
    # collectorê°€ ì €ì¥í•œ ê²½ë¡œì™€ ë™ì¼í•´ì•¼ í•¨
    return Path("iceage") / "data" / "raw" / f"kr_prices_{ref_date.isoformat()}.csv"


def _processed_path(ref_date: date) -> Path:
    return Path("iceage") / "data" / "processed" / f"kr_prices_{ref_date.isoformat()}.csv"


def _to_number(s: str) -> float:
    """
    '12,345', '+3.21%', '-1.50%' ê°™ì€ ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜.
    """
    if pd.isna(s):
        return 0.0
    if isinstance(s, (int, float)):
        return float(s)
    s = str(s).strip()
    s = s.replace(",", "")
    s = s.replace("%", "")
    # 'â–²', 'â–¼' ê°™ì€ ê¸°í˜¸ê°€ ì„ì—¬ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ìˆ«ì,ë¶€í˜¸,ì ë§Œ ë‚¨ê¸°ì
    filtered = []
    for ch in s:
        if ch.isdigit() or ch in "+-.":
            filtered.append(ch)
    if not filtered:
        return 0.0
    try:
        return float("".join(filtered))
    except ValueError:
        return 0.0


def normalize_kr_prices(ref_date: date) -> Path:
    """
    ë„¤ì´ë²„ raw CSV -> í‘œì¤€ ì»¬ëŸ¼ CSV ë¡œ ë³€í™˜.
    - ì¢…ëª©ëª…/í˜„ì¬ê°€/ë“±ë½ë¥ /ê±°ë˜ëŸ‰ë§Œ ìˆì–´ë„ ë™ì‘
    - change_pct/prev_close/avg_20d_volume ì±„ì›Œ ë„£ê¸°
    """
    raw_path = _raw_path(ref_date)
    if not raw_path.exists():
        raise FileNotFoundError(f"raw kr prices not found: {raw_path}")

    df_raw = pd.read_csv(raw_path)

    # 1) ì»¬ëŸ¼ ì´ë¦„ ë§¤í•‘
    rename_map = {}
    for std_col, raw_col in COLUMN_MAPPING.items():
        if raw_col in df_raw.columns:
            rename_map[raw_col] = std_col

    df = df_raw.rename(columns=rename_map)

    # 2) ìµœì†Œ í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬ (name/close/volume)
    if not validate_kr_price_columns(list(df.columns)):
        raise ValueError(
            f"normalized kr prices missing required columns. got: {df.columns.tolist()}"
        )

    # 3) ìˆ«ìí˜• ì»¬ëŸ¼ íŒŒì‹±
    if "close" in df.columns:
        df["close"] = df["close"].apply(_to_number)
    if "volume" in df.columns:
        df["volume"] = df["volume"].apply(_to_number)
    if "change_pct" in df.columns:
        df["change_pct"] = df["change_pct"].apply(_to_number)

    # ğŸ”¹ ê±°ë˜ëŒ€ê¸ˆ(turnover) ìˆ«ìí™”
    if "turnover" in df.columns:
        df["turnover"] = df["turnover"].apply(_to_number)
    else:
        # rawì— ê±°ë˜ëŒ€ê¸ˆì´ ë”°ë¡œ ì—†ìœ¼ë©´ close * volume ìœ¼ë¡œ ê·¼ì‚¬
        if "close" in df.columns and "volume" in df.columns:
            df["turnover"] = df["close"] * df["volume"]
        else:
            df["turnover"] = 0.0

    # ğŸ”¹ ê±°ë˜ëŒ€ê¸ˆ(turnover) ìˆ«ìí™”
    if "turnover" in df.columns:
        df["turnover"] = df["turnover"].apply(_to_number)
    else:
        if "close" in df.columns and "volume" in df.columns:
            df["turnover"] = df["close"] * df["volume"]
        else:
            df["turnover"] = 0.0

    # ğŸ”¹ ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ 1,000ê°œë§Œ ìœ ë‹ˆë²„ìŠ¤ë¡œ ì‚¬ìš©
    if df["turnover"].gt(0).any():
        df = df.sort_values("turnover", ascending=False)
        df = df.head(1000).copy()


    # 4) date ì±„ìš°ê¸°
    df["date"] = ref_date.isoformat()

    # 5) prev_close / avg_20d_volume ìƒì„±
    if "change_pct" in df.columns:
        # close = prev_close * (1 + pct/100)  â†’ prev_close = close / (1+pct/100)
        df["prev_close"] = df["close"] / (1.0 + df["change_pct"] / 100.0)
    else:
        df["change_pct"] = 0.0
        df["prev_close"] = df["close"]

        # avg_20d_volume ì€ ì§€ê¸ˆì€ ë°ì´í„° ì—†ìœ¼ë‹ˆ ì„ì‹œë¡œ volume ì‚¬ìš©
    df["avg_20d_volume"] = df["volume"]

    # ğŸ”¹ ì—¬ê¸°ì„œ ê³¼ê±° ë°ì´í„° ê¸°ë°˜ vol_sigma ê³„ì‚°í•´ì„œ ë¶™ì´ê¸°
    df["vol_sigma"] = compute_volume_sigma(ref_date, df)

    # 6) í‘œì¤€ ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬ (ìˆëŠ” ê²ƒë§Œ ì‚¬ìš©)
    cols = [c for c in KR_PRICE_COLUMNS if c in df.columns]

    # KR_PRICE_COLUMNSì— vol_sigmaê°€ ì—†ë”ë¼ë„, ìˆìœ¼ë©´ ë§¨ ë’¤ì— ì¶”ê°€
    extra_cols = [c for c in ["vol_sigma"] if c in df.columns and c not in cols]
    df = df[cols + extra_cols]

    processed_path = _processed_path(ref_date)
    processed_path.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(processed_path, index=False, encoding="utf-8-sig")

    return processed_path



def ensure_normalized(ref_date: date) -> Path:
    """
    processed íŒŒì¼ì´ ì—†ìœ¼ë©´ normalize ì‹¤í–‰ í›„ ê²½ë¡œ ë°˜í™˜.
    ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ê²½ë¡œë§Œ ë°˜í™˜.
    """
    processed_path = _processed_path(ref_date)
    if processed_path.exists():
        return processed_path
    return normalize_kr_prices(ref_date)

def _find_col(df: pd.DataFrame, candidates) -> str | None:
    for c in candidates:
        if c in df.columns:
            return c
    return None


def compute_volume_sigma(
    ref_date: date,
    df_today: pd.DataFrame,
    lookback_days: int = 60,
) -> pd.Series:
    """
    ref_date ê¸°ì¤€ ì˜¤ëŠ˜ ì‹œì„¸(df_today)ë¥¼ ì…ë ¥ë°›ì•„,
    ìµœê·¼ lookback_daysì¼ ë™ì•ˆì˜ ê±°ë˜ëŸ‰ íˆìŠ¤í† ë¦¬ë¡œë¶€í„°
    ì¢…ëª©ë³„ ê±°ë˜ëŸ‰ z-score(vol_sigma)ë¥¼ ê³„ì‚°í•œë‹¤.

    z = (log(volume_t) - mean(log(volume_{t-N..t-1}))) / std(...)
    """

    # ì˜¤ëŠ˜ ë°ì´í„°ì—ì„œ ì½”ë“œ/ê±°ë˜ëŸ‰ ì»¬ëŸ¼ ì°¾ê¸°
    code_today = _find_col(df_today, ["code", "ì¢…ëª©ì½”ë“œ", "ticker"])
    vol_today = _find_col(df_today, ["volume", "ê±°ë˜ëŸ‰", "VOL", "vol"])

    if code_today is None or vol_today is None:
        return pd.Series(0.0, index=df_today.index)

    base_dir = Path("iceage") / "data" / "raw"
    history_frames: list[pd.DataFrame] = []

    # 1) ê³¼ê±° raw íŒŒì¼ë“¤ì—ì„œ ê³µí†µ í‚¤ "code" / "volume" í˜•íƒœë¡œ ì •ë¦¬
    for i in range(1, lookback_days + 1):
        d = ref_date - timedelta(days=i)
        path = base_dir / f"kr_prices_{d.isoformat()}.csv"
        if not path.exists():
            continue

        try:
            tmp = pd.read_csv(path)
        except Exception:
            continue

        raw_code = _find_col(tmp, ["code", "ì¢…ëª©ì½”ë“œ", "ticker"])
        raw_vol = _find_col(tmp, ["volume", "ê±°ë˜ëŸ‰", "VOL", "vol"])

        if raw_code is None or raw_vol is None:
            continue

        tmp = tmp[[raw_code, raw_vol]].copy()
        tmp.rename(columns={raw_code: "code", raw_vol: "volume"}, inplace=True)

        tmp["code"] = tmp["code"].astype(str).str.zfill(6)
        tmp["volume"] = (
            tmp["volume"]
            .astype(str)
            .str.replace(",", "", regex=False)
        )
        tmp["volume"] = pd.to_numeric(tmp["volume"], errors="coerce")
        tmp = tmp.dropna(subset=["volume"])
        if tmp.empty:
            continue

        tmp["log_vol"] = np.log1p(tmp["volume"].astype(float))
        history_frames.append(tmp[["code", "log_vol"]])

    if not history_frames:
        # ê³¼ê±° ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ
        return pd.Series(0.0, index=df_today.index)

    history = pd.concat(history_frames, ignore_index=True)

    stats = (
        history.groupby("code")["log_vol"]
        .agg(["mean", "std"])
        .rename(columns={"mean": "mu", "std": "sigma"})
        .reset_index()
    )
    stats["sigma"] = stats["sigma"].replace(0, np.nan)

    # 2) ì˜¤ëŠ˜ ë°ì´í„°ë„ ë™ì¼í•œ í‚¤ "code"ë¡œ ë§ì¶°ì£¼ê¸°
    today = df_today.copy()
    today["code"] = today[code_today].astype(str).str.zfill(6)

    vol_clean = (
        today[vol_today]
        .astype(str)
        .str.replace(",", "", regex=False)
    )
    vol_clean = pd.to_numeric(vol_clean, errors="coerce")
    log_v_today = np.log1p(vol_clean)

    merged = today[["code"]].copy()
    merged["log_v_today"] = log_v_today
    merged = merged.merge(stats, on="code", how="left")

    z = (merged["log_v_today"] - merged["mu"]) / merged["sigma"]
    z = z.replace([np.inf, -np.inf], np.nan).fillna(0.0)
    z.index = df_today.index

    return z
