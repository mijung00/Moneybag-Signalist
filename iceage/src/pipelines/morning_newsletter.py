# iceage/src/pipelines/morning_newsletter.py
# -*- coding: utf-8 -*-
from __future__ import annotations

import os
import json
import sys
import re  # [í•„ìˆ˜] ì •ê·œì‹ ëª¨ë“ˆ ìœ ì§€
import logging
logging.basicConfig(stream=sys.stdout, level=logging.INFO)
import pandas as pd
from pathlib import Path
import csv
from typing import List, Optional
import requests
from datetime import date as _date, timedelta, datetime
from textwrap import dedent
import tempfile
import boto3
from botocore.exceptions import ClientError

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))
from zoneinfo import ZoneInfo

# ---------------------------------------------------------------------
# âœ… SecretsManagerë¥¼ JSON í˜•íƒœë¡œ ì €ì¥í–ˆì„ ë•Œë„ ë™ì‘í•˜ê²Œ(OPENAI_API_KEY ë“±)
# ---------------------------------------------------------------------
def _normalize_json_env(env_key: str) -> None:
    raw = os.getenv(env_key, "")
    if not raw:
        return
    s = raw.strip()

    # JSON í˜•íƒœ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë‘ 
    if not (s.startswith("{") and s.endswith("}")):
        return

    try:
        obj = json.loads(s)
        if not isinstance(obj, dict):
            return

        # 1) env_keyì™€ ê°™ì€ í‚¤ê°€ ìˆìœ¼ë©´ ê·¸ ê°’ì„ ì‚¬ìš©
        v = obj.get(env_key)

        # 2) ì—†ìœ¼ë©´ valueë¼ëŠ” ê´€ìš© í‚¤ë¥¼ ì‚¬ìš©
        if not v:
            v = obj.get("value")

        # 3) ê·¸ê²ƒë„ ì—†ìœ¼ë©´ dict ì•ˆì˜ "ì²«ë²ˆì§¸ ë¬¸ìì—´ ê°’"ì„ ì‚¬ìš©
        if not v:
            for vv in obj.values():
                if isinstance(vv, str) and vv.strip():
                    v = vv.strip()
                    break

        if isinstance(v, str) and v.strip():
            os.environ[env_key] = v.strip()
    except Exception:
        pass
_normalize_json_env("OPENAI_API_KEY")

try:
    from iceage.src.llm.openai_driver import generate_newsletter_bundle
except Exception as e:
    logging.warning(f"[LLM Import Error] OpenAI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤: {e}")
    # AI ê¸°ëŠ¥ì´ ì‹¤íŒ¨í•´ë„ í”„ë¡œê·¸ë¨ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡ Noneìœ¼ë¡œ ì„¤ì •
    generate_newsletter_bundle = None

from iceage.src.analyzers.signalist_history_analyzer import build_signalist_history_markdown

try:
    from iceage.src.pipelines.final_strategy_selector import StrategySelector
except ImportError:
    pass

from iceage.src.data_sources.signalist_today import SignalRow
from iceage.src.signals.signal_volume_pattern import detect_signals_from_volume_anomaly_v2
from iceage.src.data_sources.market_themes import get_market_themes, MarketThemeSummary
from iceage.src.data_sources.sector_themes import get_sector_themes, SectorThemeSummary
from iceage.src.data_sources.investor_flow import load_investor_flow
from iceage.src.data_sources.kr_prices import load_normalized_prices
from iceage.src.data_sources.market_snapshot import get_market_overview
from iceage.src.utils.trading_days import (
    TradingCalendar,
    CalendarConfig,
    compute_reference_date,
    may_run_today,
)
from common.s3_manager import S3Manager


# LLM ìºì‹œ
_LLM_BUNDLE_CACHE: dict[str, dict] = {}

# ---------------------------------------------------------------------
# âœ… í•œêµ­íˆ¬ìì¦ê¶Œ(KIS) API í´ë¼ì´ì–¸íŠ¸ (ë‰´ìŠ¤ë ˆí„°ìš©)
# ---------------------------------------------------------------------
class KisClient:
    def __init__(self):
        self.app_key = os.getenv("KIS_APP_KEY")
        self.app_secret = os.getenv("KIS_APP_SECRET")
        self.base_url = os.getenv("KIS_BASE_URL", "https://openapi.koreainvestment.com:9443")
        # S3 ì„¤ì •
        self.bucket_name = "fincore-output-storage"
        self.s3_key = "config/kis_token.json"
        self.s3 = boto3.client("s3", region_name="ap-northeast-2")
        self.token = None

    def _get_access_token(self):
        if self.token: return self.token

        # 1. S3 ìºì‹œ í™•ì¸
        try:
            obj = self.s3.get_object(Bucket=self.bucket_name, Key=self.s3_key)
            cache = json.loads(obj["Body"].read().decode("utf-8"))
            if cache.get("expires_at", 0) > datetime.now().timestamp() + 60:
                    self.token = cache["access_token"]
                    return self.token
        except Exception as e:
            logging.warning(f"[KIS Client] S3 í† í° ìºì‹œë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        url = f"{self.base_url}/oauth2/tokenP"
        headers = {"content-type": "application/json"}
        body = {
            "grant_type": "client_credentials",
            "appkey": self.app_key,
            "appsecret": self.app_secret
        }
        try:
            res = requests.post(url, json=body, timeout=5)
            if res.status_code == 200:
                data = res.json()
                self.token = data["access_token"]
                
                # 2. S3 ì €ì¥ (ë‚´ê°€ ì²˜ìŒì´ë©´ ì €ì¥)
                try:
                    expires_in = int(data.get("expires_in", 86400))
                    payload = {
                        "access_token": self.token,
                        "expires_at": datetime.now().timestamp() + expires_in - 60
                    }
                    self.s3.put_object(Bucket=self.bucket_name, Key=self.s3_key, Body=json.dumps(payload), ContentType="application/json")
                except Exception as e:
                    logging.warning(f"[KIS Client] S3ì— ìƒˆ í† í°ì„ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                
                return self.token
        except Exception as e:
            logging.error(f"[KIS Client] APIì—ì„œ ìƒˆ í† í°ì„ ë°œê¸‰ë°›ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

    def get_index_price(self, market_code: str, date_str: str) -> tuple[float, float] | None:
        """[ìˆ˜ì •] ì§€ì •ëœ ë‚ ì§œì˜ êµ­ë‚´ ì§€ìˆ˜ ì¢…ê°€ì™€ ë“±ë½ë¥ ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        logging.info(f"[KIS Client] {date_str} ê¸°ì¤€ ì§€ìˆ˜ ê°€ê²©({market_code}) ì¡°íšŒ ì‹œë„...")
        token = self._get_access_token()
        if not token: return None

        url = f"{self.base_url}/uapi/domestic-stock/v1/quotations/inquire-daily-indexchartprice"
        headers = {
            "content-type": "application/json; charset=utf-8",
            "authorization": f"Bearer {token}",
            "appkey": self.app_key,
            "appsecret": self.app_secret,
            "tr_id": "FHKUP03530100",  # êµ­ë‚´ì—…ì¢…ê¸°ê°„ë³„ì‹œì„¸
            "custtype": "P"
        }
        params = {
            "fid_cond_mrkt_div_code": "U",
            "fid_input_iscd": market_code,
            "fid_input_date_1": date_str.replace("-", ""),
            "fid_input_date_2": date_str.replace("-", ""),
            "fid_period_div_code": "D",
        }
        res: Optional[requests.Response] = None
        try:
            res = requests.get(url, headers=headers, params=params, timeout=5)
            if res.status_code == 200:
                data = res.json()
                if data.get('rt_cd') == '0':
                    output = data.get('output2')
                    if output and len(output) > 0:
                        day_data = output[0]
                        return float(day_data['bstp_nmix_clpr']), float(day_data['prdy_ctrt'])
                    else:
                        logging.warning(f"[KIS Client] {date_str} ì§€ìˆ˜({market_code}) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ë‹µ: {res.text[:200]}")
                else:
                    logging.warning(f"[KIS Client] API ì˜¤ë¥˜ ({market_code}, {date_str}): {data.get('msg1')}")
            else:
                logging.warning(f"[KIS Client] HTTP ì˜¤ë¥˜ ({market_code}, {date_str}): Status {res.status_code}, Body: {res.text[:200]}")
        except Exception as e:
            logging.error(f"[KIS Client] ì§€ìˆ˜ ì¼ë³„ ê°€ê²©({market_code}, {date_str}) ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ---------------------------------------------------------------------
# âœ… ë„¤ì´ë²„ ê¸ˆìœµ í´ë¼ì´ì–¸íŠ¸ (API í‚¤ ì—†ì´ ë¬´ë£Œ ì‚¬ìš©)
# ---------------------------------------------------------------------
class NaverClient:
    def get_index(self, symbol: str) -> tuple[float, float] | None:
        """
        ë„¤ì´ë²„ ëª¨ë°”ì¼ APIë¥¼ í†µí•´ ì§€ìˆ˜ ì¡°íšŒ
        symbol: KOSPI, KOSDAQ, NAS@IXIC(ë‚˜ìŠ¤ë‹¥), SPI@SPX(S&P500), DJI@DJI(ë‹¤ìš°)
        ë°˜í™˜: (í˜„ì¬ê°€, ë“±ë½ë¥ )
        """
        res: Optional[requests.Response] = None
        try:
            # êµ­ë‚´/í•´ì™¸ URL ë¶„ê¸°
            if symbol in ["KOSPI", "KOSDAQ"]:
                url = f"https://m.stock.naver.com/api/index/{symbol}/basic"
            else:
                url = f"https://api.stock.naver.com/index/{symbol}/basic"
            
            res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=5)
            if res.status_code == 200:
                data = res.json()
                # [ìˆ˜ì •] API ë³€ê²½ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ í‚¤ë¥¼ ì‹œë„
                price_str = data.get('closePrice') or data.get('lastPrice') or data.get('compareToPreviousClosePrice')
                
                # 1ìˆœìœ„: fluctuationsRatio (ë“±ë½ë¥ )
                rate_val = data.get('fluctuationsRatio') 
                
                # 2ìˆœìœ„: compareToPreviousPrice.rate (ê°ì²´ ë‚´ë¶€)
                if rate_val is None:
                    comp = data.get('compareToPreviousPrice', {})
                    rate_val = comp.get('rate')

                if price_str is not None and rate_val is not None:
                    price = float(str(price_str).replace(',', ''))
                    rate = float(rate_val)
                    return price, rate # ë“±ë½ë¥ ì€ % ë‹¨ìœ„ë¡œ ê°€ì •
                logging.warning(f"[Naver Client] ì§€ìˆ˜({symbol})ì—ì„œ ì˜ˆìƒí•œ í‚¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ: {json.dumps(data)}")
        except Exception as e:
            response_text = ""
            if res and hasattr(res, 'text'):
                response_text = res.text[:500]
            logging.error(f"[Naver Client] ì§€ìˆ˜({symbol}) ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì‘ë‹µ: {response_text}")
        return None

    def get_exchange(self, symbol="FX_USDKRW") -> tuple[float, float] | None:
        """í™˜ìœ¨ ì¡°íšŒ (ê¸°ë³¸: ì›ë‹¬ëŸ¬)"""
        res: Optional[requests.Response] = None
        try:
            url = f"https://m.stock.naver.com/front-api/marketIndex/productDetail?category=exchange&reutersCode={symbol}"
            res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=5)
            if res.status_code == 200:
                data = res.json().get('result', {})
                price_str = data.get('closePrice') or data.get('lastPrice') or data.get('compareToPreviousClosePrice')
                
                # 1ìˆœìœ„: fluctuationsRatio (ë“±ë½ë¥ )
                rate_val = data.get('fluctuationsRatio')
                
                # 2ìˆœìœ„: compareToPreviousPrice.rate (ê°ì²´ ë‚´ë¶€)
                if rate_val is None:
                    comp = data.get('compareToPreviousPrice', {})
                    rate_val = comp.get('rate')

                if price_str is not None and rate_val is not None:
                    price = float(str(price_str).replace(',', ''))
                    return price, float(rate_val)
                logging.warning(f"[Naver Client] í™˜ìœ¨({symbol})ì—ì„œ ì˜ˆìƒí•œ í‚¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ: {json.dumps(data)}")
        except Exception as e:
            response_text = ""
            if res and hasattr(res, 'text'):
                response_text = res.text[:500]
            logging.error(f"[Naver Client] í™˜ìœ¨({symbol}) ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì‘ë‹µ: {response_text}")
        return None

    def get_oil(self, symbol="OIL_CL") -> tuple[float, float] | None:
        """ìœ ê°€ ì¡°íšŒ (ê¸°ë³¸: WTI)"""
        res: Optional[requests.Response] = None
        try:
            url = f"https://m.stock.naver.com/front-api/marketIndex/productDetail?category=oil&reutersCode={symbol}"
            res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=5)
            if res.status_code == 200:
                data = res.json().get('result', {})
                price_str = data.get('closePrice') or data.get('lastPrice') or data.get('compareToPreviousClosePrice')
                
                # 1ìˆœìœ„: fluctuationsRatio (ë“±ë½ë¥ )
                rate_val = data.get('fluctuationsRatio')
                
                # 2ìˆœìœ„: compareToPreviousPrice.rate (ê°ì²´ ë‚´ë¶€)
                if rate_val is None:
                    comp = data.get('compareToPreviousPrice', {})
                    rate_val = comp.get('rate')

                if price_str is not None and rate_val is not None:
                    price = float(str(price_str).replace(',', ''))
                    return price, float(rate_val)
                logging.warning(f"[Naver Client] ìœ ê°€({symbol})ì—ì„œ ì˜ˆìƒí•œ í‚¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ: {json.dumps(data)}")
        except Exception as e:
            response_text = ""
            if res and hasattr(res, 'text'):
                response_text = res.text[:500]
            logging.error(f"[Naver Client] ìœ ê°€({symbol}) ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì‘ë‹µ: {response_text}")
        return None

class KisApiExtension:
    """
    í•œêµ­íˆ¬ìì¦ê¶Œ(KIS) APIë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ì™¸ ì§€ìˆ˜, í™˜ìœ¨, ì›ìì¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í™•ì¥ í´ë˜ìŠ¤.
    ëª¨ë“  API í˜¸ì¶œ ì‹œ ìƒì„¸ ë¡œê¹…ì„ í†µí•´ ì‹¤íŒ¨ ì›ì¸ì„ ì¶”ì í•©ë‹ˆë‹¤.
    """
    def __init__(self, app_key, app_secret, s3_bucket="fincore-output-storage", s3_key_path="config/kis_token.json"):
        self.base_url = os.getenv("KIS_BASE_URL", "https://openapi.koreainvestment.com:9443")
        self.app_key = app_key
        self.app_secret = app_secret
        self.s3_bucket = s3_bucket
        self.s3_key_path = s3_key_path
        self.s3_client = boto3.client('s3')
        self.access_token = self._get_valid_token()

    def _get_valid_token(self):
        """S3ì—ì„œ í† í°ì„ í™•ì¸í•˜ê³ , ì—†ê±°ë‚˜ ë§Œë£Œëœ ê²½ìš° ìƒˆë¡œ ë°œê¸‰ë°›ìŠµë‹ˆë‹¤."""
        try:
            response = self.s3_client.get_object(Bucket=self.s3_bucket, Key=self.s3_key_path)
            token_data = json.loads(response['Body'].read().decode('utf-8'))
            if token_data.get("expires_at", 0) > datetime.now().timestamp() + 60:
                return token_data['access_token']
        except Exception:
            logging.info("[KisApiExtension] ìœ íš¨í•œ ìºì‹œ í† í°ì´ ì—†ì–´ ìƒˆë¡œ ë°œê¸‰ì„ ì§„í–‰í•©ë‹ˆë‹¤.")

        url = f"{self.base_url}/oauth2/tokenP"
        payload = {"grant_type": "client_credentials", "appkey": self.app_key, "appsecret": self.app_secret}
        try:
            res = requests.post(url, json=payload, timeout=5)
            if res.status_code == 200:
                data = res.json()
                new_token = data['access_token']
                try:
                    expires_in = int(data.get("expires_in", 86400))
                    save_data = {
                        "access_token": new_token,
                        "expires_at": datetime.now().timestamp() + expires_in - 60
                    }
                    self.s3_client.put_object(Bucket=self.s3_bucket, Key=self.s3_key_path, Body=json.dumps(save_data))
                except Exception as e:
                    logging.warning(f"[KisApiExtension] S3ì— ìƒˆ í† í°ì„ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return new_token
        except Exception as e:
            logging.error(f"[KisApiExtension] í† í° ë°œê¸‰ ì‹¤íŒ¨: {e}")
        return None

    def _get_headers(self, tr_id):
        return {
            "Content-Type": "application/json; charset=utf-8",
            "authorization": f"Bearer {self.access_token}",
            "appkey": self.app_key, "appsecret": self.app_secret,
            "tr_id": tr_id,
            "custtype": "P" # ê°œì¸ ê³ ê° ê¸°ì¤€
        }

    def get_overseas_index(self, symbol: str) -> tuple[float, float] | None:
        """
        í•´ì™¸ ì§€ìˆ˜(S&P 500, ë‚˜ìŠ¤ë‹¥, ë‹¤ìš°ì¡´ìŠ¤, ë‹¬ëŸ¬ì¸ë±ìŠ¤) ì¡°íšŒ
        TR_ID: HHDFS00000300
        """
        mapping = {
            'SPI@SPX': ('AMS', '.SPX'),  # S&P 500
            'NAS@IXIC': ('NAS', '.IXIC'), # ë‚˜ìŠ¤ë‹¥ ì¢…í•©
            'DJI@DJI': ('NYS', '.DJI'),   # ë‹¤ìš°ì¡´ìŠ¤
            'FX_USDX': ('NYS', '.DXY')    # ë‹¬ëŸ¬ ì¸ë±ìŠ¤
        }
        
        if symbol not in mapping:
            logging.error(f"[KisApiExtension] ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§€ìˆ˜ ì‹¬ë³¼: {symbol}")
            return None
        
        excd, symb = mapping[symbol]
        url = f"{self.base_url}/uapi/overseas-stock/v1/quotations/inquire-price"
        params = {"AUTH": "", "EXCD": excd, "SYMB": symb}
        
        try:
            res = requests.get(url, headers=self._get_headers("HHDFS00000300"), params=params)
            data = res.json()
            
            if data.get("rt_cd") == "0" and 'output' in data:
                output = data['output']
                # ovrs_nmix_prpr: í˜„ì¬ ì§€ìˆ˜, prdy_ctrt: ëŒ€ë¹„ìœ¨
                return float(output['ovrs_nmix_prpr']), float(output['prdy_ctrt'])
            else:
                logging.warning(
                    f"[KisApiExtension] ì§€ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨({symbol}): {data.get('msg1')}\n"
                    f"íŒŒë¼ë¯¸í„°: {params}, ì‘ë‹µì „ë¬¸: {res.text[:500]}"
                )
        except Exception as e:
            logging.error(f"[KisApiExtension] ì§€ìˆ˜ í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
        return None

    def get_exchange_rate(self, symbol: str) -> tuple[float, float] | None:
        """
        ì›/ë‹¬ëŸ¬ í™˜ìœ¨ ì¡°íšŒ ë° ë‹¬ëŸ¬ì¸ë±ìŠ¤(ì§€ìˆ˜ API í™œìš©)
        """
        if symbol == 'FX_USDX':
            return self.get_overseas_index('FX_USDX')
        
        if symbol != 'FX_USDKRW':
            return None

        url = f"{self.base_url}/uapi/overseas-stock/v1/quotations/inquire-price"
        # í™˜ìœ¨ ë°ì´í„°ì˜ ê²½ìš° ê±°ë˜ì†Œë¥¼ FXë¡œ ì§€ì •í•˜ì—¬ ì§€ìˆ˜ APIë¥¼ í†µí•´ ì¡°íšŒí•˜ëŠ” ë°©ì‹ì´ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.
        params = {"AUTH": "", "EXCD": "FX", "SYMB": "USDKRW"}
        
        try:
            res = requests.get(url, headers=self._get_headers("HHDFS00000300"), params=params)
            data = res.json()
            if data.get("rt_cd") == "0" and 'output' in data:
                output = data['output']
                return float(output['ovrs_nmix_prpr']), float(output['prdy_ctrt'])
            else:
                logging.warning(
                    f"[KisApiExtension] í™˜ìœ¨ ì¡°íšŒ ì‹¤íŒ¨: {data.get('msg1')}\n"
                    f"ì‘ë‹µì „ë¬¸: {res.text[:500]}"
                )
        except Exception as e:
            logging.error(f"[KisApiExtension] í™˜ìœ¨ í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
        return None

    def get_commodity_price(self, symbol: str) -> tuple[float, float] | None:
        """
        WTI ìœ ê°€ ì„ ë¬¼ ì¡°íšŒ (TR_ID: HHDFS76240000)
        """
        if symbol != 'OIL_CL':
            return None
            
        url = f"{self.base_url}/uapi/overseas-future/v1/quotations/inquire-price"
        # CL000: WTI ì„ ë¬¼ ìµœê·¼ë¬¼(ì—°ì†) ì‹¬ë³¼
        params = {"SYMB": "CL000"}
 
        try:
            res = requests.get(url, headers=self._get_headers("HHDFS76240000"), params=params)
            data = res.json()
            
            # í•´ì™¸ì„ ë¬¼ì˜ ê²½ìš° ì‘ë‹µ êµ¬ì¡°ê°€ 'output1'ì„ì— ì£¼ì˜
            if data.get("rt_cd") == "0" and 'output1' in data:
                output = data['output1'] # í•´ì™¸ì„ ë¬¼ì€ output1
                return float(output['last']), float(output['rate'])
            else:
                logging.warning(
                    f"[KisApiExtension] ì›ìì¬ ì¡°íšŒ ì‹¤íŒ¨: {data.get('msg1')}\n"
                    f"íŒŒë¼ë¯¸í„°: {params}, ì‘ë‹µì „ë¬¸: {res.text[:500]}"
                )
        except Exception as e:
            logging.error(f"[KisApiExtension] ì›ìì¬ í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
        return None

# ìºì‹œ ì¶”ê°€ (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€)
_MARKET_OVERVIEW_CACHE = {}

def get_market_overview_safe(ref_date: _date) -> dict:
    """ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ì‹œ KIS APIë¡œ êµ­ë‚´ ì§€ìˆ˜ ì‹¬íì†Œìƒ"""
    ref_str = str(ref_date)
    if ref_str in _MARKET_OVERVIEW_CACHE:
        return _MARKET_OVERVIEW_CACHE[ref_str]

    snap = {"indices": {}, "fx": {}, "commodities": {}, "crypto": {}}
    
    indices = snap.setdefault("indices", {})
    fx = snap.setdefault("fx", {})
    commodities = snap.setdefault("commodities", {})

    # --- [ìˆ˜ì •] í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
    kis_ext = None
    if os.getenv("KIS_APP_KEY"):
        kis_ext = KisApiExtension(app_key=os.getenv("KIS_APP_KEY"), app_secret=os.getenv("KIS_APP_SECRET"))
    
    nc = NaverClient() # NaverClientëŠ” ìµœì¢… ë¹„ìƒìš©ìœ¼ë¡œ ìœ ì§€
    
    # 1. [ìˆ˜ì •] ë¡œì»¬ì— ìˆ˜ì§‘ëœ ì§€ìˆ˜ íŒŒì¼ì—ì„œ ë°ì´í„° ì½ê¸° (ê°€ì¥ ì •í™•)
    # daily_runnerê°€ ìˆ˜ì§‘í•œ kr_market_index.csv íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì–´ì œ ì¢…ê°€ ê¸°ì¤€ìœ¼ë¡œ ì¡°íšŒ
    try:
        index_file = PROJECT_ROOT / "iceage" / "data" / "raw" / "kr_market_index.csv"
        if index_file.exists():
            df_idx = pd.read_csv(index_file, thousands=',') # ì‰¼í‘œ(,)ë¥¼ ìˆ«ìë¡œ ì¸ì‹
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸° ë° datetime ê°ì²´ë¡œ ë³€í™˜
            date_col = next((c for c in df_idx.columns if 'ë‚ ì§œ' in c or 'date' in c.lower()), None)
            if date_col:
                df_idx[date_col] = pd.to_datetime(df_idx[date_col])
                ref_date_data = df_idx[df_idx[date_col].dt.date == ref_date].copy()

                if not ref_date_data.empty:
                    name_col = next(c for c in df_idx.columns if 'ì§€ìˆ˜ëª…' in c or 'name' in c.lower())
                    close_col = next(c for c in df_idx.columns if 'ì¢…ê°€' in c or 'close' in c.lower())
                    rate_col = next(c for c in df_idx.columns if 'ë“±ë½ë¥ ' in c or 'rate' in c.lower())

                    kospi_row = ref_date_data[ref_date_data[name_col] == 'ì½”ìŠ¤í”¼']
                    if not kospi_row.empty: indices["KOSPI"] = (kospi_row.iloc[0][close_col], kospi_row.iloc[0][rate_col])

                    kosdaq_row = ref_date_data[ref_date_data[name_col] == 'ì½”ìŠ¤ë‹¥']
                    if not kosdaq_row.empty: indices["KOSDAQ"] = (kosdaq_row.iloc[0][close_col], kosdaq_row.iloc[0][rate_col])
    except Exception as e:
        logging.warning(f"[get_market_overview_safe] ë¡œì»¬ ì§€ìˆ˜ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # 2. KIS API (ë¡œì»¬ íŒŒì¼ ì‹¤íŒ¨ ì‹œ ë°±ì—…) - [ìˆ˜ì •] ì „ì¼ ì¢…ê°€ ì¡°íšŒ
    if "KOSPI" not in indices and os.getenv("KIS_APP_KEY"):
        kis = KisClient()
        date_str = ref_date.isoformat()
        if (k_data := kis.get_index_price("0001", date_str)): indices["KOSPI"] = k_data
        if (k_data := kis.get_index_price("1001", date_str)): indices["KOSDAQ"] = k_data

    # 3. [ìˆ˜ì •] KIS í™•ì¥ APIë¡œ í•´ì™¸ ì‹œì„¸ ì¡°íšŒ (1ìˆœìœ„) / ì‹¤íŒ¨ ì‹œ Naverë¡œ ëŒ€ì²´ (2ìˆœìœ„)
    def fetch_with_fallback(kis_method, nc_method, *args):
        if kis_ext and (data := kis_method(*args)):
            return data
        return nc_method(*args)

    # êµ­ë‚´ ì§€ìˆ˜ ìµœì¢… ë°±ì—…
    if "KOSPI" not in indices: indices["KOSPI"] = nc.get_index("KOSPI")
    if "KOSDAQ" not in indices: indices["KOSDAQ"] = nc.get_index("KOSDAQ")

    # í•´ì™¸ ì§€ìˆ˜
    indices["S&P 500"] = fetch_with_fallback(kis_ext.get_overseas_index, nc.get_index, "SPI@SPX")
    indices["NASDAQ"] = fetch_with_fallback(kis_ext.get_overseas_index, nc.get_index, "NAS@IXIC")
    indices["Dow Jones"] = fetch_with_fallback(kis_ext.get_overseas_index, nc.get_index, "DJI@DJI")

    # í™˜ìœ¨ ë° ë‹¬ëŸ¬ì¸ë±ìŠ¤
    fx["USD/KRW"] = fetch_with_fallback(kis_ext.get_exchange_rate, nc.get_exchange, "FX_USDKRW")
    fx["DXY"] = fetch_with_fallback(kis_ext.get_exchange_rate, nc.get_exchange, "FX_USDX")

    # ì›ìì¬
    commodities["WTI"] = fetch_with_fallback(kis_ext.get_commodity_price, nc.get_oil, "OIL_CL")

    # ë°ì´í„°ê°€ ì—†ëŠ” í•­ëª©ì€ ì œê±°
    snap["indices"] = {k: v for k, v in indices.items() if v}
    snap["fx"] = {k: v for k, v in fx.items() if v}
    snap["commodities"] = {k: v for k, v in commodities.items() if v}

    _MARKET_OVERVIEW_CACHE[ref_str] = snap
    return snap

def _get_newsletter_env_suffix() -> str:
    env = os.getenv("NEWSLETTER_ENV", "prod").strip().lower()
    if env in ("", "prod"):
        return ""
    return f"-{env}"

# 1. LLMì—ê²Œ ë³´ë‚¼ ì¬ë£Œë¥¼ í’ì„±í•˜ê²Œ ë§Œë“œëŠ” í•¨ìˆ˜
def _build_llm_payload(ref_date: str) -> dict:
    """LLMì—ê²Œ ë³´ë‚¼ ì¬ë£Œ ì¤€ë¹„ (ì „ëµ ì˜ë„ í¬í•¨)"""
    ref = _date.fromisoformat(ref_date)
    
    # (1) ì‹œì¥ ìš”ì•½
    snap = get_market_overview_safe(ref)
    
    headline_bits = []
    indices = snap.get("indices", {})
    if "KOSPI" in indices: headline_bits.append(f"ì½”ìŠ¤í”¼ {indices['KOSPI'][1]:+.2f}%")
    if "KOSDAQ" in indices: headline_bits.append(f"ì½”ìŠ¤ë‹¥ {indices['KOSDAQ'][1]:+.2f}%")
    if "S&P 500" in indices: headline_bits.append(f"S&P500 {indices['S&P 500'][1]:+.2f}%")
    index_summary = " Â· ".join(headline_bits)

    # (2) ì‹œê·¸ë„ ì¢…ëª©
    signal_items = []
    try:
        selector = StrategySelector(ref_date)
        results = selector.select_targets()
        
        candidates = []
        for r in results.get('panic_buying', []):
            r['_strat_hint'] = "íˆ¬ë§¤ê°€ ê³¼ë„í•˜ì—¬ ê¸°ìˆ ì  ë°˜ë“±ì´ ê¸°ëŒ€ë˜ëŠ” êµ¬ê°„"
            candidates.append(r)
        for r in results.get('fallen_angel', []):
            r['_strat_hint'] = "ë‚™í­ ê³¼ëŒ€ ìš°ëŸ‰ì£¼ì˜ ì €ì  ë§¤ìˆ˜ ê¸°íšŒ"
            candidates.append(r)
        for r in results.get('kings_shadow', []):
            r['_strat_hint'] = "ëŒ€í˜•ì£¼ ìƒìŠ¹ ì¶”ì„¸ ì¤‘ ë§¤ë¬¼ ì†Œí™” ê³¼ì • (ëˆŒë¦¼ëª©)"
            candidates.append(r)
        for r in results.get('overheat_short', []):
            r['_strat_hint'] = "ë‹¨ê¸° í­ë“±ìœ¼ë¡œ ì¸í•œ í”¼ë¡œê° ëˆ„ì , ì°¨ìµ ì‹¤í˜„ ë§¤ë¬¼ ì£¼ì˜ (ê³ ì  ì§•í›„)"
            candidates.append(r)
                         
        candidates.sort(key=lambda x: abs(float(x.get('tv_z', 0))), reverse=True)
        top_rows = candidates[:5]
        
        event_map = _get_internal_events(ref_date)
        
        for r in top_rows:
            name = r.get('name', '')
            item = {
                "name": name,
                "change_rate": f"{float(r.get('chg', 0)):+.2f}%",
                "volume_z": f"{float(r.get('tv_z', 0)):.1f}ë°°",
                "strategy_intent": r.get('_strat_hint', ''),
                "keywords": event_map.get(name, ""),
                "is_bull": "ë§¤ìˆ˜" in r.get('_sentiment', 'ë§¤ìˆ˜')
            }
            signal_items.append(item)
            
    except Exception as e:
        print(f"[WARN] LLM Payload ìƒì„± ì˜¤ë¥˜: {e}")

    global_items = load_global_news(ref_date, limit=3)
    articles = [{"title": i.get("title_en",""), "snippet": i.get("summary_en","")} for i in global_items]

    return {
        "ref_date": ref_date,
        "index_summary_line": index_summary,
        "signals": signal_items,
        "global_news": articles,
    }

# 2. í…Œë§ˆ ì„¹ì…˜
def section_themes(ref_date: str) -> str:
    ref = _date.fromisoformat(ref_date)
    themes = get_sector_themes(ref)
    if not themes: return "## Todayâ€™s Market Themes\n\nì˜¤ëŠ˜ì€ ì„¹í„° ê¸°ì¤€ìœ¼ë¡œ ë‘ë“œëŸ¬ì§„ í…Œë§ˆ ì›€ì§ì„ì´ í¬ê²Œ ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    total_turnover = sum(max(getattr(t, "turnover_sum", 0.0), 0.0) for t in themes)
    
    lines = ["## Todayâ€™s Market Themes", f"ê¸°ì¤€ì¼: {ref_date}", ""]
    
    for t in themes[:3]:
        lines.append(f"### {t.sector}")
        lines.append(f"- ì„¹í„° í‰ê·  ìˆ˜ìµë¥ : **{t.avg_return:+.2f}%**")
        
        if total_turnover > 0:
            share = max(getattr(t, "turnover_sum", 0.0), 0.0) / total_turnover * 100
            flame_count = min(5, int(share // 10))
            if flame_count == 0 and share > 1.0: flame_count = 1
            flames = "ğŸ”¥" * flame_count
            
            if share > 30: comment = "ëˆì´ ì´ ì„¹í„°ì— ìŸì•„ì¡ŒìŠµë‹ˆë‹¤."
            elif share > 20: comment = "ì£¼ë„ ì„¹í„°ì˜ ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤."
            elif share > 10: comment = "ìœ ì˜ë¯¸í•œ ìê¸ˆì´ ìœ ì…ë˜ì—ˆìŠµë‹ˆë‹¤."
            else: comment = "íŠ¹ì • ì¢…ëª© ìœ„ì£¼ë¡œ ì›€ì§ì˜€ìŠµë‹ˆë‹¤."
            
            lines.append(f"- ğŸ’° ìˆ˜ê¸‰ ì§‘ì¤‘ë„: {flames} **({share:.1f}%)** - _{comment}_")
        
        lines.append(f"- ëŒ€í‘œ ì¢…ëª©: {', '.join(t.top_stocks)}")
        lines.append("")
        
    return "\n".join(lines)

def _ensure_llm_bundle(ref_date: str) -> dict:
    if ref_date in _LLM_BUNDLE_CACHE:
        return _LLM_BUNDLE_CACHE[ref_date]

    bundle = {}
    # LLM ë“œë¼ì´ë²„ê°€ ì„±ê³µì ìœ¼ë¡œ importë˜ì—ˆëŠ”ì§€ í™•ì¸
    if generate_newsletter_bundle:
        payload = _build_llm_payload(ref_date)
        try:
            bundle = generate_newsletter_bundle(payload)
        except Exception as e:
            print("[WARN] LLM ë²ˆë“¤ ìƒì„± ì‹¤íŒ¨:", repr(e))
            bundle = {}
    
    _LLM_BUNDLE_CACHE[ref_date] = bundle
    return bundle

ENABLE_INVESTOR_FLOW_SECTION = False 

def section_header_intro(ref_date: str) -> str:
    bundle = _ensure_llm_bundle(ref_date)
    title = bundle.get("title") or f"The Signalist Daily â€” {ref_date}"
    kicker = bundle.get("kicker") or ""
    market_summary = bundle.get("market_one_liner") or ""
    
    ref = _date.fromisoformat(ref_date)
    snap = get_market_overview_safe(ref)
    
    indices = snap.get("indices", {})
    fx = snap.get("fx", {})
    commodities = snap.get("commodities", {})
    crypto = snap.get("crypto", {})

    def _fmt(key, label=None):
        if key in indices: val, pct = indices[key]
        elif key in fx: val, pct = fx[key]
        elif key in commodities: val, pct = commodities[key]
        elif key in crypto: val, pct = crypto[key]
        elif "WTI" in key and "WTI" in commodities: val, pct = commodities["WTI"]
        elif "WTI" in key and "WTI Crude" in commodities: val, pct = commodities["WTI Crude"]
        elif "BTC" in key and "BTC/USD" in crypto: val, pct = crypto["BTC/USD"]
        else: return ""
        
        icon = "ğŸ”º" if pct > 0 else ("ğŸ”¹" if pct < 0 else "-")
        lbl = label if label else key
        return f"{lbl} {val:,.2f} ({icon} {pct:+.2f}%)"

    line_kr = []
    for k, l in [("KOSPI", "ì½”ìŠ¤í”¼"), ("KOSDAQ", "ì½”ìŠ¤ë‹¥"), ("USD/KRW", "ì›/ë‹¬ëŸ¬")]:
        r = _fmt(k, l)
        if r: line_kr.append(r)
        
    line_us = []
    for k, l in [("Dow Jones", "ë‹¤ìš°"), ("NASDAQ", "ë‚˜ìŠ¤ë‹¥"), ("S&P 500", "S&P500")]:
        r = _fmt(k, l)
        if r: line_us.append(r)
        
    line_macro = []
    for k, l in [("WTI", "WTIìœ "), ("BTC", "ë¹„íŠ¸ì½”ì¸")]:
        r = _fmt(k, l)
        if r: line_macro.append(r)

    lines = [f"# {title}", ""]
    if kicker:
        lines.append(f"_{kicker}_")
        lines.append("")
    
    lines.append("## ì˜¤ëŠ˜ì˜ ì‹œì¥ í•œëˆˆì— ë³´ê¸°")
    lines.append(f"ê¸°ì¤€ì¼: {ref_date}")
    lines.append("")
    
    if market_summary:
        lines.append(market_summary)
        lines.append("")
    
    if line_kr: lines.append(f"**í•œêµ­**: " + " â”‚ ".join(line_kr)); lines.append("")
    if line_us: lines.append(f"**ë¯¸êµ­**: " + " â”‚ ".join(line_us)); lines.append("")
    if line_macro: lines.append(f"**ê¸°íƒ€**: " + " â”‚ ".join(line_macro)); lines.append("")

    if not line_kr and not line_us:
        lines.append("> _ì‹œì¥ ì§€í‘œ ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì™¸ë¶€ API ì„œë¹„ìŠ¤ ì ê²€ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤._")
        lines.append("")

    return "\n".join(lines)

def _select_signalist_today_rows(ref: _date) -> List[SignalRow]:
    try: all_rows = detect_signals_from_volume_anomaly_v2(ref)
    except Exception: all_rows = []
    if not all_rows: return []

    def _vol(r):
        try: return abs(float(getattr(r, "vol_sigma", 0.0)))
        except Exception: return 0.0
    candidates = sorted(all_rows, key=_vol, reverse=True)

    def _sector(r):
        val = getattr(r, "sector", "") or getattr(r, "theme", "")
        return str(val).strip()

    pos_rows = [r for r in candidates if getattr(r, "vol_sigma", 0.0) > 0]
    neg_rows = [r for r in candidates if getattr(r, "vol_sigma", 0.0) < 0]
    TOP_N = 5; PER_SECTOR_LIMIT = 2
    selected: list = []; seen: set[tuple] = set(); sector_counts: dict[str, int] = {}

    def _can_add(r) -> bool:
        k = (r.name, getattr(r, "vol_sigma", 0.0))
        if k in seen: return False
        sec = _sector(r)
        if not sec: return True
        if sector_counts.get(sec, 0) >= PER_SECTOR_LIMIT: return False
        return True

    def _add(r):
        if not _can_add(r): return
        k = (r.name, getattr(r, "vol_sigma", 0.0))
        seen.add(k); selected.append(r)
        sec = _sector(r)
        if sec: sector_counts[sec] = sector_counts.get(sec, 0) + 1

    if pos_rows: _add(pos_rows[0])
    if neg_rows: _add(neg_rows[0])
    for r in candidates:
        if len(selected) >= TOP_N: break
        _add(r)
    if len(selected) < TOP_N:
        for r in candidates:
            if len(selected) >= TOP_N: break
            k = (r.name, getattr(r, "vol_sigma", 0.0))
            if k in seen: continue
            seen.add(k); selected.append(r)
    return selected

# ---------------------------------------------------------
# [í•µì‹¬] ì´ìŠˆ í‚¤ì›Œë“œ ì¶”ì¶œê¸° V2 (ì •ê·œì‹ ê°•í™” ë²„ì „ ìœ ì§€)
# ---------------------------------------------------------
def _extract_keyword_from_title(title: str, stock_name: str) -> str:
    if not title: return "-"
    
    # 1. ê´„í˜¸ ë° ëŒ€ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±° (ì˜ˆ: [íŠ¹ì§•ì£¼], (ì†ë³´))
    title = re.sub(r"\[.*?\]", " ", title)
    title = re.sub(r"\(.*?\)", " ", title)
    
    # 2. ì¢…ëª©ëª… ì œê±° (ì •í™•ë„ í–¥ìƒì„ ìœ„í•´ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜)
    title = title.replace(stock_name, " ")
    
    # 3. íŠ¹ìˆ˜ë¬¸ì ì œê±° (ë”°ì˜´í‘œ, ì , ì‰¼í‘œ, ì¤„í‘œ ë“± -> ê³µë°±)
    # í•œê¸€, ì˜ë¬¸, ìˆ«ì ë¹¼ê³  ë‹¤ ì§€ì›€
    title = re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", " ", title)
    
    # 4. ë¶ˆìš©ì–´(Stopwords) ì œê±° - ë‰´ìŠ¤ ìƒíˆ¬ì–´
    stop_words = [
        "íŠ¹ì§•ì£¼", "ê¸‰ë“±", "ìƒìŠ¹", "í•˜ë½", "ì•½ì„¸", "ê°•ì„¸", "ì£¼ê°€", "ì „ë§", "ì´ìŠˆ", 
        "ê³µì‹œ", "ì²´ê²°", "ê·œëª¨", "ì¢…ëª©", "ê´€ë ¨ì£¼", "í…Œë§ˆ", "ë¶„ì„", "ì†ë³´", "ë‹¨ë…",
        "ì˜í–¥", "ì£¼ëª©", "ìµœê³ ", "ìµœì €", "ê²½ì‹ ", "ëŒíŒŒ", "ë§ˆê°", "ì¶œë°œ", "ì˜¤ì „", "ì˜¤í›„",
        "í¬ì°©", "ì²´í¬", "ì£¼ì˜", "ë¹„ìƒ", "ê¸°ëŒ€", "ìš°ë ¤", "ì‡¼í¬", "ì„œí”„ë¼ì´ì¦ˆ", "ì‹¤ì ",
        "ë°œí‘œ", "ê³µê°œ", "ê°œì‹œ", "ì„±ê³µ", "ì²´ê²°", "í™•ì •", "ì§„ì…", "í™•ëŒ€", "ì¶•ì†Œ", "ìƒí•œê°€", "í•˜í•œê°€"
    ]
    for w in stop_words:
        title = title.replace(w, " ")
        
    # 5. ìˆ«ì ì œê±° ë° 1ê¸€ì ì œê±°
    words = title.split()
    cleaned_words = []
    for w in words:
        if re.search(r"\d", w): continue
        if len(w) < 2: continue
        
        # ëì— ë¶™ì€ ì¡°ì‚¬ ì œê±° (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
        if len(w) >= 3 and w[-1] in ['ì—', 'ë¡œ', 'ì„', 'ë¥¼', 'ê°€', 'ì´', 'ì€', 'ëŠ”', 'ì˜']:
             w = w[:-1]
        cleaned_words.append(w)
        
    if not cleaned_words: return "-"
        
    # 6. ê°€ì¥ ê¸´ ë‹¨ì–´ ì„ íƒ
    return max(cleaned_words, key=len)

def _get_internal_events(ref_date: str) -> dict[str, str]:
    news_path = PROJECT_ROOT / "iceage" / "data" / "raw" / f"kr_stock_event_news_{ref_date}.jsonl"
    event_map = {}
    if not news_path.exists(): return {}
    
    with news_path.open(encoding="utf-8") as f:
        for line in f:
            try:
                item = json.loads(line)
                name = item.get("stock_name")
                title = item.get("title")
                if name and title:
                    if name not in event_map:
                        keyword = _extract_keyword_from_title(title, name)
                        if keyword and keyword != "-":
                            event_map[name] = keyword
            except: continue
    return event_map

def section_market_thermometer(ref_date: str) -> str:
    ref = _date.fromisoformat(ref_date)
    try:
        snap = get_market_overview_safe(ref)
        indices = snap.get("indices", {})
        changes = []
        if "KOSPI" in indices: changes.append(indices["KOSPI"][1])
        if "KOSDAQ" in indices: changes.append(indices["KOSDAQ"][1])
        if not changes: return ""
        avg_chg = sum(changes) / len(changes)
    except: return ""

    if avg_chg >= 1.5:
        status = "ğŸ”¥ ê³¼ì—´ (Extreme Greed)"; gauge = "[ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥]"; comment = "ì‹œì¥ì´ ëœ¨ê²ìŠµë‹ˆë‹¤. ì¶”ê²© ë§¤ìˆ˜ë³´ë‹¤ëŠ” ì°¨ìµ ì‹¤í˜„ì„ ê³ ë ¤í•  êµ¬ê°„ì…ë‹ˆë‹¤."
    elif avg_chg >= 0.5:
        status = "â˜€ï¸ ë§‘ìŒ (Greed)"; gauge = "[ğŸŸ¥ğŸŸ¥ğŸŸ¥â¬œâ¬œ]"; comment = "íˆ¬ì ì‹¬ë¦¬ê°€ ì‚´ì•„ë‚¬ìŠµë‹ˆë‹¤. ì£¼ë„ì£¼ ìœ„ì£¼ì˜ ì ‘ê·¼ì´ ìœ íš¨í•©ë‹ˆë‹¤."
    elif avg_chg >= -0.5:
        status = "â˜ï¸ íë¦¼ (Neutral)"; gauge = "[â¬œâ¬œğŸŸ©â¬œâ¬œ]"; comment = "ë°©í–¥ì„± íƒìƒ‰ êµ¬ê°„ì…ë‹ˆë‹¤. ê°œë³„ ì¢…ëª© ì´ìŠˆì— ì§‘ì¤‘í•˜ì„¸ìš”."
    elif avg_chg >= -1.5:
        status = "â˜” ë¹„ (Fear)"; gauge = "[ğŸŸ¦ğŸŸ¦ğŸŸ¦â¬œâ¬œ]"; comment = "íˆ¬ì‹¬ì´ ìœ„ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. ë³´ìˆ˜ì ì¸ ê´€ì ì´ í•„ìš”í•©ë‹ˆë‹¤."
    else:
        status = "â„ï¸ í˜¹í•œ (Extreme Fear)"; gauge = "[ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦]"; comment = "ê³µí¬ êµ¬ê°„ì…ë‹ˆë‹¤. íˆ¬ë§¤ ë™ì°¸ë³´ë‹¤ëŠ” 'íŒ¨ë‹‰ ë°”ì‰' ê¸°íšŒë¥¼ ë…¸ë¦¬ì„¸ìš”."

    return dedent(f"""
    ### ğŸŒ¡ï¸ ì˜¤ëŠ˜ì˜ ì‹œì¥ ì˜¨ë„: {status}
    **{gauge}**
    > *"{comment}"*
    """).strip()

def section_signalist_today(ref_date: str) -> str:
    try:
        from iceage.src.pipelines.final_strategy_selector import StrategySelector
        selector = StrategySelector(ref_date)
        results = selector.select_targets()
        
        candidates = []
        for r in results.get('panic_buying', []) + results.get('fallen_angel', []) + results.get('kings_shadow', []):
            r['_sentiment'] = 'ğŸ“ˆ ë§¤ìˆ˜ ìš°ìœ„'
            bucket = r.get('size_bucket', '')
            if bucket == 'large': r['_tone'] = "ğŸ”µ ëŒ€í˜•ì£¼ ìˆ˜ê¸‰"
            elif bucket == 'mid': r['_tone'] = "ğŸŸ¡ ì¤‘í˜•ì£¼ ë°˜ë“±"
            else: r['_tone'] = "ğŸŸ¢ ì†Œí˜•ì£¼ ê¸‰ë“±"
            candidates.append(r)
            
        shorts = results.get('overheat_short', [])
        if shorts:
            shorts = sorted(shorts, key=lambda x: abs(float(x.get('tv_z', 0))), reverse=True)[:1]
            for r in shorts:
                r['_sentiment'] = 'ğŸ“‰ ë§¤ë„ ìš°ìœ„'
                r['_tone'] = "ğŸš¨ ê³¼ì—´ ê²½ë³´"
                candidates.append(r)
            
        candidates.sort(key=lambda x: abs(float(x.get('tv_z', 0))), reverse=True)
        rows = candidates[:5]
        
    except Exception as e:
        rows = []
        logging.error(f"Signalist Today ì„¹ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if not rows:
        return "## ì˜¤ëŠ˜ì˜ ë ˆì´ë” í¬ì°© (The Signalist Radar)\n\ní¬ì°©ëœ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤."

    event_map = _get_internal_events(ref_date)

    intro = dedent("""
    ## ì˜¤ëŠ˜ì˜ ë ˆì´ë” í¬ì°© (The Signalist Radar)
    **"ë°ì´í„°ê°€ ë°œê²¬í•œ ìˆ˜ê¸‰ì˜ ë³€ê³¡ì "**
    Signalistë ˆì´ë”ëŠ” ì‹œì´ë³„ íŠ¹ì„±ê³¼ ê±°ë˜ëŒ€ê¸ˆ ê´´ë¦¬ìœ¨ì„ ì…ì²´ì  ë¶„ì„í•˜ì—¬, **ìœ ì˜ë¯¸í•œ íë¦„ì´ í¬ì°©ëœ ì¢…ëª©**ì„ ì„ ë³„í•©ë‹ˆë‹¤.
    ë‹¨ìˆœí•œ ê°€ê²© ë“±ë½ì´ ì•„ë‹Œ, **í‰ì†Œ ëŒ€ë¹„ ë¹„ì •ìƒì ì¸ ê±°ë˜ ê°•ë„**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ëŠ¥ì„±ì´ ë†’ì€ êµ¬ê°„ì„ íƒì§€í–ˆìŠµë‹ˆë‹¤.
    """).strip()

    header = "| ì¢…ëª©ëª… | ì¢…ê°€ | ë“±ë½ (í­) | ê´´ë¦¬ìœ¨ | ìˆ˜ê¸‰ ë°©í–¥ | ì´ìŠˆ í‚¤ì›Œë“œ |"
    sep = "|---|---|---|---|---|---|"
    
    body = []
    for r in rows:
        name = r.get('name', '')
        close_val = int(r.get('close', 0))
        close_str = f"{close_val:,}"
        chg_pct = float(r.get('chg', 0))
        prev_close = close_val / (1 + chg_pct/100)
        chg_won = int(close_val - prev_close)
        
        if chg_pct > 0: chg_str = f"**+{chg_pct:.2f}%**<br><small>(â–²{chg_won:,})</small>"
        elif chg_pct < 0: chg_str = f"{chg_pct:.2f}%<br><small>(â–¼{abs(chg_won):,})</small>"
        else: chg_str = "0.00%"
            
        sigma = f"{float(r.get('tv_z', 0)):+.1f}Ïƒ"
        display_tone = f"{r.get('_sentiment', '-')}<br>({r.get('_tone', '')})"
        event_key = event_map.get(name, "-")

        body.append(f"| {name} | {close_str} | {chg_str} | {sigma} | {display_tone} | {event_key} |")

    table = "\n".join([header, sep] + body)
    
    memo_lines = ["\n### ğŸ§ ì¢…ëª©ë³„ ê´€ì°° ë©”ëª¨"]
    bundle = _ensure_llm_bundle(ref_date)
    sig_comments = bundle.get("signal_comments") or {}
    
    for r in rows:
        name = r.get('name')
        comment = sig_comments.get(name) or "íŠ¹ì´ ìˆ˜ê¸‰ í¬ì°©"
        memo_lines.append(f"- **{name}**: {comment}")

    memo_md = "\n".join(memo_lines)
    
    return f"{intro}\n\nê¸°ì¤€ì¼: {ref_date}\n\n{table}\n{memo_md}\n\n_ìœ„ ë¦¬ìŠ¤íŠ¸ëŠ” ì•Œê³ ë¦¬ì¦˜ ì¶”ì¶œ ê²°ê³¼ì´ë©°, íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹™ë‹ˆë‹¤._"

def section_signalist_history(ref_date: str, window_days: int = 90) -> str:
    ref = _date.fromisoformat(ref_date)
    return build_signalist_history_markdown(ref, lookback_days=window_days)

def load_kr_news_cleaned(ref_date: str, limit: int = 5) -> list[dict]:
    path = Path("iceage") / "data" / "processed" / f"kr_news_cleaned_{ref_date}.jsonl"
    if not path.exists(): return []
    items = []
    with path.open(encoding="utf-8") as f:
        for line in f:
            try: items.append(json.loads(line))
            except: continue
            if len(items) >= limit: break
    return items

def load_global_news(ref_date: str, limit: int = 3) -> list[dict]:
    path = Path("iceage") / "data" / "processed" / f"global_news_{ref_date}.jsonl"
    if not path.exists(): return []
    items = []
    with path.open(encoding="utf-8") as f:
        for line in f:
            try: items.append(json.loads(line))
            except: continue
            if len(items) >= limit: break
    return items

def section_news_digest(ref_date: str) -> str:
    kr_items = load_kr_news_cleaned(ref_date, limit=5)
    global_items = load_global_news(ref_date, limit=3)
    lines = ["## Todayâ€™s Top News"]

    if kr_items:
        lines.append("\n### êµ­ë‚´ ì£¼ìš” ë‰´ìŠ¤\n")
        for i, item in enumerate(kr_items, 1):
            lines.append(f"{i}. [{item.get('title')}]({item.get('link')}) ({item.get('source')})")
        lines.append("")

    if global_items:
        bundle = _ensure_llm_bundle(ref_date)
        llm_summary = bundle.get("global_summary")
        lines.append("\n### í•´ì™¸ ì£¼ìš” ë‰´ìŠ¤\n")
        if isinstance(llm_summary, dict):
            if llm_summary.get("headline"): lines.append(f"**{llm_summary['headline']}**\n")
            if llm_summary.get("summary"): lines.append(f"{llm_summary['summary']}\n")
            for b in llm_summary.get("bullets", []): lines.append(f"- {b}")
            lines.append("")
        for i, item in enumerate(global_items, 1):
            t = item.get("title_en") or item.get("title")
            lines.append(f"{i}. [{t}]({item.get('link')}) ({item.get('source')})")

    return "\n".join(lines).strip()

def section_global_minute(ref_date: str) -> str:
    ref = _date.fromisoformat(ref_date)
    snap = get_market_overview_safe(ref)
    indices = snap.get("indices", {})
    fx = snap.get("fx", {})
    commodities = snap.get("commodities", {})

    sp_level, sp_pct = indices.get("S&P 500", (None, None))
    ndq_level, ndq_pct = indices.get("NASDAQ", (None, None))
    dxy_level, dxy_pct = fx.get("DXY", (None, None))
    wti_level, wti_pct = commodities.get("WTI", commodities.get("WTI Crude", (None, None)))

    lines = ["## Global Minute", f"ê¸°ì¤€ì¼: {ref_date}", ""]
    lines.append("### US")
    if sp_pct is not None:
        lines.append(f"- ì´ìŠˆ: S&P 500 {sp_level:,.2f} ({sp_pct:+.2f}%), NASDAQ {ndq_pct:+.2f}%")
        if sp_pct > 0.4: impact = "ì„±ì¥ì£¼Â·ê¸°ìˆ ì£¼ ì¤‘ì‹¬ìœ¼ë¡œ ìœ„í—˜ì„ í˜¸ê°€ ê°•í™”ëœ íë¦„ì…ë‹ˆë‹¤."
        elif sp_pct < -0.4: impact = "ê¸ˆë¦¬Â·ì‹¤ì  ë¶€ë‹´ìœ¼ë¡œ ìœ„í—˜ìì‚° íšŒí”¼ ì‹¬ë¦¬ê°€ ë‚˜íƒ€ë‚œ êµ¬ê°„ì…ë‹ˆë‹¤."
        else: impact = "ì‹¤ì Â·ë§¤í¬ë¡œ ì´ë²¤íŠ¸ë¥¼ ì†Œí™”í•˜ë©° ë°©í–¥ì„±ì„ íƒìƒ‰í•˜ëŠ” ì¡°ì • êµ¬ê°„ì…ë‹ˆë‹¤."
        lines.append(f"- í•´ì„: {impact}")
    else:
        lines.append("- ì´ìŠˆ: ë°ì´í„° ë¶€ì¡±")
        lines.append("- í•´ì„: ë¯¸êµ­ ì¦ì‹œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    lines.append("")

    lines.append("### ë‹¬ëŸ¬/í™˜ìœ¨")
    if dxy_pct is not None:
        lines.append(f"- ì´ìŠˆ: ë‹¬ëŸ¬ ì¸ë±ìŠ¤(DXY) {dxy_level:,.2f} ({dxy_pct:+.2f}%)")
        if dxy_pct < -0.3: impact = "ë‹¬ëŸ¬ ì•½ì„¸ êµ¬ê°„ìœ¼ë¡œ, ì‹ í¥êµ­ ìì‚°ê³¼ ìœ„í—˜ìì‚°ì— ìƒëŒ€ì ìœ¼ë¡œ ìš°í˜¸ì ì¸ í™˜ê²½ì…ë‹ˆë‹¤."
        elif dxy_pct > 0.3: impact = "ë‹¬ëŸ¬ ê°•ì„¸ë¡œ, ì•ˆì „ìì‚° ì„ í˜¸ ë° ìœ ë™ì„± ê²½ê³„ ì‹¬ë¦¬ê°€ ë°˜ì˜ëœ íë¦„ì…ë‹ˆë‹¤."
        else: impact = "ë‹¬ëŸ¬ê°€ ëšœë ·í•œ ë°©í–¥ì„± ì—†ì´ ë“±ë½í•˜ë©° ë‹¨ê¸° ì´ë²¤íŠ¸ë¥¼ ê´€ë§í•˜ëŠ” êµ¬ê°„ì…ë‹ˆë‹¤."
        lines.append(f"- í•´ì„: {impact}")
    else:
        lines.append("- ì´ìŠˆ: ë°ì´í„° ë¶€ì¡±")
        lines.append("- í•´ì„: ë‹¬ëŸ¬ ì¸ë±ìŠ¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    lines.append("")

    lines.append("### ì›ìì¬/ì—ë„ˆì§€")
    if wti_pct is not None:
        lines.append(f"- ì´ìŠˆ: WTI {wti_level:,.2f}ë‹¬ëŸ¬ ({wti_pct:+.2f}%)")
        if wti_pct > 0.5: impact = "ìœ ê°€ ìƒìŠ¹ìœ¼ë¡œ ì¸í”Œë ˆì´ì…˜Â·ì›ê°€ ë¶€ë‹´ì— ëŒ€í•œ ê²½ê³„ê°€ ë‹¤ì‹œ ë¶€ê°ë  ìˆ˜ ìˆëŠ” êµ¬ê°„ì…ë‹ˆë‹¤."
        elif wti_pct < -0.5: impact = "ìœ ê°€ í•˜ë½ìœ¼ë¡œ ë¬¼ê°€ ë¶€ë‹´ ì™„í™” ê¸°ëŒ€ê°€ ì»¤ì§€ë©° ìœ„í—˜ìì‚°ì— ìš°í˜¸ì ì¸ í™˜ê²½ì…ë‹ˆë‹¤."
        else: impact = "ìœ ê°€ê°€ ë°•ìŠ¤ê¶Œ ë“±ë½ì„ ì´ì–´ê°€ë©° ê³µê¸‰Â·ìˆ˜ìš” ì´ìŠˆë¥¼ ì†Œí™”í•˜ëŠ” êµ¬ê°„ì…ë‹ˆë‹¤."
        lines.append(f"- í•´ì„: {impact}")
    else:
        lines.append("- ì´ìŠˆ: ë°ì´í„° ë¶€ì¡±")
        lines.append("- í•´ì„: ìœ ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    lines.append("")

    return "\n".join(lines)

def section_investors_mind(topic: str, body: str) -> str:
    if not topic or not body: return ""
    return dedent(f"""
    ## ğŸ§˜ Investor's Mind: {topic}
    {body}
    """).strip()

def _find_col(columns, candidates):
    cols = list(columns)
    for c in candidates:
        if c in columns: return c
    for c in candidates:
        for col in cols:
            if c in str(col): return col
    return None

def _load_turnover_by_market(ref: _date) -> dict[str, float]:
    """
    [ìˆ˜ì •] ê±°ë˜ëŒ€ê¸ˆ ì»¬ëŸ¼ì´ ìˆì–´ë„ ë°ì´í„°ê°€ 0ì´ë©´, 
    ì¢…ê°€*ê±°ë˜ëŸ‰ìœ¼ë¡œ ê°•ì œ ë³µêµ¬í•˜ì—¬ ë°˜í™˜í•˜ëŠ” ì•ˆì „ì¥ì¹˜ ì¶”ê°€
    """
    raw_path = Path("iceage") / "data" / "raw" / f"kr_prices_{ref.isoformat()}.csv"
    if not raw_path.exists(): return {}
    
    try: 
        df = pd.read_csv(raw_path)
    except: return {}
    
    # ìˆ«ì ë³€í™˜ í—¬í¼
    def _clean(x):
        try: return float(str(x).replace(",", ""))
        except: return 0.0
        
    cols = set(df.columns)
    
    # 1. ì‹œì¥ êµ¬ë¶„ ì»¬ëŸ¼ ì°¾ê¸°
    market_col = _find_col(cols, ["market", "ì‹œì¥êµ¬ë¶„", "ì‹œì¥", "Market"])
    if not market_col: return {}
    
    # 2. ê±°ë˜ëŒ€ê¸ˆ ìš°ì„  ì‹œë„
    value_col = _find_col(cols, ["trading_value", "ê±°ë˜ëŒ€ê¸ˆ"])
    if value_col:
        df["_turnover_"] = df[value_col].apply(_clean)
    else:
        df["_turnover_"] = 0.0
        
    # 3. [í•µì‹¬] ê±°ë˜ëŒ€ê¸ˆì´ ë¹„ì–´ìˆê±°ë‚˜ í•©ê³„ê°€ 0ì´ë©´ ê°•ì œ ê³„ì‚° (ì‹¬íì†Œìƒìˆ )
    if df["_turnover_"].sum() == 0:
        close_col = _find_col(cols, ["close", "ì¢…ê°€", "í˜„ì¬ê°€"])
        vol_col = _find_col(cols, ["volume", "ê±°ë˜ëŸ‰"])
        
        if close_col and vol_col:
            df["_turnover_"] = df[close_col].apply(_clean) * df[vol_col].apply(_clean)

    return df.groupby(market_col)["_turnover_"].sum().to_dict()

def section_numbers_that_matter(ref_date: str) -> str:
    ref = _date.fromisoformat(ref_date)
    lines = ["## Numbers that Matter", f"ê¸°ì¤€ì¼: {ref_date}", ""]
    
    by_market = _load_turnover_by_market(ref)
    if by_market:
        lines.append("### ì˜¤ëŠ˜ êµ­ë‚´ ì£¼ì‹ ê±°ë˜ëŒ€ê¸ˆ (ì¡°ì› ë‹¨ìœ„, ì¶”ì •)")
        total = 0.0
        for market_name, v in by_market.items():
            total += float(v)
            trillions = float(v) / 1_000_000_000_000
            lines.append(f"- {market_name}: {trillions:,.1f}ì¡°")
        lines.append(f"- í•©ê³„: {total / 1_000_000_000_000:,.1f}ì¡°")
        lines.append("")
        
    fx_series = []
    for back in range(4, -1, -1):
        d = ref - timedelta(days=back)
        try:
            snap = get_market_overview_safe(d)
            fx = snap.get("fx", {})
            if "USD/KRW" in fx: fx_series.append((d, fx["USD/KRW"][0]))
        except: continue
        
    if fx_series:
        lines.append("### USD/KRW í™˜ìœ¨ (ìµœê·¼ ì¼ì)")
        prev = None
        for d, level in fx_series:
            diff = f"({level-prev:+.2f})" if prev else ""
            lines.append(f"- {d.isoformat()}: {level:,.2f} {diff}")
            prev = level
        lines.append("")
        
    if ENABLE_INVESTOR_FLOW_SECTION:
        flow_map = load_investor_flow(ref)
        if flow_map:
            lines.append("### íˆ¬ììë³„ ë§¤ë§¤ ë™í–¥ (ë‹¨ìœ„: ì–µì›, ìˆœë§¤ìˆ˜ ê¸°ì¤€)")
            lines.append("| ì‹œì¥ | ê°œì¸ | ì™¸êµ­ì¸ | ê¸°ê´€ |")
            lines.append("|------|------|--------|------|")
            for m in ["KOSPI", "KOSDAQ"]:
                s = flow_map.get(m)
                if s:
                    p = s.net_by_investor.get("ê°œì¸", 0)
                    f = s.net_by_investor.get("ì™¸êµ­ì¸", 0)
                    i = s.net_by_investor.get("ê¸°ê´€", 0)
                    lines.append(f"| {m} | {p:,.1f} | {f:,.1f} | {i:,.1f} |")
            lines.append("")
            
    return "\n".join(lines)

def extract_first_sentence(text: str) -> str:
    if not text: return ""
    cleaned = " ".join(text.split())
    sentences = re.split(r'(?<=[\.!?])\s+', cleaned)
    return sentences[0].strip() if sentences else cleaned.strip()

def section_morning_quote(quote: str) -> str:
    return dedent(f"""
    ## Morning Quote
    > {quote}
    """).strip()

def section_footer() -> str:
    return dedent(f"""
    ---
    ë³¸ ì½˜í…ì¸ ëŠ” íˆ¬ì ê¶Œìœ  ëª©ì ì´ ì•„ë‹Œ ì •ë³´ ì œê³µìš©ì…ë‹ˆë‹¤.  
    The Signalist Â© 2025 All Rights Reserved.  [êµ¬ë…í•´ì§€]  [ì˜ê²¬ë³´ë‚´ê¸°]
    """).strip()

MIND_TOPICS = ["í™•ì‹ ë³´ë‹¤ ìœ ì—°í•¨", "ì†ì‹¤ì„ ëŒ€í•˜ëŠ” íƒœë„", "ê³¼ì‰ í™•ì‹ ì˜ í•¨ì •", "ë³µë¦¬ì™€ ê¸°ë‹¤ë¦¼", "í¬ì§€ì…˜ ì‚¬ì´ì§•"]
def pick_topic_and_body(ref_date: str) -> tuple[str, str]:
    import random
    fallback_topic = random.choice(MIND_TOPICS)
    fallback_body = "í‰ì •ì‹¬ì„ ìœ ì§€í•˜ì„¸ìš”. ì‹œì¥ì€ ì–¸ì œë‚˜ ê¸°íšŒë¥¼ ì¤ë‹ˆë‹¤."
    try:
        bundle = _ensure_llm_bundle(ref_date)
        im = bundle.get("investor_mind") or {}
        return im.get("topic", fallback_topic), im.get("body", fallback_body)
    except: return fallback_topic, fallback_body

def render_newsletter(ref_date: str) -> str:
    topic, body = pick_topic_and_body(ref_date)
    parts = [
        section_header_intro(ref_date),
        section_market_thermometer(ref_date),
        section_signalist_today(ref_date),
        section_signalist_history(ref_date),
        section_themes(ref_date),
        # IPO ì„¹ì…˜ ì œê±°
        section_global_minute(ref_date),
        section_news_digest(ref_date),
        section_investors_mind(topic, body),
        section_numbers_that_matter(ref_date),
        section_footer()
    ]
    return "\n\n".join([p for p in parts if p])

def log_signalist_today(ref_date: str, rows: list, force: bool = True) -> None:
    if not rows: return
    out_dir = PROJECT_ROOT / "iceage" / "data" / "processed"
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "signalist_today_log.csv"
    
    new_records = []
    for r in rows:
        if hasattr(r, '__dict__'):
            d = {
                "signal_date": ref_date, "code": getattr(r, "code", ""), "name": r.name,
                "close": r.close, "vol_sigma": float(getattr(r, "vol_sigma", 0.0)),
                "sentiment": getattr(r, "sentiment", ""), "insight": getattr(r, "insight", "")
            }
        else:
            d = {
                "signal_date": ref_date, "code": str(r.get('code', '')).zfill(6),
                "name": r.get('name', ''), "close": r.get('close', 0),
                "vol_sigma": float(r.get('tv_z', 0) or r.get('vol_sigma', 0)),
                "sentiment": r.get('_sentiment') or r.get('sentiment', ''),
                "insight": r.get('_insight') or r.get('insight', '')
            }
        new_records.append(d)
        
    new_records.sort(key=lambda x: abs(x['vol_sigma']), reverse=True)
    new_records = new_records[:5]
    df_new = pd.DataFrame(new_records)
    
    if out_path.exists():
        try:
            df_old = pd.read_csv(out_path, encoding="utf-8-sig")
            
            # [Fix] ì»¬ëŸ¼ í˜¸í™˜ì„± ì²´í¬ (ê³¼ê±° ë°±í•„ ë°ì´í„° í˜¸í™˜)
            if "date" in df_old.columns and "signal_date" not in df_old.columns:
                df_old.rename(columns={"date": "signal_date"}, inplace=True)
            
            if "tv_z" in df_old.columns and "vol_sigma" not in df_old.columns:
                df_old.rename(columns={"tv_z": "vol_sigma"}, inplace=True)
                
            if "signal_date" not in df_old.columns:
                print("[ERROR] ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ì— 'signal_date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë®ì–´ì“°ê¸°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë³‘í•©ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return 

            df_old = df_old[df_old["signal_date"] != ref_date]
            df_all = pd.concat([df_old, df_new], ignore_index=True)
        except Exception as e:
            print(f"[ERROR] ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ ë³‘í•© ì‹¤íŒ¨: {e}")
            print("   -> ê¸°ì¡´ ë°ì´í„°ë¥¼ ë³´ì¡´í•˜ê¸° ìœ„í•´ ìƒˆ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return # ì•ˆì „ì¥ì¹˜: ì—ëŸ¬ë‚˜ë©´ ê·¸ëƒ¥ ë¦¬í„´ (ë®ì–´ì“°ê¸° ë°©ì§€)
    else: 
        df_all = df_new
    
    df_all = df_all.sort_values("signal_date")
    df_all.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ… [Log Saved] {ref_date} ì‹œê·¸ë„ {len(new_records)}ê°œ ì €ì¥ ì™„ë£Œ!")

def main():
    cal = TradingCalendar(CalendarConfig())
    if len(sys.argv) >= 2: ref_date = sys.argv[1]
    else: 
        # [ìˆ˜ì •] ì„œë²„ì˜ ê¸°ë³¸ ì‹œê°„ëŒ€(UTC) ëŒ€ì‹  í•œêµ­ ì‹œê°„(KST)ì„ ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©
        now_kst = datetime.now(ZoneInfo('Asia/Seoul'))
        ref = compute_reference_date(cal, now_kst)
        ref_date = ref.isoformat()

    print(f"\nğŸ“… Newsletter ref_date: {ref_date}")

    try:
        selector = StrategySelector(ref_date)
        results = selector.select_targets()
        candidates = []
        for r in results.get('panic_buying', []) + results.get('fallen_angel', []) + results.get('kings_shadow', []):
            r['_sentiment'] = 'ğŸ“ˆ ë§¤ìˆ˜ ìš°ìœ„'
            b = r.get('size_bucket')
            if b == 'small': r['_insight'] = "ì†Œí˜•ì£¼ ìˆ˜ê¸‰ ë³€ê³¡ì  í¬ì°©"
            elif b == 'large': r['_insight'] = "ëŒ€í˜•ì£¼ ì¶”ì„¸ ëˆŒë¦¼ëª© í¬ì°©"
            else: r['_insight'] = "ì¤‘í˜•ì£¼ ë‚™í­ ê³¼ëŒ€ í¬ì°©"
            candidates.append(r)
        for r in results.get('overheat_short', []):
            r['_sentiment'] = 'ğŸ“‰ ë§¤ë„ ìš°ìœ„'
            r['_insight'] = "ë‹¨ê¸° ê³¼ì—´ê¶Œ ë„ë‹¬ (ê³ ì  ê²½ê³ )"
            candidates.append(r)
            
        candidates.sort(key=lambda x: abs(float(x.get('tv_z', 0))), reverse=True)
        final_rows = candidates[:5]
        
        if final_rows:
            log_signalist_today(ref_date, final_rows)

    except Exception as e:
        print(f"[ERROR] ì‹œê·¸ë„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

    md = render_newsletter(ref_date)
    
    out_dir = PROJECT_ROOT / "iceage" / "out"
    out_dir.mkdir(parents=True, exist_ok=True)
    suffix = _get_newsletter_env_suffix()
    filename = f"Signalist_Daily_{ref_date}{suffix}.md"
    out_path = out_dir / filename
    
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(md)

    print(f"âœ… ìƒì„± ì™„ë£Œ: {out_path}")

if __name__ == "__main__":
    main()