# iceage/src/collectors/krx_index_collector.py
import os
import sys
import requests
import pandas as pd
import time
import urllib3
from datetime import datetime, timedelta
from pathlib import Path

# [ìˆ˜ì •] ëª¨ë“  í™˜ê²½ ì„¤ì •ì€ common.configê°€ ì±…ì„ì§‘ë‹ˆë‹¤.
import common.config

# [ì ¬ê³µì˜ ì±…ëµ] ê²½ë¡œ ì„¤ì • & SSL ê²½ê³  ë„ê¸°
PROJECT_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

KRX_API_KEY = os.getenv("KRX_AUTH_KEY")

# ---------------------------------------------------------
# 1. KRX API ìˆ˜ì§‘ê¸° (Primary)
# ---------------------------------------------------------
def fetch_krx_index(market: str, ref_date: str) -> dict:
    """
    market: 'KOSPI' or 'KOSDAQ'
    ref_date: 'YYYYMMDD'
    """
    # Spec ë¬¸ì„œ ê¸°ì¤€ URL (data-dbg)
    if market == "KOSPI":
        url = "https://data-dbg.krx.co.kr/svc/apis/idx/kospi_dd_trd"
    else:
        url = "https://data-dbg.krx.co.kr/svc/apis/idx/kosdaq_dd_trd"
        
    headers = {"AUTH_KEY": KRX_API_KEY}
    params = {"basDd": ref_date}
    
    try:
        resp = requests.get(url, headers=headers, params=params, timeout=5, verify=False)
        if resp.status_code == 200:
            return resp.json()
        return {}
    except Exception as e:
        # print(f"[WARN] KRX {market} API Fail: {e}")
        return {}

# ---------------------------------------------------------
# 2. Naver ê¸ˆìœµ í¬ë¡¤ëŸ¬ (Fallback)
# ---------------------------------------------------------
def fetch_naver_index_fallback(market: str, target_date_str: str) -> dict:
    """
    KRX API ì‹¤íŒ¨ ì‹œ ë„¤ì´ë²„ ê¸ˆìœµ ì¼ë³„ ì‹œì„¸ í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ë°ì´í„° í™•ë³´
    target_date_str: 'YYYY-MM-DD'
    """
    code = "KOSPI" if market == "KOSPI" else "KOSDAQ"
    url = f"https://finance.naver.com/sise/sise_index_day.naver?code={code}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        # 1í˜ì´ì§€(ìµœì‹  6ì¼ì¹˜)ë§Œ ê°€ì ¸ì˜´
        resp = requests.get(url, headers=headers, timeout=5)
        resp.raise_for_status()
        
        # pandasë¡œ HTML í…Œì´ë¸” íŒŒì‹±
        dfs = pd.read_html(resp.text)
        if not dfs: return {}
        
        df = dfs[0].dropna() # ì²« ë²ˆì§¸ í…Œì´ë¸”ì´ ì‹œì„¸ ë°ì´í„°
        
        # ë‚ ì§œ í¬ë§· í†µì¼ (YYYY.MM.DD -> YYYY-MM-DD)
        target_dot = target_date_str.replace("-", ".")
        
        # í•´ë‹¹ ë‚ ì§œ í–‰ ì°¾ê¸°
        row = df[df['ë‚ ì§œ'] == target_dot]
        
        if row.empty:
            # print(f"[WARN] ë„¤ì´ë²„ì—ë„ {target_date_str} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
            
        # ë°ì´í„° ì¶”ì¶œ
        # ì²´ê²°ê°€(ì¢…ê°€), ë“±ë½ë¥ (ì „ì¼ë¹„ ë¹„ìœ¨)
        close = str(row.iloc[0]['ì²´ê²°ê°€']).replace(",", "")
        
        # ë“±ë½ë¥  ê³„ì‚° (ë„¤ì´ë²„ëŠ” 'ë“±ë½ë¥ ' ì»¬ëŸ¼ì´ ë°”ë¡œ ê¸íˆê¸°ë„ í•˜ì§€ë§Œ, ì „ì¼ë¹„ë¡œ ê³„ì‚°í•˜ëŠ” ê²Œ ì•ˆì „)
        # í•˜ì§€ë§Œ í‘œì— %ê°€ ìˆë‹¤ë©´ ê·¸ê±¸ ì”€. ë³´í†µ ë„¤ì´ë²„ í‘œì—ëŠ” 'ì²´ê²°ê°€', 'ì „ì¼ë¹„', 'ë“±ë½ë¥ 'ì´ ìˆìŒ.
        # read_html ê²°ê³¼ ì»¬ëŸ¼ëª… í™•ì¸ í•„ìš”. ë³´í†µ ['ë‚ ì§œ', 'ì²´ê²°ê°€', 'ì „ì¼ë¹„', 'ë“±ë½ë¥ ', 'ê±°ë˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ']
        
        fluc_rate = "0.0"
        if 'ë“±ë½ë¥ ' in row.columns:
            fluc_rate = str(row.iloc[0]['ë“±ë½ë¥ ']).replace("%", "").strip()
        
        # ë„¤ì´ë²„ 'ì „ì¼ë¹„'ëŠ” í™”ì‚´í‘œ ì´ë¯¸ì§€ê°€ í…ìŠ¤íŠ¸ë¡œ ì„ì¼ ìˆ˜ ìˆì–´ ì£¼ì˜. ë“±ë½ë¥  ì“°ëŠ” ê²Œ ë‚˜ìŒ.
        
        print(f"   ğŸ‘‰ [Fallback] ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ {market} ë°ì´í„° í™•ë³´ ì„±ê³µ!")
        return {
            "close": close,
            "fluc_rate": fluc_rate
        }

    except Exception as e:
        print(f"   âŒ [Fallback] ë„¤ì´ë²„ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return {}

# ---------------------------------------------------------
# 3. ë©”ì¸ ì‹¤í–‰ê¸°
# ---------------------------------------------------------
def run_collector(target_date_str: str):
    # YYYY-MM-DD -> YYYYMMDD
    ref_date_clean = target_date_str.replace("-", "")
    print(f"ğŸ“Š [{target_date_str}] ì§€ìˆ˜ ìˆ˜ì§‘ ì‹œë„...", end=" ")
    
    records = []
    
    markets = ["KOSPI", "KOSDAQ"]
    
    for m in markets:
        # 1ì°¨ ì‹œë„: KRX API
        val_close = None
        val_fluc = None
        
        data_krx = fetch_krx_index(m, ref_date_clean)
        
        # KRX ì‘ë‹µ íŒŒì‹±
        if data_krx:
            for item in data_krx.get("OutBlock_1", []):
                # 'ì½”ìŠ¤í”¼' ë˜ëŠ” 'ì½”ìŠ¤ë‹¥' (ì •í™•í•œ ì§€ìˆ˜ëª… ë§¤ì¹­)
                idx_nm = item.get("IDX_NM", "")
                if (m == "KOSPI" and idx_nm == "ì½”ìŠ¤í”¼") or (m == "KOSDAQ" and idx_nm == "ì½”ìŠ¤DAQ" or idx_nm == "ì½”ìŠ¤ë‹¥"):
                    val_close = str(item.get("CLSPRC_IDX", "0")).replace(",", "")
                    val_fluc = str(item.get("FLUC_RT", "0")).replace(",", "")
                    break
        
        # 2ì°¨ ì‹œë„: ì‹¤íŒ¨ ì‹œ ë„¤ì´ë²„ í´ë°±
        if val_close is None:
            print(f"(KRXë¶ˆí†µ->ë„¤ì´ë²„{m})", end=" ")
            data_naver = fetch_naver_index_fallback(m, target_date_str)
            if data_naver:
                val_close = data_naver.get("close")
                val_fluc = data_naver.get("fluc_rate")
        
        # ê²°ê³¼ ì €ì¥
        if val_close is not None:
            records.append({
                "date": target_date_str,
                "market": m,
                "close": val_close,
                "fluc_rate": val_fluc
            })

    if not records:
        print("ì‹¤íŒ¨ (íœ´ì¥ì¼ ë˜ëŠ” ë°ì´í„° ì—†ìŒ)")
        return

    # CSV ì €ì¥ (ëˆ„ì )
    out_dir = PROJECT_ROOT / "iceage" / "data" / "raw"
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "kr_market_index.csv"
    
    df_new = pd.DataFrame(records)
    
    if out_path.exists():
        df_old = pd.read_csv(out_path)
        # ë‚ ì§œ í¬ë§· í†µì¼ ë“± ì „ì²˜ë¦¬ í›„ ë³‘í•©
        df = pd.concat([df_old, df_new], ignore_index=True)
        # ì¤‘ë³µ ì œê±° (ê°™ì€ ë‚ ì§œ, ê°™ì€ ì‹œì¥ì´ë©´ ìµœì‹  ê±¸ë¡œ ë®ì–´ì“°ê¸°)
        df.drop_duplicates(subset=['date', 'market'], keep='last', inplace=True)
        df.sort_values('date', inplace=True)
    else:
        df = df_new
        
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"ì„±ê³µ âœ… (ì €ì¥: {len(df)} rows)")

def backfill_index(days: int = 365 * 3):
    print(f"ğŸš€ ì§€ìˆ˜ ë°ì´í„° {days}ì¼ ë°±í•„ ì‹œì‘...")
    end = datetime.now().date()
    start = end - timedelta(days=days)
    
    curr = start
    while curr <= end:
        # ì£¼ë§ ì œì™¸
        if curr.weekday() < 5: 
            run_collector(curr.isoformat())
            # API ë¶€í•˜ ë°©ì§€ (ë„¤ì´ë²„ í¬ë¡¤ë§ ì‹œ ë„ˆë¬´ ë¹ ë¥´ë©´ ì°¨ë‹¨ë  ìˆ˜ ìˆìŒ)
            time.sleep(0.5) 
        curr += timedelta(days=1)

if __name__ == "__main__":
    import sys
    if len(sys.argv) >= 2 and sys.argv[1] == "backfill":
        backfill_index()
    else:
        # ì¸ìê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ
        target = sys.argv[1] if len(sys.argv) >= 2 else datetime.now().strftime("%Y-%m-%d")
        run_collector(target)