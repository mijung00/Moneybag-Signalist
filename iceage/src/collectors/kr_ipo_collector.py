# iceage/src/collectors/kr_ipo_collector.py
# -*- coding: utf-8 -*-
import sys
import json
import re
import requests
import pandas as pd
from datetime import date
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# 38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ URL
URL_SUB = "http://www.38.co.kr/html/fund/index.htm?o=k"  # ê³µëª¨ì£¼ ì²­ì•½ì¼ì •
URL_LISTING = "http://www.38.co.kr/html/fund/index.htm?o=nw" # ì‹ ê·œ ìƒìž¥

def _clean_text(x):
    if pd.isna(x): return ""
    return str(x).strip()

def _is_spac(name: str) -> bool:
    target = name.replace(" ", "")
    if "ìŠ¤íŒ©" in target or "ê¸°ì—…ì¸ìˆ˜ëª©ì " in target:
        return True
    return False

def _parse_rate_to_float(raw_val) -> float:
    if pd.isna(raw_val): return 0.0
    # "1,200.5:1" -> "1200.5"
    s = str(raw_val).replace(",", "").split(":")[0]
    s = re.sub(r"[^\d\.]", "", s)
    try: return float(s)
    except: return 0.0

def collect_ipo_data(ref_date: date):
    print(f"ðŸš€ [IPO] 38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘ (ê¸°ì¤€ì¼: {ref_date})")
    results = {"subscription": [], "listing": []}
    
    # --- 1. ì²­ì•½ ì¼ì • ìˆ˜ì§‘ ---
    try:
        resp = requests.get(URL_SUB, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
        resp.encoding = "euc-kr"
        dfs = pd.read_html(resp.text)
        
        target_df = None
        # [FIX] ë°ì´í„°ê°€ ê°€ìž¥ ë§Žì€(í–‰ ìˆ˜ê°€ ë§Žì€) í…Œì´ë¸”ì„ ë©”ì¸ í…Œì´ë¸”ë¡œ ê°„ì£¼
        # 38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì€ ìƒë‹¨ì— ìž‘ì€ ìš”ì•½ í…Œì´ë¸”ë“¤ì´ ìžˆì–´ì„œ ì—‰ëš±í•œ ê±¸ ìž¡ì„ ìˆ˜ ìžˆìŒ
        candidate_dfs = []
        for df in dfs:
            # ì»¬ëŸ¼ ì´ë¦„ì— ê³µë°± ì œê±° í›„ í™•ì¸
            cols = [str(c).replace(" ", "") for c in df.columns]
            if "ì¢…ëª©ëª…" in cols and "ê³µëª¨ì£¼ì¼ì •" in cols:
                df.columns = cols # ì»¬ëŸ¼ëª… ê³µë°± ì œê±° ì ìš©
                candidate_dfs.append(df)
        
        if candidate_dfs:
            # í–‰ ìˆ˜ê°€ ê°€ìž¥ ë§Žì€ ê²ƒì´ ì§„ì§œ ë¦¬ìŠ¤íŠ¸ì¼ í™•ë¥  ë†’ìŒ
            target_df = max(candidate_dfs, key=len)
        
        if target_df is not None:
            target_df = target_df.dropna(subset=["ì¢…ëª©ëª…"])
            
            # ê²½ìŸë¥  ì»¬ëŸ¼ ì°¾ê¸° (ê¸°ê´€ê²½ìŸë¥ , ì²­ì•½ê²½ìŸë¥  ë“± í¬í•¨)
            comp_col = next((c for c in target_df.columns if "ê²½ìŸë¥ " in c), None)
            
            for _, row in target_df.iterrows():
                name = _clean_text(row.get("ì¢…ëª©ëª…"))
                if _is_spac(name): continue
                    
                schedule = _clean_text(row.get("ê³µëª¨ì£¼ì¼ì •"))
                price = row.get("í™•ì •ê³µëª¨ê°€", "")
                band = row.get("í¬ë§ê³µëª¨ê°€", "")
                underwriter = _clean_text(row.get("ì£¼ê°„ì‚¬", ""))
                
                competition_str = ""
                competition_rate = 0.0
                
                if comp_col:
                    competition_str = row.get(comp_col, "")
                    competition_rate = _parse_rate_to_float(competition_str)
                
                is_exceed_band = False
                try:
                    confirmed = int(str(price).replace(",", ""))
                    upper_band = int(str(band).split("~")[-1].replace(",", "").strip())
                    if confirmed > upper_band: is_exceed_band = True
                except: pass

                results["subscription"].append({
                    "name": name,
                    "schedule": schedule,
                    "price": str(price),
                    "band": str(band),
                    "underwriter": underwriter,
                    "competition_str": str(competition_str),
                    "competition_rate": competition_rate,
                    "is_exceed_band": is_exceed_band
                })
            print(f"  - ì²­ì•½ ì¼ì • {len(results['subscription'])}ê±´ ìˆ˜ì§‘ ì™„ë£Œ (ìŠ¤íŒ© ì œì™¸)")
            
    except Exception as e:
        print(f"[WARN] ì²­ì•½ ì¼ì • ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    # --- 2. ì‹ ê·œ ìƒìž¥ ì¼ì • ìˆ˜ì§‘ ---
    try:
        resp = requests.get(URL_LISTING, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
        resp.encoding = "euc-kr"
        dfs = pd.read_html(resp.text)
        
        target_df = None
        candidate_dfs = []
        for df in dfs:
            cols = [str(c).replace(" ", "") for c in df.columns]
            if "ê¸°ì—…ëª…" in cols and "ìƒìž¥ì¼" in cols:
                df.columns = cols
                candidate_dfs.append(df)
        
        if candidate_dfs:
            target_df = max(candidate_dfs, key=len)
                
        if target_df is not None:
            target_df = target_df.dropna(subset=["ê¸°ì—…ëª…"])
            for _, row in target_df.iterrows():
                name = _clean_text(row.get("ê¸°ì—…ëª…"))
                if _is_spac(name): continue
                    
                date_str = _clean_text(row.get("ìƒìž¥ì¼")) 
                price_offer = row.get("ê³µëª¨ê°€(ì›)", "")
                
                results["listing"].append({
                    "name": name,
                    "date": date_str,
                    "price_offer": str(price_offer).replace(",", "").strip(),
                })
            print(f"  - ì‹ ê·œ ìƒìž¥ ì¼ì • {len(results['listing'])}ê±´ ìˆ˜ì§‘ ì™„ë£Œ (ìŠ¤íŒ© ì œì™¸)")
            
    except Exception as e:
        print(f"[WARN] ì‹ ê·œ ìƒìž¥ ì¼ì • ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    out_dir = PROJECT_ROOT / "iceage" / "data" / "raw"
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / f"kr_ipo_info_{ref_date.isoformat()}.json"
    
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… IPO ë°ì´í„° ì €ìž¥ ì™„ë£Œ: {out_path}")

if __name__ == "__main__":
    if len(sys.argv) >= 2:
        ref = date.fromisoformat(sys.argv[1])
    else:
        ref = date.today()
    collect_ipo_data(ref)