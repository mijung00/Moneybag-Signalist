# iceage/src/collectors/naver_theme_collector.py
# -*- coding: utf-8 -*-
"""
[Signalist Upgrade]
ë„¤ì´ë²„ í…Œë§ˆ ëž­í‚¹(ìˆœìœ„)ì— ì˜ì¡´í•˜ì§€ ì•Šê³ , 'ì „ì²´ í…Œë§ˆ ë¦¬ìŠ¤íŠ¸'ë¥¼ ëª¨ë‘ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
ìƒˆë²½ ì‹œê°„ëŒ€ ë„¤ì´ë²„ ìˆœìœ„ ì´ˆê¸°í™”(0%) ì´ìŠˆë¥¼ ë°©ì–´í•˜ê¸° ìœ„í•¨ìž…ë‹ˆë‹¤.
ìˆ˜ì§‘ëœ ì „ì²´ í…Œë§ˆ ë§¤í•‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Aggregatorê°€ ì§ì ‘ ìˆ˜ìµë¥  ìˆœìœ„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
"""
from __future__ import annotations

import re
import time
import sys
from datetime import date
from pathlib import Path
from typing import List, Dict

import pandas as pd
import requests
from requests import RequestException
from bs4 import BeautifulSoup

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
try:
    PROJECT_ROOT = Path(__file__).resolve().parents[3]
    if str(PROJECT_ROOT) not in sys.path:
        sys.path.append(str(PROJECT_ROOT))
except Exception:
    pass

THEME_LIST_URL = "https://finance.naver.com/sise/theme.naver"

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/129.0.0.0 Safari/537.36"
    ),
    "Referer": "https://finance.naver.com/",
}

SESSION = requests.Session()
SESSION.headers.update(HEADERS)

def _safe_get(url: str, timeout: float = 10.0):
    try:
        res = SESSION.get(url, timeout=timeout)
        res.raise_for_status()
        return res
    except RequestException as e:
        print(f"[WARN] ìš”ì²­ ì‹¤íŒ¨: {url} -> {e}")
        return None

def _fetch_theme_list_all_pages() -> List[Dict]:
    """
    ë„¤ì´ë²„ í…Œë§ˆ ëª©ë¡ì˜ 'ëª¨ë“  íŽ˜ì´ì§€'ë¥¼ ìˆœíšŒí•˜ì—¬ ì „ì²´ í…Œë§ˆ ëª©ë¡ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    (ê¸°ì¡´: 1íŽ˜ì´ì§€ë§Œ ìˆ˜ì§‘ -> ë³€ê²½: ëê¹Œì§€ ìˆ˜ì§‘)
    """
    all_themes = []
    seen_ids = set()
    page = 1
    
    print("ðŸ”„ [ì „ìˆ˜ ì¡°ì‚¬] ë„¤ì´ë²„ ì „ì²´ í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹œìž‘...")

    while True:
        url = f"{THEME_LIST_URL}?page={page}"
        res = _safe_get(url, timeout=10)
        if res is None:
            break
        res.encoding = "euc-kr"

        soup = BeautifulSoup(res.text, "lxml")
        table = soup.select_one("table.type_1.theme")
        
        if not table:
            print(f"[INFO] {page}íŽ˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì—†ìŒ. ìˆ˜ì§‘ ì¢…ë£Œ.")
            break

        # íŽ˜ì´ì§€ ë‚´ í…Œë§ˆ ì¶”ì¶œ
        found_on_page = 0
        for a in table.select("td.col_type1 a[href*='sise_group_detail.naver']"):
            href = a.get("href", "")
            # ì˜ˆ: /sise/sise_group_detail.naver?type=theme&no=575
            m = re.search(r"no=(\d+)", href)
            if not m:
                continue
            
            theme_id = m.group(1)
            name = a.get_text(strip=True)
            if not name:
                continue
                
            if theme_id in seen_ids:
                continue

            seen_ids.add(theme_id)
            all_themes.append({"theme_id": theme_id, "theme_name": name})
            found_on_page += 1

        # ë‹¤ìŒ íŽ˜ì´ì§€ íŒë‹¨ ë¡œì§
        # ë„¤ì´ë²„ í…Œë§ˆ íŽ˜ì´ì§€ëŠ” ë³´í†µ 7~8íŽ˜ì´ì§€ ì •ë„ìž…ë‹ˆë‹¤.
        # ë§¨ ë’¤ íŽ˜ì´ì§€ ë²„íŠ¼ì´ í˜„ìž¬ íŽ˜ì´ì§€ë³´ë‹¤ ìž‘ê±°ë‚˜ ê°™ìœ¼ë©´ ì¢…ë£Œ
        pg_last = soup.select_one("td.pgRR a")
        
        if found_on_page == 0:
            break
            
        print(f"  - Page {page}: {found_on_page}ê°œ í…Œë§ˆ ë°œê²¬")
        
        # ë§ˆì§€ë§‰ íŽ˜ì´ì§€ ì²´í¬ (pgRR íƒœê·¸ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ íŽ˜ì´ì§€ìž„)
        if not pg_last:
            break
            
        # ì•ˆì „ìž¥ì¹˜: 20íŽ˜ì´ì§€ ë„˜ì–´ê°€ë©´ ê°•ì œ ì¢…ë£Œ (ë¬´í•œë£¨í”„ ë°©ì§€)
        if page >= 20:
            break
            
        page += 1
        time.sleep(0.2) # íŽ˜ì´ì§€ ë„˜ê¹€ ê°„ ë§¤ë„ˆ ë”œë ˆì´

    print(f"ðŸ“Œ ì „ì²´ í…Œë§ˆ ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_themes)}ê°œ í…Œë§ˆ")
    return all_themes

def _fetch_stocks_for_theme(theme_id: str, theme_name: str) -> List[Dict]:
    """
    ê°œë³„ í…Œë§ˆ íŽ˜ì´ì§€ì—ì„œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    """
    url = f"https://finance.naver.com/sise/sise_group_detail.naver?type=theme&no={theme_id}"
    res = _safe_get(url, timeout=10)
    if res is None:
        return []
    res.encoding = "euc-kr"

    soup = BeautifulSoup(res.text, "lxml")
    records: List[Dict] = []

    for a in soup.select("a[href*='/item/main.naver?code=']"):
        name = a.get_text(strip=True)
        if not name: continue
        
        href = a.get("href", "")
        m = re.search(r"code=(\d+)", href)
        if not m: continue
        
        code = m.group(1).zfill(6)
        records.append({
            "code": code,
            "name": name,
            "naver_label": theme_name,
        })

    if records:
        # ì¢…ëª© ì¤‘ë³µ ì œê±° (í˜¹ì‹œë‚˜ í•´ì„œ)
        seen_code = set()
        unique_records = []
        for r in records:
            if r['code'] not in seen_code:
                seen_code.add(r['code'])
                unique_records.append(r)
        return unique_records
        
    return []

def save_naver_themes(ref_date: date) -> Path:
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜: ì „ì²´ í…Œë§ˆ ìˆ˜ì§‘ -> ì „ì²´ ì¢…ëª© ë§¤í•‘ -> ì €ìž¥
    """
    # 1. ì „ì²´ í…Œë§ˆ ë¦¬ìŠ¤íŠ¸ í™•ë³´ (ëž­í‚¹ ë¬´ê´€)
    themes = _fetch_theme_list_all_pages()
    
    if not themes:
        raise RuntimeError("ë„¤ì´ë²„ í…Œë§ˆ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    all_records: List[Dict] = []
    
    print(f"ðŸš€ ê°œë³„ í…Œë§ˆ ìƒì„¸ ìˆ˜ì§‘ ì‹œìž‘ (ëŒ€ìƒ: {len(themes)}ê°œ)...")
    
    # 2. ê° í…Œë§ˆë³„ êµ¬ì„± ì¢…ëª© ìˆ˜ì§‘
    for idx, t in enumerate(themes, 1):
        tid = t["theme_id"]
        tname = t["theme_name"]
        
        try:
            stocks = _fetch_stocks_for_theme(tid, tname)
            all_records.extend(stocks)
            
            # ì§„í–‰ ìƒí™© ë¡œê¹… (ë„ˆë¬´ ë§Žìœ¼ë‹ˆ 10ê°œ ë‹¨ìœ„ë¡œ)
            if idx % 10 == 0:
                print(f"  [{idx}/{len(themes)}] '{tname}' ë“± ìˆ˜ì§‘ ì¤‘...")
                
            time.sleep(0.05) # ì„œë²„ ë¶€í•˜ ë°©ì§€ìš© ë¯¸ì„¸ ë”œë ˆì´
            
        except Exception as e:
            print(f"[WARN] í…Œë§ˆ {tname}({tid}) ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    if not all_records:
        raise RuntimeError("ë„¤ì´ë²„ í…Œë§ˆ ì¢…ëª©ì„ í•˜ë‚˜ë„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # 3. ë°ì´í„° ì €ìž¥
    df = pd.DataFrame(all_records).drop_duplicates()
    
    out_dir = Path("iceage") / "data" / "raw"
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / f"naver_themes_{ref_date.isoformat()}.csv"
    
    df.to_csv(path, index=False, encoding="utf-8-sig")

    print("\n" + "="*50)
    print(f"âœ… ë„¤ì´ë²„ í…Œë§ˆ ì „ì²´ ì „ìˆ˜ ì¡°ì‚¬ ì™„ë£Œ")
    print(f"ðŸ“‚ ì €ìž¥ ê²½ë¡œ: {path}")
    print(f"ðŸ“Š ì´ ìˆ˜ì§‘ëœ ë§¤í•‘: {len(df)} rows (í…Œë§ˆ-ì¢…ëª© ìŒ)")
    print("="*50 + "\n")
    
    return path

if __name__ == "__main__":
    if len(sys.argv) >= 2:
        ref = date.fromisoformat(sys.argv[1])
    else:
        ref = date.today()
    save_naver_themes(ref)