from datetime import date
from datetime import timedelta as _timedelta, datetime as _dt
from typing import List, Optional, Dict, Any

import numpy as np
import pandas as pd

import json
from pathlib import Path

from iceage.src.data_sources.kr_prices import load_normalized_prices
from iceage.src.data_sources.signalist_today import SignalRow


def _find_col(df: pd.DataFrame, candidates) -> str | None:
    for c in candidates:
        if c in df.columns:
            return c
    return None


# --- ë‚´ë¶€ ì´ë²¤íŠ¸(íšŒì‚¬ ì´ìŠˆ) íƒœê¹…ìš© í—¬í¼ë“¤ ---

# (íƒœê·¸ëª…, [í‚¤ì›Œë“œë“¤]) ë¦¬ìŠ¤íŠ¸
EVENT_TAG_RULES: List[tuple[str, list[str]]] = [
    # 1) ì‹¤ì /ê°€ì´ë˜ìŠ¤
    (
        "ì‹¤ì /ê°€ì´ë˜ìŠ¤",
        [
            "ì‹¤ì ",
            "ì‹¤ì ë°œí‘œ",
            "ì‹¤ì  ë°œí‘œ",
            "ì ì •ì‹¤ì ",
            "ì ì • ì‹¤ì ",
            "ì–´ë‹ ì„œí”„ë¼ì´ì¦ˆ",
            "ì–´ë‹ ì„œí”„",
            "ì–´ë‹ ì‡¼í¬",
            "ë§¤ì¶œ",
            "ë§¤ì¶œì•¡",
            "ì˜ì—…ì´ìµ",
            "ìˆœì´ìµ",
            "í‘ì ì „í™˜",
            "ì ì ì „í™˜",
            "guidance",
            "ê°€ì´ë˜ìŠ¤",
            "ì‹¤ì  ì „ë§",
            "ì‹¤ì  ì¶”ì •",
        ],
    ),

    # 2) ë§¤ì¶œ/ìˆ˜ì£¼ ì„±ì¥(íƒ‘ë¼ì¸ ë“œë¼ì´ë²„)
    (
        "ë§¤ì¶œ/ìˆ˜ì£¼ ì„±ì¥",
        [
            "ìˆ˜ì£¼ ì¦ê°€",
            "ìˆ˜ì£¼ ì„±ì¥",
            "ìˆ˜ì£¼ í™•ëŒ€",
            "ìˆ˜ì£¼ ì”ê³ ",
            "backlog",
            "ìˆ˜ì£¼ì”ê³ ",
            "ë§¤ì¶œ ì„±ì¥",
            "ë§¤ì¶œ ì¦ê°€",
            "ë§¤ì¶œ í™•ëŒ€",
        ],
    ),

    # 3) ê³µê¸‰ê³„ì•½/ì¥ê¸° ê³„ì•½/ê³µì‹œ
    (
        "ê³µê¸‰ê³„ì•½/ìˆ˜ì£¼ ê³µì‹œ",
        [
            "ê³µê¸‰ê³„ì•½",
            "ê³µê¸‰ ê³„ì•½",
            "ì¥ê¸° ê³µê¸‰",
            "ì¥ê¸°ê³„ì•½",
            "ì¥ê¸° ê³„ì•½",
            "ìˆ˜ì£¼",
            "ëŒ€ê·œëª¨ ìˆ˜ì£¼",
            "ìˆ˜ì£¼ ê³µì‹œ",
            "ê³„ì•½ ì²´ê²°",
            "ê³„ì•½ì„ ì²´ê²°",
            "ê³„ì•½ì„ ë§º",
            "ì–‘í•´ê°ì„œ",
            "mou ì²´ê²°",
            "mouë¥¼ ì²´ê²°",
            "loi",
            "ì…ì°°",
            "ë‚™ì°°",
            "ê³µì‹œ",
        ],
    ),

    # 4) M&A/ì§€ë¶„ ì¸ìˆ˜Â·ë§¤ê°
    (
        "M&A/ì§€ë¶„ ê±°ë˜",
        [
            "ì¸ìˆ˜í•©ë³‘",
            "ì¸ìˆ˜ í•©ë³‘",
            "m&a",
            "í•©ë³‘",
            "ë¶„í• í•©ë³‘",
            "ë¶„í•  í•©ë³‘",
            "í¡ìˆ˜í•©ë³‘",
            "ì§€ë¶„ ì¸ìˆ˜",
            "ì§€ë¶„ ì·¨ë“",
            "ê²½ì˜ê¶Œ ë¶„ìŸ",
            "ê²½ì˜ê¶Œ í™•ë³´",
            "ê²½ì˜ê¶Œ ë§¤ê°",
            "ì§€ë¶„ ë§¤ê°",
            "ì§€ë¶„ ì²˜ë¶„",
        ],
    ),

    # 5) ê²½ì˜ê¶Œ/ì˜¤ë„ˆÂ·ì§€ë°°êµ¬ì¡°
    (
        "ê²½ì˜ê¶Œ/ì§€ë°°êµ¬ì¡° ì´ìŠˆ",
        [
            "ìµœëŒ€ì£¼ì£¼ ë³€ê²½",
            "ìµœëŒ€ ì£¼ì£¼ ë³€ê²½",
            "ì˜¤ë„ˆ ë¦¬ìŠ¤í¬",
            "ì˜¤ë„ˆ ë¦¬ìŠ¤í¬",
            "ì§€ë°°êµ¬ì¡° ê°œì„ ",
            "ì§€ë°° êµ¬ì¡° ê°œì„ ",
            "ì§€ë°°êµ¬ì¡° ê°œí¸",
            "ì§€ë°° êµ¬ì¡° ê°œí¸",
            "ê²½ì˜ ì°¸ì—¬",
            "ê²½ì˜ê¶Œ ì°¸ì—¬",
        ],
    ),

    # 6) ì¦ì/CB/BW ë“± ìë³¸ ì¡°ë‹¬
    (
        "ì¦ì/CB/BW ìê¸ˆì¡°ë‹¬",
        [
            "ìœ ìƒì¦ì",
            "ë¬´ìƒì¦ì",
            "ìœ ìƒ ì¦ì",
            "ë¬´ìƒ ì¦ì",
            "ì „í™˜ì‚¬ì±„",
            "cb ë°œí–‰",
            "ì „í™˜ ì‚¬ì±„",
            "ì‹ ì£¼ ë°œí–‰",
            "ì‹ ì£¼ì¸ìˆ˜ê¶Œë¶€ì‚¬ì±„",
            "ì‹ ì£¼ì¸ìˆ˜ê¶Œ",
            "bw ë°œí–‰",
            "ì‚¬ëª¨ì±„ ë°œí–‰",
            "íšŒì‚¬ì±„ ë°œí–‰",
        ],
    ),

    # 7) ìì‚¬ì£¼/ë°°ë‹¹/ì£¼ì£¼í™˜ì›
    (
        "ë°°ë‹¹/ìì‚¬ì£¼/ì£¼ì£¼í™˜ì›",
        [
            "ë°°ë‹¹",
            "í˜„ê¸ˆë°°ë‹¹",
            "í˜„ê¸ˆ ë°°ë‹¹",
            "ì¤‘ê°„ë°°ë‹¹",
            "ë¶„ê¸°ë°°ë‹¹",
            "íŠ¹ë³„ë°°ë‹¹",
            "ë°°ë‹¹ê¸ˆ",
            "ë°°ë‹¹ ì •ì±…",
            "ìì‚¬ì£¼ ì·¨ë“",
            "ìì‚¬ì£¼ ë§¤ì…",
            "ìì‚¬ì£¼ ì†Œê°",
            "ì£¼ì£¼í™˜ì›",
            "ì£¼ì£¼ í™˜ì›",
            "ë°°ë‹¹ì„±í–¥",
        ],
    ),

    # 8) ì‹ ì‚¬ì—…/í”Œë«í¼/AI
    (
        "ì‹ ì‚¬ì—…/í”Œë«í¼/AI",
        [
            "ì‹ ì‚¬ì—…",
            "ì‹ ê·œ ì‚¬ì—…",
            "ìƒˆë¡œìš´ ì‚¬ì—…",
            "í”Œë«í¼",
            "í”Œë«í¼ ì¶œì‹œ",
            "í”Œë«í¼ ì‚¬ì—…",
            "ai ì‚¬ì—…",
            "ì¸ê³µì§€ëŠ¥ ì„œë¹„ìŠ¤",
            "ai í”Œë«í¼",
            "ë°ì´í„° í”Œë«í¼",
            "í´ë¼ìš°ë“œ ì‚¬ì—…",
        ],
    ),

    # 9) ì‹ ì œí’ˆ/ì„œë¹„ìŠ¤ ì¶œì‹œ
    (
        "ì‹ ì œí’ˆ/ì„œë¹„ìŠ¤ ì¶œì‹œ",
        [
            "ì‹ ì œí’ˆ",
            "ì‹ ê·œ ì œí’ˆ",
            "ì‹ ê·œ ì„œë¹„ìŠ¤",
            "ì„œë¹„ìŠ¤ ì¶œì‹œ",
            "ì¶œì‹œ",
            "ë¡ ì¹­",
            "ëŸ°ì¹­",
            "ì‹ ê·œ ë¼ì¸ì—…",
            "ì‹ ê·œ ë¼ì¸ ì—…",
            "ì—…ê·¸ë ˆì´ë“œ ë²„ì „",
        ],
    ),

    # 10) ì„ìƒ/í—ˆê°€/ì˜ì•½í’ˆ ì´ìŠˆ
    (
        "ì„ìƒ/í—ˆê°€ ì´ìŠˆ",
        [
            "ì„ìƒ",
            "ì„ìƒ 1ìƒ",
            "ì„ìƒ1ìƒ",
            "ì„ìƒ 2ìƒ",
            "ì„ìƒ2ìƒ",
            "ì„ìƒ 3ìƒ",
            "ì„ìƒ3ìƒ",
            "ì„ìƒì‹œí—˜",
            "ì„ìƒ ì‹œí—˜",
            "í’ˆëª©í—ˆê°€",
            "í’ˆëª© í—ˆê°€",
            "í—ˆê°€ ì·¨ë“",
            "í—ˆê°€ ì‹ ì²­",
            "ìŠ¹ì¸ ì‹ ì²­",
            "fda ìŠ¹ì¸",
            "fda í—ˆê°€",
            "fda ì‹¬ì‚¬",
            "ì‹ ì•½ í—ˆê°€",
            "ì‹ ì•½ ìŠ¹ì¸",
            "ì‹ ì•½ í›„ë³´",
        ],
    ),

    # 11) íŠ¹í—ˆ/ê¸°ìˆ  ê°œë°œ
    (
        "íŠ¹í—ˆ/ê¸°ìˆ  ê°œë°œ",
        [
            "íŠ¹í—ˆ ì¶œì›",
            "íŠ¹í—ˆ ë“±ë¡",
            "íŠ¹í—ˆ ì·¨ë“",
            "ê¸°ìˆ  ì´ì „",
            "ê¸°ìˆ ì´ì „",
            "ê³µë™ ì—°êµ¬",
            "ê³µë™ì—°êµ¬",
            "ê¸°ìˆ  ì œíœ´",
            "ê¸°ìˆ ì œíœ´",
            "ì•Œê³ ë¦¬ì¦˜ ê°œë°œ",
            "í”Œë«í¼ ê¸°ìˆ ",
        ],
    ),

    # 12) ê·œì œ/ì œì¬/í–‰ì •ì¡°ì¹˜
    (
        "ê·œì œ/ì œì¬/í–‰ì •ì¡°ì¹˜",
        [
            "ì œì¬",
            "ì§•ê³„",
            "ì˜ì—…ì •ì§€",
            "ì˜ì—… ì •ì§€",
            "ê³¼ì§•ê¸ˆ",
            "í–‰ì •ì§€ë„",
            "í–‰ì • ì œì¬",
            "ì œì¬ ì‹¬ì˜",
            "ê¸ˆìœµê°ë…ì›",
            "ê¸ˆê°ì›",
            "ê³µì •ê±°ë˜ìœ„ì›íšŒ",
            "ê³µì •ìœ„",
            "ì¡°ì‚¬ ì°©ìˆ˜",
        ],
    ),

    # 13) ì†Œì†¡/ë²•ì  ë¦¬ìŠ¤í¬
    (
        "ì†Œì†¡/ë²•ì  ë¦¬ìŠ¤í¬",
        [
            "ì†Œì†¡",
            "ì†Œì†¡ì „",
            "ì†Œì†¡ ì „",
            "ì§‘ë‹¨ì†Œì†¡",
            "ì§‘ë‹¨ ì†Œì†¡",
            "ì†í•´ë°°ìƒ ì²­êµ¬",
            "ì†Œì†¡ ì œê¸°",
            "ì†Œì†¡ì„ ì œê¸°",
            "ì†Œì†¡ì„ ë‹¹",
            "ì†Œì†¡ ì·¨í•˜",
            "ê°€ì²˜ë¶„",
            "ë²•ì›",
        ],
    ),

    # 14) ìƒì‚°/ì„¤ë¹„ ì¦ì„¤Â·ì¤‘ë‹¨
    (
        "ìƒì‚°/ì„¤ë¹„ ì¦ì„¤Â·ì¤‘ë‹¨",
        [
            "ì¦ì„¤",
            "ë¼ì¸ ì¦ì„¤",
            "ê³µì¥ ì¦ì„¤",
            "ìƒì‚°ëŠ¥ë ¥ í™•ëŒ€",
            "ì¦ì‚°",
            "ìƒì‚° ì¤‘ë‹¨",
            "ê°€ë™ ì¤‘ë‹¨",
            "ê°€ë™ ì¬ê°œ",
            "ê³µì¥ ê°€ë™",
            "ë¼ì¸ ê°€ë™",
            "ì„¤ë¹„ íˆ¬ì",
            "capex",
        ],
    ),

    # 15) ì›ì¬ë£Œ/ê³µê¸‰ë§/ê°€ê²© ì´ìŠˆ
    (
        "ì›ì¬ë£Œ/ê³µê¸‰ë§ ì´ìŠˆ",
        [
            "ì›ì¬ë£Œ ê°€ê²©",
            "ì›ìì¬ ê°€ê²©",
            "ì›ì¬ë£Œ ìƒìŠ¹",
            "ì›ì¬ë£Œ í•˜ë½",
            "ê³µê¸‰ë§",
            "supply chain",
            "ê³µê¸‰ ì°¨ì§ˆ",
            "ê³µê¸‰ ì¤‘ë‹¨",
            "ìˆ˜ê¸‰ ë¶ˆì•ˆ",
            "ìˆ˜ê¸‰ ì°¨ì§ˆ",
        ],
    ),

    # 16) ê²½ì˜ì§„/ì¡°ì§ë³€ê²½/ì¸ì‚¬
    (
        "ê²½ì˜ì§„/ì¡°ì§ê°œí¸",
        [
            "ëŒ€í‘œì´ì‚¬ êµì²´",
            "ëŒ€í‘œì´ì‚¬ ì„ ì„",
            "ëŒ€í‘œì´ì‚¬ í•´ì„",
            "ëŒ€í‘œì´ì‚¬ ë³€ê²½",
            "ceo êµì²´",
            "ceo ì„ ì„",
            "ê²½ì˜ì§„ êµì²´",
            "ê²½ì˜ì§„ ê°œí¸",
            "ì¡°ì§ ê°œí¸",
            "ì¡°ì§ê°œí¸",
            "ì„ì› ì¸ì‚¬",
            "ì„ì› ì¸ì‚¬ ë‹¨í–‰",
        ],
    ),

    # 17) ESG/ì•ˆì „/ì‚¬ê³ 
    (
        "ESG/ì•ˆì „/ì‚¬ê³  ì´ìŠˆ",
        [
            "í™˜ê²½ ì˜¤ì—¼",
            "í™˜ê²½ì˜¤ì—¼",
            "í™˜ê²½ ê·œì œ",
            "esg",
            "íƒ„ì†Œì¤‘ë¦½",
            "íƒ„ì†Œ ì¤‘ë¦½",
            "ì˜¨ì‹¤ê°€ìŠ¤",
            "ì‚°ì—…ì¬í•´",
            "ì‚°ì¬",
            "í™”ì¬",
            "ê³µì¥ í™”ì¬",
            "ì‚¬ê³  ë°œìƒ",
        ],
    ),

    # 18) IR/ì»¨í¼ëŸ°ìŠ¤ì½œ/íˆ¬ìì ì†Œí†µ
    (
        "IR/ì»¨ì½œ/íˆ¬ìì ì†Œí†µ",
        [
            "ir",
            "ir í–‰ì‚¬",
            "ir ë¯¸íŒ…",
            "ì»¨í¼ëŸ°ìŠ¤ì½œ",
            "ì»¨ì½œ",
            "ê¸°ì—…ì„¤ëª…íšŒ",
            "ê¸°ì—… ì„¤ëª…íšŒ",
            "ndr",
            "non deal roadshow",
            "ì• ë„ë¦¬ìŠ¤íŠ¸ ë¯¸íŒ…",
        ],
    ),

    # 19) ë¦¬í¬íŠ¸/ëª©í‘œê°€ ì¡°ì •
    (
        "ë¦¬í¬íŠ¸/ëª©í‘œê°€ ì¡°ì •",
        [
            "íˆ¬ìì˜ê²¬",
            "íˆ¬ì ì˜ê²¬",
            "ëª©í‘œê°€ ìƒí–¥",
            "ëª©í‘œê°€ í•˜í–¥",
            "ëª©í‘œì£¼ê°€ ìƒí–¥",
            "ëª©í‘œì£¼ê°€ í•˜í–¥",
            "ëª©í‘œ ì£¼ê°€",
            "ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸",
            "ë¦¬í¬íŠ¸ ë°œí‘œ",
        ],
    ),

    # 20) ê¸°íƒ€ í…Œë§ˆ/ë£¨ë¨¸ì„± ì´ìŠˆ
    (
        "í…Œë§ˆ/ë£¨ë¨¸ì„± ì´ìŠˆ",
        [
            "ë£¨ë¨¸",
            "í’ë¬¸",
            "ì‹œì¥ ë£¨ë¨¸",
            "í…Œë§ˆì£¼",
            "ê´€ë ¨ì£¼",
            "ìˆ˜í˜œì£¼",
            "ê´€ë ¨ ì£¼",
            "ìˆ˜í˜œ ì£¼",
        ],
    ),
]



def _parse_event_published_at(value: str) -> Optional[date]:
    """
    kr_news_cleaner ê°€ ë§Œë“¤ì–´ ë‘” published_at ë¬¸ìì—´ì„ date ë¡œ íŒŒì‹±í•œë‹¤.

    - ISO í˜•ì‹(2025-11-09 ë˜ëŠ” 2025-11-09T...)ì´ë©´ ê·¸ëŒ€ë¡œ íŒŒì‹±
    - "11/09/2025, 02:20 AM, +0000 UTC" ê°™ì€ í˜•ì‹ë„ ì§€ì›
    - ì‹¤íŒ¨í•˜ë©´ None ë°˜í™˜ (ì´ ê²½ìš° í•´ë‹¹ ë‰´ìŠ¤ëŠ” ë‚ ì§œ ê¸°ì¤€ í•„í„°ë§ì—ì„œ ì œì™¸)
    """
    if not value:
        return None
    value = str(value).strip()
    from datetime import datetime as _dt

    # 1) ISO í˜•íƒœ ìš°ì„  ì‹œë„
    try:
        v = value.replace("Z", "+00:00")
        return _dt.fromisoformat(v).date()
    except Exception:
        pass

    # 2) "11/09/2025, 02:20 AM, +0000 UTC" í˜•íƒœ
    try:
        if value.endswith(" UTC"):
            value2 = value[:-4]
        else:
            value2 = value
        dt = _dt.strptime(value2, "%m/%d/%Y, %I:%M %p, %z")
        return dt.date()
    except Exception:
        return None


def _load_stock_event_news(
    ref_date: date,
    window_days: int = 7,
) -> tuple[Dict[str, List[Dict[str, Any]]], Dict[str, List[Dict[str, Any]]]]:
    """
    kr_news_cleaned_{date}.jsonl ì—ì„œ kind == 'stock_event' ì¸ ë‰´ìŠ¤ë§Œ
    ì¢…ëª© code / name ê¸°ì¤€ìœ¼ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜.

    window_days:
        published_at ê¸°ì¤€ ref_date Â± window_days ì•ˆì— ìˆëŠ” ê¸°ì‚¬ë§Œ ì‚¬ìš©.
        (ë‚ ì§œë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìœ¼ë©´ í’ˆì§ˆ ê´€ì ì—ì„œ ê³¼ê°íˆ ìŠ¤í‚µ)
    """
    base = Path("iceage") / "data" / "processed"
    path = base / f"kr_news_cleaned_{ref_date.isoformat()}.jsonl"

    events_by_code: Dict[str, List[Dict[str, Any]]] = {}
    events_by_name: Dict[str, List[Dict[str, Any]]] = {}

    if not path.exists():
        return events_by_code, events_by_name

    with path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                obj: Dict[str, Any] = json.loads(line)
            except Exception:
                continue

            if obj.get("kind") != "stock_event":
                continue

            pub_raw = obj.get("published_at") or ""
            pub_date = _parse_event_published_at(pub_raw)
            if pub_date is None:
                # ë‚ ì§œë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë©´ í’ˆì§ˆ ê´€ì ì—ì„œ ê³¼ê°íˆ ìŠ¤í‚µ
                continue

            if abs((pub_date - ref_date).days) > window_days:
                # ref_date Â± window_days ë°–ì´ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                continue

            code = obj.get("code")
            name = obj.get("name")

            if code:
                events_by_code.setdefault(str(code), []).append(obj)
            if name:
                events_by_name.setdefault(str(name), []).append(obj)

    return events_by_code, events_by_name


def _infer_internal_event_tag(items: List[Dict[str, Any]]) -> str:
    """
    í•œ ì¢…ëª©ì— ëŒ€í•´ ëª¨ì¸ ì—¬ëŸ¬ ê°œì˜ stock_event ë‰´ìŠ¤(items)ë¥¼ ë³´ê³ 
    'ë‚´ë¶€ ì´ë²¤íŠ¸'ìš© íƒœê·¸ í•œ ì¤„ì„ ìƒì„±í•œë‹¤.

    ê¸°ì¡´: íƒœê·¸ê°€ í•˜ë‚˜ë¼ë„ ê±¸ë¦¬ë©´ Trueë§Œ ë³´ê³  EVENT_TAG_RULES ìˆœì„œëŒ€ë¡œ ì‚¬ìš©
    ë³€ê²½: ê° íƒœê·¸ê°€ ê¸°ì‚¬ë“¤ì—ì„œ ëª‡ ë²ˆ ë“±ì¥í–ˆëŠ”ì§€ "ë¹ˆë„"ë¥¼ ì„¸ê³ ,
          ë§ì´ ë“±ì¥í•œ íƒœê·¸ ìˆœìœ¼ë¡œ ìƒìœ„ 2ê°œë§Œ ì„ íƒ.

    - íƒœê·¸ ìŠ¤ì½”ì–´ = (í•´ë‹¹ íƒœê·¸ í‚¤ì›Œë“œê°€ ê±¸ë¦° ê¸°ì‚¬ ê°œìˆ˜)
    - ìŠ¤ì½”ì–´ê°€ ë™ì¼í•˜ë©´ EVENT_TAG_RULES ì •ì˜ ìˆœì„œë¥¼ ìš°ì„ 
    - ìµœì¢…ì ìœ¼ë¡œëŠ” ìƒìœ„ 2ê°œ íƒœê·¸ë¥¼ " / "ë¡œ join
    - ì•„ë¬´ íƒœê·¸ë„ ì•ˆ ê±¸ë¦¬ë©´ "" ë°˜í™˜
    """
    if not items:
        return ""

    texts: List[str] = []
    for art in items:
        parts = [
            str(art.get("title", "")),
            str(art.get("snippet", "")),
            str(art.get("summary", "")),
        ]
        texts.append(" ".join(parts).lower())

    # íƒœê·¸ë³„ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
    tag_counts: Dict[str, int] = {tag: 0 for tag, _ in EVENT_TAG_RULES}

    # ê¸°ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ëŒë©´ì„œ ê° íƒœê·¸ê°€ ëª‡ ë²ˆ ë“±ì¥í–ˆëŠ”ì§€ ì§‘ê³„
    for doc in texts:
        for tag, keywords in EVENT_TAG_RULES:
            if any(kw.lower() in doc for kw in keywords):
                tag_counts[tag] += 1

    # 1ë²ˆë„ ì•ˆ ê±¸ë¦° íƒœê·¸ëŠ” ë²„ë¦¼
    tag_items = [(tag, cnt) for tag, cnt in tag_counts.items() if cnt > 0]
    if not tag_items:
        return ""

    # EVENT_TAG_RULES ìƒì˜ ì›ë˜ ìˆœì„œë¥¼ tie-breakerë¡œ ì‚¬ìš©
    tag_index: Dict[str, int] = {tag: i for i, (tag, _) in enumerate(EVENT_TAG_RULES)}

    # 1) ë§ì´ ë“±ì¥í•œ íƒœê·¸ ìš°ì„   2) ê·¸ë‹¤ìŒ ê·œì¹™ ì •ì˜ ìˆœì„œ
    tag_items.sort(key=lambda x: (-x[1], tag_index[x[0]]))

    # ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ìƒìœ„ 2ê°œë§Œ
    top_tags = [tag for tag, _ in tag_items[:2]]
    return " / ".join(top_tags)



def _build_internal_event_map(
    ref_date: date,
    window_days: int = 7,
) -> Dict[str, str]:
    """
    code / name ê¸°ì¤€ìœ¼ë¡œ "ë‚´ë¶€ ì´ë²¤íŠ¸ íƒœê·¸"ë¥¼ ë§¤í•‘í•œ dictë¥¼ ë§Œë“ ë‹¤.

    ë°˜í™˜ ì˜ˆ:
        {
            "005930": "ì‹¤ì /ì–´ë‹ ì´ìŠˆ",
            "ì‚¼ì„±ì „ì": "ì‹¤ì /ì–´ë‹ ì´ìŠˆ",
            ...
        }
    """
    events_by_code, events_by_name = _load_stock_event_news(ref_date, window_days)
    tag_by_key: Dict[str, str] = {}

    # ì½”ë“œ ê¸°ì¤€
    for code, items in events_by_code.items():
        tag = _infer_internal_event_tag(items)
        if tag:
            tag_by_key[code] = tag

    # ì´ë¦„ ê¸°ì¤€ (codeë¡œ ì´ë¯¸ ì±„ì›Œì§„ ê±´ ë®ì–´ì“°ì§€ ì•ŠìŒ)
    for name, items in events_by_name.items():
        tag = _infer_internal_event_tag(items)
        if tag and name not in tag_by_key:
            tag_by_key[name] = tag

    return tag_by_key



def detect_signals_from_prices(ref_date: date, top_n: int | None = None) -> List[SignalRow]:
    """
    ref_date ê¸°ì¤€ í•œêµ­ ì£¼ì‹ ì‹œì„¸ì—ì„œ
    'ì˜¤ëŠ˜ ì‹œì¥ ë‚´ì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ê±°ë˜ëŒ€ê¸ˆê³¼ ê°€ê²© ì›€ì§ì„ì´ í° ì¢…ëª©'ì„ ì„ ë³„í•œë‹¤.

    - ê±°ë˜ëŒ€ê¸ˆ(ê°€ê²©Ã—ê±°ë˜ëŸ‰)ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ë©´ z-score(vol_sigma)ë¥¼ ê³„ì‚°
    - ETF/ETN/ë¦¬ì¸ /ì¸ë²„ìŠ¤/ë ˆë²„ë¦¬ì§€ ë“±ì€ ì œì™¸
    - ì €ìœ ë™ì„±(ê±°ë˜ëŒ€ê¸ˆ í•˜ìœ„ êµ¬ê°„)ì€ ìœ ë‹ˆë²„ìŠ¤ì—ì„œ ì œì™¸

    top_n:
      Noneì´ë©´ ì¡°ê±´ì„ í†µê³¼í•œ ëª¨ë“  ì¢…ëª©ì„ ë°˜í™˜í•˜ê³ ,
      ì •ìˆ˜ê°€ ì£¼ì–´ì§€ë©´ ê·¸ ê°œìˆ˜ë§Œí¼ score ìƒìœ„ ì¢…ëª©ë§Œ ë°˜í™˜í•œë‹¤.
    """

    df = load_normalized_prices(ref_date).copy()
    if df.empty:
        return []

    # 0) ê¸°ë³¸ ì»¬ëŸ¼ íƒìƒ‰
    name_col = _find_col(df, ["name", "ì¢…ëª©ëª…"])
    code_col = _find_col(df, ["code", "ì¢…ëª©ì½”ë“œ", "ticker"])
    price_col = _find_col(df, ["close", "í˜„ì¬ê°€", "ì¢…ê°€"])
    vol_col = _find_col(df, ["volume", "ê±°ë˜ëŸ‰", "VOL", "vol"])
    value_col = _find_col(df, ["trading_value", "amount", "value", "ê±°ë˜ëŒ€ê¸ˆ"])

    if name_col is None or price_col is None or vol_col is None:
        return []

    df[name_col] = df[name_col].astype(str)

    # 1) ETF/ETN/ë¦¬ì¸ /ì¸ë²„ìŠ¤/ë ˆë²„ë¦¬ì§€/ì•¡í‹°ë¸Œ ETF ë“± ì§€ìˆ˜í˜• ìƒí’ˆ ì œì™¸
    etf_keywords = [
        "KODEX",
        "TIGER",
        "KINDEX",
        "ACE",
        "ARIRANG",
        "HANARO",
        "SOL ",
        "ì¸ë²„ìŠ¤",
        "ë ˆë²„ë¦¬ì§€",
        "ì„ ë¬¼",
        "TRF",
        "ETN",
        "ë¦¬ì¸ ",
        "REITs",
        "ETF",
        "ì•¡í‹°ë¸Œ",
        "TIMEFOLIO",
    ]
    etf_pattern = "|".join(etf_keywords)
    df = df[~df[name_col].str.contains(etf_pattern, regex=True, case=False, na=False)].copy()
    if df.empty:
        return []

    # 2) ê±°ë˜ëŒ€ê¸ˆ ê³„ì‚°/ì •ë¦¬
    if value_col is None:
        price_clean = df[price_col].astype(str).str.replace(",", "", regex=False)
        price_clean = pd.to_numeric(price_clean, errors="coerce")

        vol_clean = df[vol_col].astype(str).str.replace(",", "", regex=False)
        vol_clean = pd.to_numeric(vol_clean, errors="coerce")

        df["trading_value"] = price_clean * vol_clean
        value_col = "trading_value"
    else:
        df[value_col] = df[value_col].astype(str).str.replace(",", "", regex=False)
        df[value_col] = pd.to_numeric(df[value_col], errors="coerce")

    df = df.dropna(subset=[value_col])
    if df.empty:
        return []

    # 3) ìœ ë™ì„± í•„í„°: ê±°ë˜ëŒ€ê¸ˆ ë„ˆë¬´ ì‘ì€ ì¢…ëª© ì»·
    abs_floor = 5e8  # 5ì–µ
    q40 = df[value_col].quantile(0.4)
    liquidity_cut = max(abs_floor, q40)
    df = df[df[value_col] >= liquidity_cut].copy()
    if df.empty:
        return []

    # 4) ê±°ë˜ëŒ€ê¸ˆ ë‹¨ë©´ z-score ê³„ì‚° (log scale)
    log_v = np.log1p(df[value_col].astype(float))
    mu = log_v.mean()
    sigma = log_v.std(ddof=0)
    if sigma <= 0:
        df["vol_sigma"] = 0.0
    else:
        df["vol_sigma"] = (log_v - mu) / sigma

    df["vol_sigma_abs"] = df["vol_sigma"].abs()

    # 5) ì¼ê°„ ë“±ë½ë¥  ê³„ì‚°
    ret_col = _find_col(
        df,
        [
            "ret_1d",
            "return_1d",
            "pct_change",
            "chg_pct",
            "change_pct",
            "ë“±ë½ë¥ ",
        ],
    )

    if ret_col is not None:
        if df[ret_col].dtype == "O":
            tmp = (
                df[ret_col]
                .astype(str)
                .str.replace("%", "", regex=False)
                .str.replace("+", "", regex=False)
                .str.replace(",", "", regex=False)
            )
            ret_series = pd.to_numeric(tmp, errors="coerce") / 100.0
        else:
            ret_series = pd.to_numeric(df[ret_col], errors="coerce")
    else:
        ret_series = pd.Series(0.0, index=df.index)

    df["__ret__"] = ret_series
    df = df.dropna(subset=["__ret__"])
    if df.empty:
        return []

    # 6) ê°€ê²©/ê±°ë˜ëŒ€ê¸ˆ ì›€ì§ì„ í•„í„° + ìµœì†Œ 5ê°œ í™•ë³´
    ret_abs = df["__ret__"].abs()
    vol_abs = df["vol_sigma_abs"]

    def _filter(r_min: float, v_min: float) -> pd.DataFrame:
        return df[(ret_abs >= r_min) & (vol_abs >= v_min)].copy()

    candidates = [
        (0.02, 1.0),  # 1ì°¨: 2% ì´ìƒ + 1Ïƒ ì´ìƒ
        (0.015, 0.8),  # 2ì°¨: 1.5% ì´ìƒ + 0.8Ïƒ ì´ìƒ
        (0.01, 0.5),  # 3ì°¨: 1% ì´ìƒ + 0.5Ïƒ ì´ìƒ
        (0.005, 0.0),  # 4ì°¨: 0.5% ì´ìƒ, vol_sigma ì œí•œ ì—†ìŒ
    ]
    df_sel = pd.DataFrame()
    for r_min, v_min in candidates:
        tmp = _filter(r_min, v_min)
        if len(tmp) >= 5:
            df_sel = tmp
            break
        if df_sel.empty or len(tmp) > len(df_sel):
            df_sel = tmp

    df = df_sel
    if df.empty:
        return []

    # 7) ìˆ˜ê¸‰ ì‹¬ë¦¬ ì ìˆ˜/ë¼ë²¨
    # - ê°€ê²© ë“±ë½ë¥ (__ret__)ê³¼ ê±°ë˜ëŒ€ê¸ˆ z-score(vol_sigma)ë¥¼ ì„ì–´ì„œ
    #   [-2, 2] êµ¬ê°„ì˜ 'sentiment_score'ë¥¼ ë§Œë“¤ê³ ,
    #   ì´ë¥¼ 5ë‹¨ê³„ ë¼ë²¨ë¡œ ë³€í™˜í•œë‹¤.
    ret = df["__ret__"].astype(float)
    z = df["vol_sigma"].astype(float)

    # 3% ë“±ë½ â†’ ê°ì • 1ë‹¨ê³„, 2Ïƒ â†’ ê°ì • 1ë‹¨ê³„ ì •ë„ë¡œ ìŠ¤ì¼€ì¼ë§
    comp_ret = np.clip(ret / 0.03, -1.0, 1.0)
    comp_z = np.clip(z / 2.0, -1.0, 1.0)

    # ë‘ ì¶•ì„ ë°˜ë°˜ ì„ê³ , [-1, 1] â†’ [-2, 2]ë¡œ í™•ì¥
    sentiment_score = 2.0 * (0.5 * comp_ret + 0.5 * comp_z)
    df["sentiment_score"] = sentiment_score

    def _sentiment_label(s: float) -> str:
        if s >= 1.0:
            return "ğŸ”¥ ê³¼ì—´ ìœ ì…"
        if s >= 0.3:
            return "â¬†ï¸ ìœ ì… ìš°ì„¸"
        if s > -0.3:
            return "âš–ï¸ ê´€ë§"
        if s > -1.0:
            return "â¬‡ï¸ ì´íƒˆ ìš°ì„¸"
        return "â„ï¸ ê³¼ì—´ ì´íƒˆ"

    df["sentiment"] = df["sentiment_score"].apply(_sentiment_label)


    # 8) ì‹œê·¸ë„ í•´ì„ ë¬¸êµ¬
    def _insight(row) -> str:
        r = float(row["__ret__"])
        z = float(row["vol_sigma"])

        if r >= 0.02 and z >= 1.0:
            return (
                "ê°€ê²©ê³¼ ê±°ë˜ëŒ€ê¸ˆì´ ë™ì‹œì— í‰ê· ì„ ëšœë ·í•˜ê²Œ ìƒíšŒí•˜ëŠ” ìƒìŠ¹ íŒ¨í„´ì…ë‹ˆë‹¤. "
                "ë‹¨ê¸° ìˆ˜ê¸‰ì´ ê³¼ì—´ë  ìˆ˜ ìˆì–´ ì¶”ê²© ë§¤ìˆ˜ ì‹œ ë³€ë™ì„± ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            )
        if r <= -0.02 and z >= 1.0:
            return (
                "ê±°ë˜ëŒ€ê¸ˆì´ ë™ë°˜ëœ í•˜ë½ êµ¬ê°„ì…ë‹ˆë‹¤. ì†ì ˆÂ·íˆ¬ë§¤ ë˜ëŠ” ì•…ì¬ í•´ì„ êµ¬ê°„ì¼ ìˆ˜ ìˆì–´ "
                "ê´€ë ¨ ë‰´ìŠ¤Â·ê³µì‹œë¥¼ í•¨ê»˜ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
            )
        if r > 0 and z < 0:
            return (
                "ê±°ë˜ëŒ€ê¸ˆ ì¦ê°€ ì—†ì´ ì¡°ìš©íˆ ìš°ìƒí–¥í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤. ê¸°ê´€Â·ì™¸êµ­ì¸ì˜ "
                "ì²œì²œíˆ ìŒ“ì´ëŠ” ìˆ˜ê¸‰ì¼ ìˆ˜ ìˆì–´ ì¤‘ê¸°ì ì¸ íë¦„ì„ ì ê²€í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
            )
        if r < 0 and z < 0:
            return (
                "ê°€ê²©ê³¼ ê±°ë˜ëŒ€ê¸ˆì´ ëª¨ë‘ ìœ„ì¶•ëœ êµ¬ê°„ì…ë‹ˆë‹¤. ë‹¨ê¸° ê´€ì‹¬ë„ëŠ” ë‚®ì§€ë§Œ, "
                "ê³¼ë„í•œ ì €í‰ê°€ êµ¬ê°„ì´ ì•„ë‹Œì§€ ì²´í¬í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        return (
            "ê°€ê²©ê³¼ ê±°ë˜ëŒ€ê¸ˆì´ í‰ê·  ëŒ€ë¹„ ì˜ë¯¸ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì›€ì§ì¸ ì¢…ëª©ì…ë‹ˆë‹¤. "
            "ì„¸ë¶€ ì¬ë£Œì™€ ìˆ˜ê¸‰ ì›ì¸ì„ ì¶”ê°€ë¡œ ì ê²€í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
        )

    df["insight"] = df.apply(_insight, axis=1)

    # 9) ì‹œê·¸ë„ ìœ í˜• íƒœê·¸ (íŒ¨í„´ íƒœê·¸) â€“ ë‚´ë¶€ ì´ë²¤íŠ¸ì™€ëŠ” ë³„ê°œ
    def _pattern_tag(row) -> str:
        r = float(row["__ret__"])
        z = float(row["vol_sigma"])

        if r >= 0.05 and z >= 2.0:
            return "ê°•í•œ ìˆ˜ê¸‰ ìƒìŠ¹"
        if r <= -0.05 and z >= 2.0:
            return "ê±°ë˜ëŒ€ê¸ˆ ë™ë°˜ ê¸‰ë½"
        if z >= 2.0:
            return "ê±°ë˜ëŒ€ê¸ˆ ê¸‰ì¦"
        if r > 0.01 and z <= 0.0:
            return "ì¡°ìš©í•œ ìƒìŠ¹"
        if r < -0.01 and z <= 0.0:
            return "ì¡°ìš©í•œ í•˜ë½"
        return "ìˆ˜ê¸‰ íŒ¨í„´ ìœ ì˜"

    df["event_tag"] = df.apply(_pattern_tag, axis=1)

    # 10) ìŠ¤ì½”ì–´
    df["score"] = df["vol_sigma_abs"] * 2.0 + df["__ret__"].abs()

    # 11) ê°€ê²© ìˆ«ìí™”
    df[price_col] = df[price_col].astype(str).str.replace(",", "", regex=False)
    df[price_col] = pd.to_numeric(df[price_col], errors="coerce")
    df = df.dropna(subset=[price_col])
    if df.empty:
        return []

    # 12) ìµœì¢… ì •ë ¬ + top_n ì ìš©
    df_sorted = df.sort_values("score", ascending=False)
    if top_n is not None:
        df_sorted = df_sorted.head(top_n)

    # 13) ë‚´ë¶€ ì´ë²¤íŠ¸ íƒœê·¸ (ì¢…ëª© ì´ë²¤íŠ¸ ë‰´ìŠ¤ ê¸°ë°˜: code ìš°ì„ , name fallback)
    internal_event_map = _build_internal_event_map(ref_date)

    picks: List[SignalRow] = []
    for _, r in df_sorted.iterrows():
        name_val = str(r[name_col])
        code_str = None
        if code_col is not None and code_col in df.columns:
            code_str = str(r[code_col])

        # code -> name ìˆœìœ¼ë¡œ ë‚´ë¶€ ì´ë²¤íŠ¸ íƒœê·¸ ë§¤ì¹­
        internal_event = ""
        if code_str:
            internal_event = internal_event_map.get(code_str, "")
        if not internal_event:
            internal_event = internal_event_map.get(name_val, "")

        row_obj = SignalRow(
            name=name_val,
            close=int(r[price_col]),
            vol_sigma=float(r["vol_sigma"]),
            sentiment=str(r["sentiment"]),
            event=internal_event,  # ë‚´ë¶€ ì´ë²¤íŠ¸
            insight=str(r["insight"]),
        )

        # íŒ¨í„´ íƒœê·¸ëŠ” ë³„ë„ ì†ì„±ìœ¼ë¡œ (ì‹œê·¸ë„ ìœ í˜•)
        setattr(row_obj, "pattern_tag", str(r.get("event_tag", "")))

        # ì½”ë“œë„ ê°™ì´ ë‹¬ì•„ë‘ê¸° (íˆìŠ¤í† ë¦¬/ë‰´ìŠ¤ ë§¤í•‘ìš©)
        if code_str:
            setattr(row_obj, "code", code_str)

        picks.append(row_obj)

    return picks


from typing import List

def select_featured_signals(signals: List["SignalRow"], k: int = 5) -> List["SignalRow"]:
    """
    Universe ì‹œê·¸ë„ë“¤ ì¤‘ì—ì„œ ë‰´ìŠ¤ë ˆí„°/ê³µì‹ ë¡œê·¸ì— ì‹¤ë¦´ 5ê°œë¥¼ ê³ ë¥¸ë‹¤.

    ì—¬ê¸°ì„œëŠ” detect_signals_from_pricesê°€
    "ì´ë¯¸ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸"ë¥¼ ì¤€ë‹¤ê³  ê°€ì •í•˜ê³ ,

    - Universe: ì „ë‹¬ë°›ì€ signals ì „ì²´ (ì •ë ¬ ìˆœì„œ ìœ ì§€)
    - 1ì°¨ ì„ íƒ: ì•ì—ì„œë¶€í„° kê°œ
    - ì „ë¶€ ê°™ì€ ë°©í–¥(ìƒìŠ¹/í•˜ë½)ì´ë©´:
      * Universe ì „ì²´ì—ì„œ ë°˜ëŒ€ ë°©í–¥(ret_5d ë°˜ëŒ€ ë¶€í˜¸)ì¸ ì¢…ëª©ì„ í•˜ë‚˜ ì°¾ê³ 
      * base ì•ˆì˜ 'ë‹¤ìˆ˜ ë°©í–¥' ì¢…ëª© ì¤‘ ì œì¼ ë’¤ì— ìˆëŠ” ì• ë¥¼ ê·¸ê±¸ë¡œ êµì²´

    ì ìˆ˜ í•„ë“œëŠ” ì“°ì§€ ì•Šê³ , ì •ë ¬ ìˆœì„œ + ret_5d ë°©í–¥ë§Œ ì“´ë‹¤.
    """
    if not signals:
        return []

    # Universe ìˆœì„œëŠ” detect_signals_from_pricesê°€ ì •í•´ì¤€ëŒ€ë¡œ ì‚¬ìš©
    universe = list(signals)
    base = universe[:k]

    def direction(row: "SignalRow") -> int:
        r = getattr(row, "ret_5d", 0.0)
        if r > 0:
            return 1
        if r < 0:
            return -1
        return 0  # ë³´í•©

    dirs = [direction(s) for s in base]
    ups = sum(1 for d in dirs if d > 0)
    downs = sum(1 for d in dirs if d < 0)

    # ì´ë¯¸ ìƒìŠ¹/í•˜ë½ì´ ì„ì—¬ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if ups > 0 and downs > 0:
        return base

    # í•œìª½ìœ¼ë¡œ ëª°ë ¤ ìˆëŠ” ê²½ìš°
    majority_sign = 1 if ups > 0 else -1
    minority_sign = -majority_sign

    # Universe ì „ì²´ì—ì„œ 'ë°˜ëŒ€ ë°©í–¥' í›„ë³´ ì°¾ê¸° (ì •ë ¬ ìˆœì„œ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°•í•œ ì• )
    opposite_pick = None
    for s in universe:
        if direction(s) == minority_sign:
            opposite_pick = s
            break

    # ë°˜ëŒ€ ë°©í–¥ì´ ì•„ì˜ˆ ì—†ìœ¼ë©´(=Universe 10ê°œ ì „ë¶€ ê°™ì€ ë°©í–¥) â†’ ê·¸ëƒ¥ base ë°˜í™˜
    if opposite_pick is None:
        return base

    # base ì•ˆì—ì„œ 'ë‹¤ìˆ˜ ë°©í–¥'ì¸ ì• ë“¤ ì¤‘ ì œì¼ ë’¤ì— ìˆëŠ” ì• ë¥¼ êµì²´ ëŒ€ìƒë¡œ ì„ íƒ
    majority_indices = [i for i, s in enumerate(base) if direction(s) == majority_sign]
    if not majority_indices:
        return base

    weakest_idx = majority_indices[-1]
    base[weakest_idx] = opposite_pick

    return base


# iceage/src/analyzers/signal_volume_pattern.py

from pathlib import Path
from datetime import date
import numpy as np
import pandas as pd

from iceage.src.data_sources.signalist_today import SignalRow

# ì´ë¯¸ ìœ„ìª½ì— EVENT_TAG_RULES, _build_internal_event_map ë“± ì¡´ì¬í•¨
# :contentReference[oaicite:2]{index=2}

DATA_PROCESSED_DIR = Path("iceage") / "data" / "processed"


def detect_signals_from_volume_anomaly_v2(
    ref_date: date,
    use_top_bucket_only: bool = True,
) -> list[SignalRow]:
    """
    volume_anomaly_v2ì—ì„œ ë½‘ì€ CSVë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ë‰´ìŠ¤ë ˆí„°ìš© SignalRow ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ ì¤€ë‹¤.
    """

    ref_str = ref_date.isoformat()
    path = DATA_PROCESSED_DIR / f"volume_anomaly_v2_{ref_str}.csv"
    if not path.exists():
        raise FileNotFoundError(f"{path} ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € volume_anomaly_v2ë¥¼ ëŒë ¤ì£¼ì„¸ìš”.")

    df = pd.read_csv(path)

    # 1) ìœ ë‹ˆë²„ìŠ¤ ì„ íƒ: ì²´ê¸‰ë³„ ìƒìœ„ ë²„í‚·ë§Œ ì‚¬ìš©
    if use_top_bucket_only and "is_top_bucket" in df.columns:
        df = df[df["is_top_bucket"] == True].copy()

    if df.empty:
        return []

    # ì •ë ¬ ê¸°ì¤€: ì‹œì¥ ëŒ€ë¹„ ê´´ë¦¬(tv_z_rel)ê°€ í° ìˆœìœ¼ë¡œ
    sort_col = "tv_z_rel" if "tv_z_rel" in df.columns else "tv_z"
    df = df.sort_values(sort_col, ascending=False)

    # 2) ìˆ˜ìµë¥ /ê±°ë˜ëŒ€ê¸ˆ z-score ê¸°ë°˜ sentiment_score ê³„ì‚°
    # change_rateëŠ” ë³´í†µ %ë¼ê³  ê°€ì • â†’ 100ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì†Œìˆ˜í™”
    ret = pd.to_numeric(df["change_rate"], errors="coerce") / 100.0
    z = pd.to_numeric(df["tv_z"], errors="coerce")  # v1ì˜ vol_sigma ì—­í• 

    comp_ret = np.clip(ret / 0.03, -1.0, 1.0)  # 3% ë“±ë½ì„ ê¸°ì¤€ 1ë‹¨ê³„ë¡œ
    comp_z = np.clip(z / 2.0, -1.0, 1.0)       # 2Ïƒë¥¼ ê¸°ì¤€ 1ë‹¨ê³„ë¡œ
    sentiment_score = 2.0 * (0.5 * comp_ret + 0.5 * comp_z)

    def _sentiment_label(s: float) -> str:
        if s >= 1.0:
            return "ğŸ”¥ ê³¼ì—´ ìœ ì…"
        if s >= 0.3:
            return "â¬†ï¸ ìœ ì… ìš°ì„¸"
        if s > -0.3:
            return "âš–ï¸ ê´€ë§"
        if s > -1.0:
            return "â¬‡ï¸ ì´íƒˆ ìš°ì„¸"
        return "â„ï¸ ê³¼ì—´ ì´íƒˆ"

    df["sentiment_score"] = sentiment_score
    df["sentiment"] = df["sentiment_score"].apply(_sentiment_label)

    # 3) íŒ¨í„´ íƒœê·¸ + insight ë¬¸êµ¬ (v1 ë¡œì§ì„ ê·¸ëŒ€ë¡œ ì˜®ê¹€)
    def _insight(row) -> str:
        r = float(row.get("ret_1d", row["change_rate"] / 100.0))
        z = float(row["tv_z"])

        if r >= 0.02 and z >= 1.0:
            return (
                "ê°€ê²©ê³¼ ê±°ë˜ëŒ€ê¸ˆì´ ë™ì‹œì— í‰ê· ì„ ëšœë ·í•˜ê²Œ ìƒíšŒí•˜ëŠ” ìƒìŠ¹ íŒ¨í„´ì…ë‹ˆë‹¤. "
                "ë‹¨ê¸° ìˆ˜ê¸‰ì´ ê³¼ì—´ë  ìˆ˜ ìˆì–´ ì¶”ê²© ë§¤ìˆ˜ ì‹œ ë³€ë™ì„± ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            )
        if r <= -0.02 and z >= 1.0:
            return (
                "ê±°ë˜ëŒ€ê¸ˆì´ ë™ë°˜ëœ í•˜ë½ êµ¬ê°„ì…ë‹ˆë‹¤. ì†ì ˆÂ·íˆ¬ë§¤ ë˜ëŠ” ì•…ì¬ í•´ì„ êµ¬ê°„ì¼ ìˆ˜ ìˆì–´ "
                "ê´€ë ¨ ë‰´ìŠ¤Â·ê³µì‹œë¥¼ í•¨ê»˜ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
            )
        if r > 0 and z < 0:
            return (
                "ê±°ë˜ëŒ€ê¸ˆ ì¦ê°€ ì—†ì´ ì¡°ìš©íˆ ìš°ìƒí–¥í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤. ê¸°ê´€Â·ì™¸êµ­ì¸ì˜ "
                "ì²œì²œíˆ ìŒ“ì´ëŠ” ìˆ˜ê¸‰ì¼ ìˆ˜ ìˆì–´ ì¤‘ê¸°ì ì¸ íë¦„ì„ ì ê²€í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
            )
        if r < 0 and z < 0:
            return (
                "ê°€ê²©ê³¼ ê±°ë˜ëŒ€ê¸ˆì´ ëª¨ë‘ ìœ„ì¶•ëœ êµ¬ê°„ì…ë‹ˆë‹¤. ë‹¨ê¸° ê´€ì‹¬ë„ëŠ” ë‚®ì§€ë§Œ, "
                "ê³¼ë„í•œ ì €í‰ê°€ êµ¬ê°„ì´ ì•„ë‹Œì§€ ì²´í¬í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        return (
            "ê°€ê²©ê³¼ ê±°ë˜ëŒ€ê¸ˆì´ í‰ê·  ëŒ€ë¹„ ì˜ë¯¸ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì›€ì§ì¸ ì¢…ëª©ì…ë‹ˆë‹¤. "
            "ì„¸ë¶€ ì¬ë£Œì™€ ìˆ˜ê¸‰ ì›ì¸ì„ ì¶”ê°€ë¡œ ì ê²€í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
        )

    def _pattern_tag(row) -> str:
        r = float(row.get("ret_1d", row["change_rate"] / 100.0))
        z = float(row["tv_z"])

        if r >= 0.05 and z >= 2.0:
            return "ê°•í•œ ìˆ˜ê¸‰ ìƒìŠ¹"
        if r <= -0.05 and z >= 2.0:
            return "ê±°ë˜ëŒ€ê¸ˆ ë™ë°˜ ê¸‰ë½"
        if z >= 2.0:
            return "ê±°ë˜ëŒ€ê¸ˆ ê¸‰ì¦"
        if r > 0.01 and z <= 0.0:
            return "ì¡°ìš©í•œ ìƒìŠ¹"
        if r < -0.01 and z <= 0.0:
            return "ì¡°ìš©í•œ í•˜ë½"
        return "ìˆ˜ê¸‰ íŒ¨í„´ ìœ ì˜"

    df["insight"] = df.apply(_insight, axis=1)
    df["event_tag"] = df.apply(_pattern_tag, axis=1)

    # 4) ë‚´ë¶€ ì´ë²¤íŠ¸ íƒœê·¸ (ë‰´ìŠ¤ ê¸°ë°˜) ì¬ì‚¬ìš©
    internal_event_map = _build_internal_event_map(ref_date)

    # 5) SignalRow ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    picks: list[SignalRow] = []
    for _, r in df.iterrows():
        name = str(r["name"])
        code = str(r["code"])
        close = int(r["close"])

        internal_event = internal_event_map.get(code) or internal_event_map.get(name, "")

        row_obj = SignalRow(
            name=name,
            close=close,
            vol_sigma=float(r["tv_z"]),   # v1ì—ì„œ ì“°ë˜ vol_sigma ì—­í• 
            sentiment=str(r["sentiment"]),
            event=internal_event,
            insight=str(r["insight"]),
        )
        setattr(row_obj, "pattern_tag", str(r.get("event_tag", "")))
        setattr(row_obj, "code", code)

        picks.append(row_obj)

    return picks
