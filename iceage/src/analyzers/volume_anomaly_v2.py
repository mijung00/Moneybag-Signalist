# iceage/src/analyzers/volume_anomaly_v2.py

from __future__ import annotations

import sys
from pathlib import Path
from datetime import date, datetime, timedelta
from typing import Dict, Any

import pandas as pd

from iceage.src.data_sources.kr_price_history import (
    load_daily_prices,
    load_price_history,
    load_listing,
)


# -------------------------
# ì „ì—­ ìƒìˆ˜
# -------------------------
MIN_MARKET_CAP_WON = 80_000_000_000  # 800ì–µ (ì› ë‹¨ìœ„)



# í”„ë¡œì íŠ¸ ë£¨íŠ¸ (C:/project/iceage)
PROJECT_ROOT = Path(__file__).resolve().parents[2]
DATA_PROCESSED_DIR = PROJECT_ROOT / "data" / "processed"
DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)


# =========================
# ìœ í‹¸
# =========================

def _parse_ref_date(argv: list[str]) -> date:
    """CLI ì¸ìë¡œ YYYY-MM-DD ë¥¼ ë°›ëŠ”ë‹¤."""
    if len(argv) < 2:
        print(
            "Usage: python -m iceage.src.analyzers.volume_anomaly_v2 YYYY-MM-DD",
            file=sys.stderr,
        )
        sys.exit(1)
    ref_date_str = argv[1]
    return datetime.strptime(ref_date_str, "%Y-%m-%d").date()


def _assign_size_bucket(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì²´ê¸‰ ë²„í‚· ìƒì„± (small / mid / large / unknown).

    - ì‹œì´ 800ì–µ ë¯¸ë§Œ, ETF/ETN/ë¦¬ì¸  ë“±ì€ ì•ì—ì„œ ì´ë¯¸ ì»·ë˜ì—ˆë‹¤ê³  ê°€ì •.
    - ì—¬ê¸°ì„œëŠ” 'avg_trading_value(60ì¼ í‰ê·  ê±°ë˜ëŒ€ê¸ˆ)'ì˜ ëˆ„ì  ë¹„ì¤‘ìœ¼ë¡œ ì²´ê¸‰ì„ ë‚˜ëˆˆë‹¤.

      * large: ëˆ„ì  í‰ê·  ê±°ë˜ëŒ€ê¸ˆ ë¹„ì¤‘ 0.0 ~ 0.5
      * mid  : 0.5 ~ 0.8
      * small: 0.8 ~ 1.0
    """
    if "avg_trading_value" not in df.columns:
        df["size_bucket"] = "unknown"
        return df

    caps = df[["code", "avg_trading_value"]].dropna()
    if caps.empty:
        df["size_bucket"] = "unknown"
        return df

    caps = caps.copy()
    caps["avg_trading_value"] = pd.to_numeric(
        caps["avg_trading_value"], errors="coerce"
    )
    caps = caps.dropna(subset=["avg_trading_value"])
    if caps.empty:
        df["size_bucket"] = "unknown"
        return df

    # í‰ê·  ê±°ë˜ëŒ€ê¸ˆ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    caps = caps.sort_values("avg_trading_value", ascending=False)

    total_tv = caps["avg_trading_value"].sum()
    if total_tv <= 0:
        df["size_bucket"] = "unknown"
        return df

    # ëˆ„ì  ë¹„ì¤‘ (0~1)
    caps["cum_share"] = caps["avg_trading_value"].cumsum() / total_tv

    LARGE_CUTOFF = 0.60  # ìƒìœ„ 60% â†’ large
    MID_CUTOFF = 0.90    # 60~90% â†’ mid, ì´í›„ small

    def _bucket_from_share(cum_share: float) -> str:
        if pd.isna(cum_share):
            return "unknown"
        if cum_share <= LARGE_CUTOFF:
            return "large"
        elif cum_share <= MID_CUTOFF:
            return "mid"
        else:
            return "small"

    caps["size_bucket"] = caps["cum_share"].apply(_bucket_from_share)

    # ì›ë³¸ dfì— size_bucket merge
    df = df.copy()
    df = df.merge(
        caps[["code", "size_bucket"]],
        on="code",
        how="left",
        suffixes=("", "_bucket"),
    )
    df["size_bucket"] = df["size_bucket"].fillna("unknown")

    return df

def _compute_volume_patterns(
    hist: pd.DataFrame,
    ref_date: date,
    window_days: int = 20,
) -> pd.DataFrame:
    """
    ìµœê·¼ window_days ë™ì•ˆì˜ ê±°ë˜ëŸ‰ íŒ¨í„´ì„ ì½”ë“œë³„ë¡œ ë¼ë²¨ë§.

    íŒ¨í„´ ì •ì˜(ì˜ˆì‹œ):
      - steady_accumulation : ìµœê·¼ 5ì¼ vol_z í‰ê·  >= +1.0, ìµœì†Œê°’ > 0
      - sudden_spike        : ì˜¤ëŠ˜ ì§ì „ 10ì¼ max vol_z < +1.0 ì´ë©´ì„œ, ìµœê·¼ì¼ vol_z >= +2.5
      - boom_and_fade       : ìµœê·¼ 5ì¼ ë‚´ max vol_z >= +2.5 ì´ê³ , ìµœê·¼ì¼ vol_z <= 0
      - dead_silent         : 20ì¼ í‰ê·  vol_z <= -0.5 ì´ê³ , 20ì¼ max vol_z < 0
      - ë‚˜ë¨¸ì§€              : normal
    """
    if hist.empty:
        return pd.DataFrame(columns=["code", "pattern_label"])

    # ref_date ì´ì „ ë°ì´í„°ë§Œ ì‚¬ìš©
    past = hist[hist["trade_date"] < ref_date].copy()
    if past.empty:
        return pd.DataFrame(columns=["code", "pattern_label"])

    # ìµœê·¼ window_days ì¼ë§Œ ì‚¬ìš© (ìº˜ë¦°ë” ê¸°ì¤€)
    cutoff = ref_date - timedelta(days=window_days)
    past = past[past["trade_date"] >= cutoff].copy()
    if past.empty:
        return pd.DataFrame(columns=["code", "pattern_label"])

    # ì½”ë“œ/ë‚ ì§œ ìˆœì„œ ì •ë ¬
    past = past.sort_values(["code", "trade_date"]).copy()

    records = []

    for code, g in past.groupby("code"):
        g = g.copy()
        # í‘œì¤€í™”: ê° ì½”ë“œë³„ë¡œ 20ì¼ ê¸°ì¤€ z-score
        vols = g["volume"].astype(float)
        mean_v = vols.mean()
        std_v = vols.std(ddof=0)
        if std_v == 0 or pd.isna(std_v):
            pattern = "unknown"
        else:
            g["vol_z"] = (vols - mean_v) / std_v
            z = g["vol_z"]

            if len(z) < 5:
                pattern = "unknown"
            else:
                last = z.iloc[-1]
                recent5 = z.iloc[-5:]
                prev10 = z.iloc[:-1].iloc[-10:] if len(z) > 1 else pd.Series([], dtype=float)

                # ì¡°ê±´ë“¤
                if (
                    last >= 2.5
                    and (prev10.empty or prev10.max() < 1.0)
                ):
                    pattern = "sudden_spike"
                elif recent5.max() >= 2.5 and last <= 0:
                    pattern = "boom_and_fade"
                elif recent5.mean() >= 1.0 and recent5.min() > 0:
                    pattern = "steady_accumulation"
                elif z.mean() <= -0.5 and z.max() < 0:
                    pattern = "dead_silent"
                else:
                    pattern = "normal"

        records.append({"code": code, "pattern_label": pattern})

    return pd.DataFrame(records)

def _assign_signal_tone(row: pd.Series) -> dict:
    """
    tv_z_rel + change_rate + ì‹œì¥ ë ˆì§ì„ ì´ìš©í•´ì„œ
    ì‹œê·¸ë„ í†¤(ğŸŸ¢/âšª/ğŸ”´)ê³¼ ê°•ë„(0~3)ë¥¼ ì§€ì •.
    """
    tv_rel = row.get("tv_z_rel")
    regime = row.get("market_regime")
    chg = row.get("change_rate")

    try:
        tv_rel = float(tv_rel)
    except Exception:
        tv_rel = float("nan")

    try:
        chg = float(chg) if chg is not None else 0.0
    except Exception:
        chg = 0.0

    # ê¸°ë³¸ê°’
    tone = "âšª"
    strength = 0

    if pd.isna(tv_rel):
        return {"signal_tone": tone, "signal_strength": strength}

    # ê°•í•œ ê´´ë¦¬: tv_z_rel >= 2.0
    if tv_rel >= 2.5:
        # ì´ë¯¸ ë‹¹ì¼ ê¸‰ë“±(ì˜ˆ: +8% ì´ìƒ)ì´ë©´ ê³¼ì—´ ê²½ê³  ëŠë‚Œìœ¼ë¡œ ğŸ”´
        if chg >= 8.0:
            tone = "ğŸ”´"
        else:
            tone = "ğŸŸ¢"
        strength = 3
    elif tv_rel >= 1.5:
        tone = "ğŸŸ¢"
        strength = 2
    elif tv_rel >= 1.0:
        tone = "ğŸŸ¢"
        strength = 1
    elif tv_rel >= 0.5:
        tone = "âšª"
        strength = 1
    else:
        tone = "âšª"
        strength = 0

    # ì‹œì¥ì´ ê³µí¬(panic)ì¸ë° ê°•í•œ ìŒìˆ˜ ìˆ˜ìµë¥ ì´ë©´, ë³´ìˆ˜ì ìœ¼ë¡œ í†¤ì„ í•œ ë‹¨ê³„ ë‚®ì¶œ ìˆ˜ë„ ìˆìŒ
    if regime == "panic" and chg <= -5.0 and strength >= 2:
        strength = max(1, strength - 1)

    return {"signal_tone": tone, "signal_strength": strength}


# =========================
# ì‹œì¥ ë ˆì§ ê³„ì‚°
# =========================

def _compute_market_regime(
    hist: pd.DataFrame,
    today: pd.DataFrame,
    ref_date: date,
) -> Dict[str, Any]:
    """
    ê³¼ê±° íˆìŠ¤í† ë¦¬(hist)ì™€ ì˜¤ëŠ˜ ë°ì´í„°(today)ë¥¼ ì´ìš©í•´
    'ì‹œì¥ ì „ì²´' ê¸°ì¤€ ê±°ë˜ëŒ€ê¸ˆ/ìˆ˜ìµë¥  ë ˆì§ì„ ê³„ì‚°í•œë‹¤.

    ë°˜í™˜ ê°’ ì˜ˆì‹œ:
    {
      "market_tv_today": float,
      "market_tv_mean": float,
      "market_tv_std": float,
      "market_tv_z": float,
      "market_ret_today": float,
      "market_ret_mean": float,
      "market_ret_std": float,
      "market_ret_z": float,
      "market_regime": "panic" | "euphoria" | "calm" | "normal",
    }
    """
    # ê³¼ê±°(ì˜¤ëŠ˜ ì´ì „) ë°ì´í„°ë§Œ ì‚¬ìš©
    past = hist[hist["trade_date"] < ref_date].copy()
    if past.empty:
        # ê³¼ê±° ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë ˆì§ ê³„ì‚° ë¶ˆê°€ â†’ ì „ë¶€ NaN
        return {
            "market_tv_today": float("nan"),
            "market_tv_mean": float("nan"),
            "market_tv_std": float("nan"),
            "market_tv_z": float("nan"),
            "market_ret_today": float("nan"),
            "market_ret_mean": float("nan"),
            "market_ret_std": float("nan"),
            "market_ret_z": float("nan"),
            "market_regime": "unknown",
        }

    # ------------------------
    # 1) ë‚ ì§œë³„ ì‹œì¥ ê±°ë˜ëŒ€ê¸ˆ (ì „ì²´ í•©)
    # ------------------------
    past_tv = (
        past.groupby("trade_date")["trading_value"]
        .sum()
        .rename("market_tv")
        .sort_index()
    )

    tv_mean = past_tv.mean()
    tv_std = past_tv.std()

    tv_today = today["trading_value"].sum()
    if tv_std and tv_std > 0:
        tv_z = (tv_today - tv_mean) / tv_std
    else:
        tv_z = float("nan")

    # ------------------------
    # 2) ë‚ ì§œë³„ ì‹œì¥ ìˆ˜ìµë¥  (ì‹œì´ ê°€ì¤‘ í‰ê· )
    # ------------------------
    # ê³¼ê±°
    past = past.copy()
    # ë‚ ì§œë³„ total mcap
    total_mcap_by_date = (
        past.groupby("trade_date")["market_cap"]
        .sum()
        .rename("total_mcap")
    )
    past = past.merge(total_mcap_by_date, on="trade_date", how="left")

    # weight = ê° ì¢…ëª© ì‹œì´ / ì „ì²´ ì‹œì´
    past["w_mcap"] = past["market_cap"] / past["total_mcap"]

    # ê° ë‚ ì§œë³„ ì‹œì´ ê°€ì¤‘ ìˆ˜ìµë¥ 
    # change_rate ê°€ %, ì†Œìˆ˜ ë“± ì–´ë–¤ í¬ë§·ì¸ì§€ì— ë”°ë¼ í•´ì„ì€ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ
    # ì—¬ê¸°ì„œëŠ” 'ìƒëŒ€ ë¹„êµìš©'ì´ë¯€ë¡œ ì¼ê´€ì„±ë§Œ ë³´ì¥ë˜ë©´ ë¨.
    past_ret = (
        (past["change_rate"] * past["w_mcap"])
        .groupby(past["trade_date"])
        .sum()
        .rename("market_ret")
        .sort_index()
    )

    ret_mean = past_ret.mean()
    ret_std = past_ret.std()

    # ì˜¤ëŠ˜ë„ ê°™ì€ ë°©ì‹ìœ¼ë¡œ
    today = today.copy()
    total_mcap_today = today["market_cap"].sum()
    if total_mcap_today and total_mcap_today > 0:
        today["w_mcap"] = today["market_cap"] / total_mcap_today
        ret_today = float((today["change_rate"] * today["w_mcap"]).sum())
    else:
        ret_today = float("nan")

    if ret_std and ret_std > 0:
        ret_z = (ret_today - ret_mean) / ret_std
    else:
        ret_z = float("nan")

    # ------------------------
    # 3) ì‹œì¥ ë ˆì§ ë¼ë²¨ë§
    # ------------------------
    regime = "normal"

    # ê¸°ì¤€ì€ ëŒ€ëµì ì¸ heuristic (ë‚˜ì¤‘ì— ê²½í—˜ ìŒ“ì´ë©´ì„œ íŠœë‹)
    if not pd.isna(ret_z) and not pd.isna(tv_z):
        if ret_z <= -1.5 and tv_z >= 1.0:
            regime = "panic"      # ê³µí¬/íˆ¬ë§¤
        elif ret_z >= 1.5 and tv_z >= 1.0:
            regime = "euphoria"   # ê³¼ì—´/í™˜í˜¸
        elif abs(ret_z) <= 0.5 and abs(tv_z) <= 0.5:
            regime = "calm"       # ì•„ì£¼ í‰ì˜¨
        else:
            regime = "normal"
    else:
        regime = "unknown"

    return {
        "market_tv_today": float(tv_today),
        "market_tv_mean": float(tv_mean),
        "market_tv_std": float(tv_std if tv_std == tv_std else 0.0),
        "market_tv_z": float(tv_z) if tv_z == tv_z else float("nan"),
        "market_ret_today": float(ret_today),
        "market_ret_mean": float(ret_mean),
        "market_ret_std": float(ret_std if ret_std == ret_std else 0.0),
        "market_ret_z": float(ret_z) if ret_z == ret_z else float("nan"),
        "market_regime": regime,
    }


# =========================
# ê´´ë¦¬ìœ¨ v2 ë©”ì¸ ë¡œì§
# =========================

def run_volume_anomaly_v2(
    ref_date: date,
    window_days: int = 60,
    min_history_days: int = 20,
    top_n_per_bucket: int = 30,
) -> Path:
    """
    ref_date ê¸°ì¤€ìœ¼ë¡œ ìµœê·¼ window_days ì˜ì—…ì¼ì˜ ê±°ë˜ëŒ€ê¸ˆ/ê±°ë˜ëŸ‰ ê´´ë¦¬ìœ¨ì„ ê³„ì‚°í•œë‹¤.

    í•µì‹¬ í¬ì¸íŠ¸:
      - ê°œë³„ ì¢…ëª©ì˜ ê±°ë˜ëŒ€ê¸ˆ ê´´ë¦¬ìœ¨(tv_z)ì„ ìê¸° ê³¼ê±° ëŒ€ë¹„ë¡œ ê³„ì‚°
      - ë™ì‹œì— ì‹œì¥ ì „ì²´ ê±°ë˜ëŒ€ê¸ˆ z-score(market_tv_z)ë¥¼ ê³„ì‚°
      - ì¢…ëª©ë³„ 'ì‹œì¥ ëŒ€ë¹„' z-score: tv_z_rel = tv_z - market_tv_z
      - ì‹œê°€ì´ì•¡ ê¸°ë°˜ ì²´ê¸‰(bucket)ë³„ ìƒìœ„ Nê°œë¥¼ is_top_bucket=Trueë¡œ íƒœê¹…

    ì¶œë ¥:
      - data/processed/volume_anomaly_v2_YYYY-MM-DD.csv
    """

    ref_date_str = ref_date.strftime("%Y-%m-%d")
    print(
        f"[INFO] ê´´ë¦¬ìœ¨ v2 ê³„ì‚° ì‹œì‘: ref_date={ref_date_str}, "
        f"window={window_days}d, min_history_days={min_history_days}"
    )

    # 1) ë°ì´í„° ë¡œë“œ
    hist = load_price_history(ref_date, window_days=window_days)
    today = load_daily_prices(ref_date)
    listing = load_listing(ref_date)

    # 2) ë³´í†µì£¼ í•„í„°ë§ (ë¦¬ìŠ¤íŒ… ê¸°ì¤€)
    listing = listing.copy()
    if "stock_kind" in listing.columns:
        listing = listing[listing["stock_kind"] == "ë³´í†µì£¼"].copy()

    # 3) ì˜¤ëŠ˜ ì‹œì„¸ì— ë¦¬ìŠ¤íŒ… ì •ë³´ ì¡°ì¸ (ì„¹í„° / ìƒì¥ì£¼ì‹ìˆ˜ / ì¢…ëª©êµ¬ë¶„ ë“±)
    merge_cols = [
        "code",
        "stock_kind",
        "sector_name",
        "listed_shares",
        "security_group",  # ETF/ETN/ë¦¬ì¸  ì œê±°ìš©
    ]
    merge_cols = [c for c in merge_cols if c in listing.columns]

    today = today.merge(
        listing[merge_cols].drop_duplicates("code"),
        on="code",
        how="left",
    )

    # í˜¹ì‹œ ì‹œì„¸ ìª½ì— stock_kindê°€ ìˆë‹¤ë©´ ë³´í†µì£¼ë§Œ ì‚¬ìš©
    if "stock_kind" in today.columns:
        today = today[today["stock_kind"] == "ë³´í†µì£¼"].copy()

    # ETF / ETN / ë¦¬ì¸  ì œê±°
    if "security_group" in today.columns:
        etf_like_groups = ["ETF", "ETN", "ë¦¬ì¸ "]
        before_cnt = len(today)
        today = today[~today["security_group"].isin(etf_like_groups)].copy()
        after_cnt = len(today)
        print(f"[INFO] ETF/ETN/ë¦¬ì¸  ì œê±°: {before_cnt} â†’ {after_cnt} ì¢…ëª©")


    # 4) íˆìŠ¤í† ë¦¬ì—ì„œ ë‹¹ì¼(ref_date) ì œê±° í›„, ê³¼ê±° Nì¼ë§Œìœ¼ë¡œ í†µê³„ ê³„ì‚°
    hist_past = hist[hist["trade_date"] < ref_date].copy()
    if hist_past.empty:
        raise RuntimeError(
            f"[ERROR] {ref_date_str} ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±° ë°ì´í„°ê°€ ì—†ì–´ "
            "ê´´ë¦¬ìœ¨ v2ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )

    grouped = hist_past.groupby("code")

    stats = grouped.agg(
        history_days=("trade_date", "nunique"),
        avg_trading_value=("trading_value", "mean"),
        std_trading_value=("trading_value", "std"),
        avg_volume=("volume", "mean"),
        std_volume=("volume", "std"),
    ).reset_index()

    # 5) ì˜¤ëŠ˜ ë°ì´í„° + íˆìŠ¤í† ë¦¬ í†µê³„ ì¡°ì¸
    df = today.merge(
        stats,
        on="code",
        how="left",
        suffixes=("", "_hist"),
    )

    # 5-1) ì‹œì´ í•˜í•œì„  í•„í„° (800ì–µ ë¯¸ë§Œ ì»·)
    if "market_cap" in df.columns:
        df = df.copy()
        df["market_cap"] = pd.to_numeric(df["market_cap"], errors="coerce")
        before_cnt = len(df)
        df = df[df["market_cap"] >= MIN_MARKET_CAP_WON].copy()
        after_cnt = len(df)
        print(
            f"[INFO] ì‹œì´ {MIN_MARKET_CAP_WON:,.0f}ì› ì´ìƒ ì¢…ëª©ë§Œ ì‚¬ìš©: "
            f"{before_cnt} â†’ {after_cnt}"
        )

    # 5-2) ì¶©ë¶„í•œ íˆìŠ¤í† ë¦¬/ê±°ë˜ëŒ€ê¸ˆì´ ì—†ëŠ” ì¢…ëª© ì œì™¸
    df = df[
        (df["history_days"].fillna(0) >= min_history_days)
        & (df["avg_trading_value"].fillna(0) > 0)
    ].copy()

    if df.empty:
        raise RuntimeError(
            f"[ERROR] {ref_date_str} ê¸°ì¤€ìœ¼ë¡œ "
            "ì¡°ê±´(history_days/min_history_days)ì— ë§ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤."
        )

    # 6) ê°œë³„ ì¢…ëª© ê±°ë˜ëŒ€ê¸ˆ ê¸°ì¤€ ê´´ë¦¬ìœ¨ (ë¹„ìœ¨ + z-score)
    # [ê°œì„ ] .apply ëŒ€ì‹  ë²¡í„° ì—°ì‚°ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ ëŒ€í­ í–¥ìƒ
    # ë¶„ëª¨ê°€ 0ì¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ np.divide ì‚¬ìš©
    import numpy as np
    df['tv_ratio'] = np.divide(df['trading_value'], df['avg_trading_value'], 
                             out=np.full_like(df['trading_value'], np.nan, dtype=float), 
                             where=df['avg_trading_value'] > 0)
    
    df['tv_z'] = np.divide(df['trading_value'] - df['avg_trading_value'], df['std_trading_value'],
                         out=np.full_like(df['trading_value'], np.nan, dtype=float),
                         where=df['std_trading_value'] > 0)

    df['vol_ratio'] = np.divide(df['volume'], df['avg_volume'],
                              out=np.full_like(df['volume'], np.nan, dtype=float),
                              where=df['avg_volume'] > 0)

    df['vol_z'] = np.divide(df['volume'] - df['avg_volume'], df['std_volume'],
                          out=np.full_like(df['volume'], np.nan, dtype=float),
                          where=df['std_volume'] > 0)

    # 7) ì‹œì¥ ë ˆì§ ê³„ì‚° (ì „ì²´ ì‹œì¥ ê¸°ì¤€)
    market_info = _compute_market_regime(hist, today, ref_date)
    market_tv_z = market_info.get("market_tv_z")

    # 8) ì‹œì¥ ëŒ€ë¹„ ê´´ë¦¬ìœ¨ (tv_z_rel)
    if not pd.isna(market_tv_z):
        df["tv_z_rel"] = df["tv_z"] - market_tv_z
    else:
        # ì‹œì¥ z-scoreê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ tv_z ê·¸ëŒ€ë¡œ ì‚¬ìš©
        df["tv_z_rel"] = df["tv_z"]

    # 9) ì‹œê°€ì´ì•¡ ê¸°ë°˜ ì²´ê¸‰ (small/mid/large)
    df = _assign_size_bucket(df)

    # 10) ë­í‚¹ ê³„ì‚° (ì‹œì¥ ëŒ€ë¹„ tv_z_rel ê¸°ì¤€)
    df = df.sort_values("tv_z_rel", ascending=False)
    df["rank_overall"] = df["tv_z_rel"].rank(method="dense", ascending=False)

    # ì²´ê¸‰ë³„ ë­í‚¹
    df["rank_in_bucket"] = df.groupby("size_bucket")["tv_z_rel"].rank(
        method="dense", ascending=False
    )

    # ìƒìœ„ ì¼ë¶€ë§Œ íƒœê¹… (LLM/ë‰´ìŠ¤ë ˆí„°ì—ì„œ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©)
    df["is_top_bucket"] = df["rank_in_bucket"] <= top_n_per_bucket
    
        # 10-1) ìµœê·¼ 20ì¼ ê±°ë˜ëŸ‰ íŒ¨í„´ ë¼ë²¨ë§
    pattern_df = _compute_volume_patterns(hist, ref_date, window_days=20)
    if not pattern_df.empty:
        df = df.merge(pattern_df, on="code", how="left")
    else:
        df["pattern_label"] = "unknown"

    # 10-2) ì‹œê·¸ë„ í†¤/ê°•ë„ ê³„ì‚°
    tone_info = df.apply(_assign_signal_tone, axis=1, result_type="expand")
    df["signal_tone"] = tone_info["signal_tone"]
    df["signal_strength"] = tone_info["signal_strength"]


    # 11) ë©”íƒ€ ì •ë³´(ì‹œì¥ ë ˆì§)ë¥¼ ëª¨ë“  í–‰ì— ë¶™ì´ê¸°
    df["market_tv_today"] = market_info.get("market_tv_today")
    df["market_tv_mean"] = market_info.get("market_tv_mean")
    df["market_tv_std"] = market_info.get("market_tv_std")
    df["market_tv_z"] = market_info.get("market_tv_z")

    df["market_ret_today"] = market_info.get("market_ret_today")
    df["market_ret_mean"] = market_info.get("market_ret_mean")
    df["market_ret_std"] = market_info.get("market_ret_std")
    df["market_ret_z"] = market_info.get("market_ret_z")

    df["market_regime"] = market_info.get("market_regime")
    df["window_days"] = window_days
    df["min_history_days"] = min_history_days

    # 12) ì €ì¥
    out_path = DATA_PROCESSED_DIR / f"volume_anomaly_v2_{ref_date_str}.csv"
    df.to_csv(out_path, index=False, encoding="utf-8-sig")

    total_cnt = len(df)
    top_cnt = int(df["is_top_bucket"].sum())

    print(
        f"[OK] ê´´ë¦¬ìœ¨ v2 ê³„ì‚° ì™„ë£Œ: {ref_date_str} "
        f"(ì „ì²´ {total_cnt}ì¢…ëª©, ì²´ê¸‰ë³„ ìƒìœ„ {top_cnt}ì¢…ëª© is_top_bucket=True)"
    )
    print(
        f"[INFO] ì‹œì¥ ë ˆì§: regime={market_info.get('market_regime')}, "
        f"tv_z={market_info.get('market_tv_z'):.2f} "
        f"ret_z={market_info.get('market_ret_z'):.2f}"
        if not pd.isna(market_info.get("market_tv_z"))
        and not pd.isna(market_info.get("market_ret_z"))
        else f"[INFO] ì‹œì¥ ë ˆì§ ê³„ì‚° ë¶ˆê°€ (ë°ì´í„° ë¶€ì¡±)"
    )
    print(f"[OK] ì €ì¥ ê²½ë¡œ: {out_path}")

    return out_path


def main():
    ref_date = _parse_ref_date(sys.argv)
    run_volume_anomaly_v2(ref_date)


if __name__ == "__main__":
    main()
