# iceage/src/analyzers/signalist_history_analyzer.py
import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
from pathlib import Path
import sys

PROJECT_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from iceage.src.data_sources.kr_price_history import load_daily_prices

BASE_DIR = PROJECT_ROOT / "iceage"
PROCESSED_DIR = BASE_DIR / "data" / "processed"
HISTORY_LOG_PATH = PROCESSED_DIR / "signalist_today_log.csv"

def _to_date(d):
    if isinstance(d, date): return d
    try: return datetime.strptime(str(d).split()[0], "%Y-%m-%d").date()
    except: return date.today()

def _normalize_code(code_val):
    try: return str(int(float(code_val))).zfill(6)
    except: return str(code_val).strip().zfill(6)

def _load_signalist_log():
    if not HISTORY_LOG_PATH.exists(): return pd.DataFrame()
    try: df = pd.read_csv(HISTORY_LOG_PATH, encoding="utf-8-sig")
    except: return pd.DataFrame()

    if "ref_date" not in df.columns and "signal_date" in df.columns:
        df = df.rename(columns={"signal_date": "ref_date"})
    if "ref_date" not in df.columns: return pd.DataFrame()

    df["ref_date"] = pd.to_datetime(df["ref_date"]).dt.date
    if "code" in df.columns: df["code"] = df["code"].apply(_normalize_code)
    return df

def _parse_signal_direction(sentiment):
    s = str(sentiment)
    if "ë§¤ìˆ˜" in s or "ìœ ì…" in s or "ìƒìŠ¹" in s: return 1
    if "ë§¤ë„" in s or "ì´íƒˆ" in s or "í•˜ë½" in s or "ê³¼ì—´" in s: return -1
    return 0

def _get_market_return(start_date: date, end_date: date) -> float:
    """KOSPI ì§€ìˆ˜ ê¸°ì¤€ ê¸°ê°„ ìˆ˜ìµë¥  ê³„ì‚°"""
    try:
        path = PROJECT_ROOT / "iceage" / "data" / "raw" / "kr_market_index.csv"
        if not path.exists(): return 0.0
        
        df = pd.read_csv(path)
        df['date'] = pd.to_datetime(df['date']).dt.date
        
        start_row = df[(df['date'] == start_date) & (df['market'] == 'KOSPI')]
        end_row = df[(df['date'] == end_date) & (df['market'] == 'KOSPI')]
        
        if start_row.empty or end_row.empty: return 0.0
        
        start_val = float(start_row.iloc[0]['close'])
        end_val = float(end_row.iloc[0]['close'])
        
        if start_val == 0: return 0.0
        return (end_val - start_val) / start_val * 100
    except:
        return 0.0

def _attach_current_price(log_df: pd.DataFrame, ref_d: date) -> pd.DataFrame:
    if log_df.empty: return log_df
    price_today = load_daily_prices(ref_d)
    if price_today.empty: return log_df

    price_today = price_today[["code", "close"]].copy()
    price_today["code"] = price_today["code"].astype(str).str.zfill(6)
    price_today = price_today.rename(columns={"close": "current_price"})

    df = log_df.merge(price_today, on="code", how="left")
    if "close" in df.columns: df = df.rename(columns={"close": "entry_price"})
    else: df["entry_price"] = pd.NA

    df["current_price"] = pd.to_numeric(df["current_price"], errors="coerce")
    df["entry_price"] = pd.to_numeric(df["entry_price"], errors="coerce")
    
    df["raw_return"] = (df["current_price"] - df["entry_price"]) / df["entry_price"] * 100
    return df

def build_signalist_history_context(ref_date: date, lookback_days: int = 120) -> dict:
    ref_d = _to_date(ref_date)
    log_df = _load_signalist_log()
    
    empty = {"ref_date": ref_d, "n_signals": 0, "periods": {}, "top_movers": []}
    if log_df.empty: return empty

    min_d = ref_d - timedelta(days=lookback_days)
    subset = log_df[(log_df["ref_date"] < ref_d) & (log_df["ref_date"] >= min_d)].copy()
    if subset.empty: return empty

    subset = _attach_current_price(subset, ref_d)
    subset = subset.dropna(subset=["raw_return", "entry_price", "current_price"])
    if subset.empty: return empty

    subset["direction"] = subset["sentiment"].apply(_parse_signal_direction)
    subset["strat_return"] = subset.apply(
        lambda r: r["raw_return"] if r["direction"] == 1 else (-r["raw_return"] if r["direction"] == -1 else 0), 
        axis=1
    )
    subset["is_win"] = subset["strat_return"] > 0
    subset["days_elapsed"] = (ref_d - subset["ref_date"]).apply(lambda x: x.days)

    # [1] ê¸°ê°„ë³„ ì„±ê³¼
    periods = {}
    for label, (d_min, d_max) in {
        "D+5 (1ì£¼ì°¨)": (3, 7),
        "D+15 (2~3ì£¼)": (10, 20),
        "D+30 (1ë‹¬+)": (25, 45)
    }.items():
        mask = (subset["days_elapsed"] >= d_min) & (subset["days_elapsed"] <= d_max)
        p_df = subset[mask]
        if not p_df.empty:
            win_rate = p_df["is_win"].mean() * 100
            avg_ret = p_df["strat_return"].mean()
            periods[label] = {"win": win_rate, "ret": avg_ret, "count": len(p_df)}

    # [2] Best Calls (ì¤‘ë³µ ì œê±° & ì‹ êµ¬ ì¡°í™”)
    # A. ì ì¤‘í•œ ê²ƒë§Œ í•„í„°ë§
    win_candidates = subset[(subset["direction"] != 0) & (subset["strat_return"] > 0)].copy()
    
    # B. ì¤‘ë³µ ì œê±° (ê°™ì€ ì¢…ëª©ì´ë©´ ìˆ˜ìµë¥ ì´ ê°€ì¥ ë†’ì€ 1ê°œë§Œ ë‚¨ê¹€)
    win_candidates = win_candidates.sort_values("strat_return", ascending=False)
    win_candidates = win_candidates.drop_duplicates(subset=["code"], keep="first")

    final_picks = []

    # C. ì „ëµì  ì„ ë°œ (Legend 3 + Rising 2)
    if not win_candidates.empty:
        # 1) Rising Stars: ìµœê·¼ 20ì¼ ì´ë‚´ í¬ì°©ëœ ë†ˆ ì¤‘ ë² ìŠ¤íŠ¸
        recent_mask = win_candidates["days_elapsed"] <= 20
        rising_candidates = win_candidates[recent_mask].head(2) # ìµœëŒ€ 2ê°œ
        
        # 2) Hall of Fame: ì „ì²´ ê¸°ê°„ ì¤‘ ë² ìŠ¤íŠ¸ (Risingì— ë½‘íŒ ë†ˆ ì œì™¸)
        rising_codes = set(rising_candidates["code"])
        legend_candidates = win_candidates[~win_candidates["code"].isin(rising_codes)].head(5) # ë„‰ë„‰íˆ ë½‘ìŒ
        
        # 3) ìŠ¬ë¡¯ ì±„ìš°ê¸° (ì´ 5ê°œ)
        # Risingì´ ìˆìœ¼ë©´ ë¨¼ì € ë„£ê³ , ë‚˜ë¨¸ì§€ëŠ” Legendë¡œ ì±„ì›€
        final_picks.extend(rising_candidates.to_dict('records'))
        
        needed = 5 - len(final_picks)
        final_picks.extend(legend_candidates.head(needed).to_dict('records'))
        
        # 4) ë‹¤ì‹œ ìˆ˜ìµë¥  ìˆœ ì •ë ¬ (ë³´ì—¬ì¤„ ë•ŒëŠ” 1ë“±ë¶€í„°)
        final_picks.sort(key=lambda x: x["strat_return"], reverse=True)

    top_movers = []
    for r in final_picks:
        direction_icon = "ğŸ“ˆ ë§¤ìˆ˜" if r["direction"] == 1 else "ğŸ“‰ ë§¤ë„"
        
        # í¬ë§·íŒ…
        perf_str = f"+{r['strat_return']:.1f}%"
        raw_str = f"{r['raw_return']:.1f}%"
        if r["raw_return"] > 0: raw_str = f"+{raw_str}"
        
        top_movers.append({
            "name": r["name"],
            "days": r["days_elapsed"],
            "view": direction_icon,
            "raw_move": raw_str,      
            "profit": perf_str,       
            "ref_date": r["ref_date"],
            "entry_price": r["entry_price"],
            "current_price": r["current_price"]
        })

    return {
        "ref_date": ref_d,
        "n_signals": len(subset),
        "periods": periods,
        "top_movers": top_movers
    }

def build_signalist_history_markdown(ref_date: date, lookback_days: int = 90) -> str:
    ctx = build_signalist_history_context(ref_date, lookback_days)
    ref_d = ctx["ref_date"]
    
    if ctx["n_signals"] == 0:
        return f"## Signalist History\n\nì•„ì§ ë¶„ì„í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

    lines = []
    lines.append("## Signalist History")
    lines.append(f"ê¸°ì¤€ì¼: {ref_d}")
    lines.append("")
    lines.append("ê³¼ê±° ë ˆì´ë”ì— í¬ì°©ëœ ì¢…ëª©ë“¤ì˜ **ì¶”ì  ê´€ì°° ì„±ê³¼**ì…ë‹ˆë‹¤.")
    lines.append("ë°©í–¥ì„±(ë§¤ìˆ˜/ë§¤ë„)ì´ ì ì¤‘í–ˆì„ ê²½ìš°ì˜ í‰ê·  ìˆ˜ìµë¥ ì„ ì§‘ê³„í•©ë‹ˆë‹¤.")
    lines.append("")

    if ctx["periods"]:
        lines.append("### ğŸ“Š ê²½ê³¼ ê¸°ê°„ë³„ í‰ê·  ì„±ê³¼")
        lines.append("| ê²½ê³¼ ê¸°ê°„ | ì ì¤‘ë¥ (Win Rate) | í‰ê·  ì„±ê³¼ | ìƒ˜í”Œ ìˆ˜ |")
        lines.append("|---|---|---|---|")
        for label, stat in ctx["periods"].items():
            win_str = f"{stat['win']:.1f}%"
            ret_str = f"{stat['ret']:+.1f}%"
            if stat['ret'] > 0: ret_str = f"**{ret_str}** ğŸ”´"
            lines.append(f"| {label} | {win_str} | {ret_str} | {stat['count']} |")
        lines.append("")
        lines.append("ğŸ‘‰ _ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ìˆ˜ìµì´ ëˆ„ì ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. (ì¶”ì„¸ ì¶”ì¢… ê²€ì¦)_")
        lines.append("")

    if ctx["top_movers"]:
        lines.append("### ğŸ† ëª…ì˜ˆì˜ ì „ë‹¹ (Best Calls)")
        lines.append("ë°©í–¥ì„±ì„ ì •í™•íˆ ì˜ˆì¸¡í•˜ì—¬ ë†’ì€ ìˆ˜ìµì„ ë‚¸ ì‚¬ë¡€ì…ë‹ˆë‹¤. (ìµœê·¼ ë° ì—­ëŒ€ ìµœê³ )")
        lines.append("")
        lines.append("| ì¢…ëª©ëª… | í¬ì°© ê²½ê³¼ | ë·°(View) | ê°€ê²© ë³€í™” | ì„±ê³¼ (ì‹œì¥ëŒ€ë¹„) |")
        lines.append("|---|---|---|---|---|")
        
        for r in ctx["top_movers"]:
            entry_price = int(r.get('entry_price', 0))
            curr_price = int(r.get('current_price', 0))
            price_change = f"{entry_price:,} â†’ {curr_price:,}"
            
            market_ret = _get_market_return(r['ref_date'], ref_d)
            try:
                strat_ret = float(r['profit'].replace('%', '').replace('+', ''))
            except: strat_ret = 0.0
                
            alpha = strat_ret - market_ret
            alpha_str = f"{alpha:+.1f}%p"
            if alpha > 0: alpha_str = f"(+{alpha_str})"
            else: alpha_str = f"({alpha_str})"
            
            final_perf = f"**{r['profit']}**<br><small>{alpha_str}</small>"
            
            # New ë±ƒì§€: 20ì¼ ì´ë‚´ë©´ í‘œì‹œ
            badge = "ğŸ†•" if r['days'] <= 20 else ""
            
            lines.append(f"| {r['name']} {badge}| D+{r['days']} | {r['view']} | {price_change} | {final_perf} |")
    else:
        lines.append("### ìµœê·¼ ì ì¤‘ ì‚¬ë¡€ ì—†ìŒ")
        lines.append("ìµœê·¼ ë³€ë™ì„± êµ¬ê°„ì—ì„œ ìœ ì˜ë¯¸í•œ ì ì¤‘ ì‚¬ë¡€ê°€ ë‚˜ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    lines.append("")
    lines.append("_* ê³¼ê±° ì„±ê³¼ê°€ ë¯¸ë˜ ìˆ˜ìµì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë§¤ë„(Short) ì„±ê³¼ëŠ” í•˜ë½ë¥ ì„ ìˆ˜ìµìœ¼ë¡œ í™˜ì‚°í•œ ê²ƒì…ë‹ˆë‹¤._")
    
    return "\n".join(lines)