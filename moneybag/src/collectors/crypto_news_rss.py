import requests
import xml.etree.ElementTree as ET
from datetime import datetime
from email.utils import parsedate_to_datetime # RSS ë‚ ì§œ íŒŒì‹±ìš©
import html
import re

class CryptoNewsRSS:
    def __init__(self):
        self.rss_feeds = {
            "CoinDesk": "https://www.coindesk.com/arc/outboundfeeds/rss/",
            "CoinTelegraph": "https://cointelegraph.com/rss",
            "TheBlock": "https://www.theblock.co/rss.xml",
            "Decrypt": "https://decrypt.co/feed",
            "BitcoinMagazine": "https://bitcoinmagazine.com/.rss/full/",
            "CryptoSlate": "https://cryptoslate.com/feed/",
            "Blockworks": "https://blockworks.co/feed",
            "CoinGape": "https://coingape.com/feed/"
        }
        
        self.keywords = ["ETF", "SEC", "Fed", "Rate", "Binance", "BlackRock", "Regulation", "Hack", "Approval"]

    def fetch_feed(self, source_name, url):
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=5)
            if response.status_code != 200: return []

            root = ET.fromstring(response.content)
            items = root.findall('./channel/item')
            if not items: items = root.findall('.//item')

            news_list = []
            for item in items[:5]:
                title = item.find('title').text
                link = item.find('link').text
                desc = item.find('description').text
                
                # [NEW] ë‚ ì§œ ì¶”ì¶œ ë° ë³€í™˜
                pub_date_str = ""
                pub_element = item.find('pubDate')
                if pub_element is not None and pub_element.text:
                    try:
                        # RSS í‘œì¤€ ë‚ ì§œ í¬ë§·(RFC 822) íŒŒì‹± -> YYYY-MM-DD HH:MM ë³€í™˜
                        dt = parsedate_to_datetime(pub_element.text)
                        pub_date_str = dt.strftime('%Y-%m-%d %H:%M')
                    except:
                        pub_date_str = pub_element.text[:16] # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©

                if not title: continue
                
                summary = self._clean_html(desc) if desc else ""
                
                score = 0
                for k in self.keywords:
                    if k.lower() in title.lower(): score += 2
                    if k.lower() in summary.lower(): score += 1
                
                news_list.append({
                    "source": source_name,
                    "title": title.strip(),
                    "link": link,
                    "summary": summary[:250].strip() + "...",
                    "score": score,
                    "published_at": pub_date_str # [NEW] ìˆ˜ì§‘ëœ ë‚ ì§œ ì €ì¥
                })
            return news_list
        except:
            return []

    def _clean_html(self, raw_html):
        if not raw_html: return ""
        text = html.unescape(raw_html)
        text = re.sub(r'<[^>]+>', '', text)
        return text.strip()

    def collect_all(self):
        print(f"ğŸŒ ê¸€ë¡œë²Œ ë‰´ìŠ¤ ì†ŒìŠ¤ {len(self.rss_feeds)}ê°œ ìŠ¤ìº” ì¤‘...")
        all_news = []
        for name, url in self.rss_feeds.items():
            print(f"   ğŸ“¡ {name}...", end=" ")
            items = self.fetch_feed(name, url)
            print(f"{len(items)}ê±´")
            all_news.extend(items)
        
        all_news.sort(key=lambda x: x['score'], reverse=True)
        
        seen_links = set()
        unique_news = []
        for news in all_news:
            if news['link'] not in seen_links:
                unique_news.append(news)
                seen_links.add(news['link'])
        
        return unique_news[:10]

if __name__ == "__main__":
    collector = CryptoNewsRSS()
    news = collector.collect_all()
    for n in news[:3]:
        print(f"[{n['published_at']}] {n['title']}")