# iceage/src/pipelines/weekly_report_generator.py
import os
import sys
import json
import re
from pathlib import Path
from datetime import datetime, timedelta
from io import StringIO
import pandas as pd
import boto3

# ê²½ë¡œ ì„¤ì •
try:
    PROJECT_ROOT = Path(__file__).resolve().parents[3]
except IndexError:
    PROJECT_ROOT = Path.cwd()
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

from common.s3_manager import S3Manager
from iceage.src.llm.openai_driver import _chat

def analyze_weekly_signals(df: pd.DataFrame, end_date: datetime) -> dict:
    """ì§€ë‚œ 7ì¼ê°„ì˜ ì‹œê·¸ë„ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    start_date = end_date - timedelta(days=7)
    df['signal_date'] = pd.to_datetime(df['signal_date'])
    
    weekly_df = df[(df['signal_date'] >= start_date) & (df['signal_date'] <= end_date)]
    
    if weekly_df.empty:
        return {"error": "ì§€ë‚œ 7ì¼ê°„ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    # 1. ê°€ì¥ ìì£¼ í¬ì°©ëœ ì¢…ëª© (Top 5)
    top_stocks = weekly_df['name'].value_counts().nlargest(5)
    
    # 2. ë§¤ìˆ˜/ë§¤ë„ ì‹œê·¸ë„ ë¹„ìœ¨
    sentiment_counts = weekly_df['sentiment'].value_counts(normalize=True) * 100
    
    return {
        "top_stocks": top_stocks.to_dict(),
        "sentiment_ratio": sentiment_counts.to_dict()
    }

def generate_llm_commentary(analysis: dict, ref_date: str) -> dict:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì£¼ê°„ ë¦¬í¬íŠ¸ ì½”ë©˜í„°ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not _chat or "error" in analysis:
        return {"title": f"Signalist Weekly ({ref_date})", "summary": "ë°ì´í„° ë¶„ì„ ì¤‘...", "stock_comments": {}}

    top_stocks_str = "\n".join([f"- {name}: {count}íšŒ" for name, count in analysis.get("top_stocks", {}).items()])
    sentiment_str = "\n".join([f"- {sent}: {ratio:.1f}%" for sent, ratio in analysis.get("sentiment_ratio", {}).items()])

    prompt = f"""
    ë‹¹ì‹ ì€ 'The Signalist'ì˜ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ì£¼ê°„ ì‹œê·¸ë„ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì „ë¬¸ì ì´ë©´ì„œë„ í¥ë¯¸ë¡œìš´ ì£¼ê°„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    **ë¶„ì„ ë°ì´í„° (ê¸°ê°„: ì§€ë‚œ 7ì¼):**
    - ê°€ì¥ ìì£¼ í¬ì°©ëœ ì¢…ëª© TOP 5:
    {top_stocks_str}
    - ë§¤ìˆ˜/ë§¤ë„ ì‹œê·¸ë„ ë¹„ìœ¨:
    {sentiment_str}

    **ìš”ì²­ ì‚¬í•­ (JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ):**
    1.  `title`: "ì‹œê·¸ë„ë¡œ ëŒì•„ë³¸ í•œ ì£¼" ì™€ ê°™ì´, í•œ ì£¼ë¥¼ ìš”ì•½í•˜ëŠ” ì°½ì˜ì ì´ê³  ë©‹ì§„ ë¦¬í¬íŠ¸ ì œëª©.
    2.  `summary`: ìœ„ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì§€ë‚œ í•œ ì£¼ê°„ì˜ ì‹œì¥ íŠ¹ì§•ì„ 2~3ë¬¸ë‹¨ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” 'Analyst's View'. (ì˜ˆ: íŠ¹ì • í…Œë§ˆì˜ ë°˜ë³µì ì¸ ë“±ì¥, ì‹œì¥ ì‹¬ë¦¬ì˜ ë³€í™” ë“±)
    3.  `stock_comments`: ê°€ì¥ ìì£¼ í¬ì°©ëœ ê° ì¢…ëª©({', '.join(analysis.get("top_stocks", {}).keys())})ì— ëŒ€í•´, ì™œ ìì£¼ í¬ì°©ë˜ì—ˆì„ì§€ ì¶”ì¸¡í•˜ë©° 1~2ì¤„ì˜ ì§§ì€ ì½”ë©˜íŠ¸. (key: ì¢…ëª©ëª…, value: ì½”ë©˜íŠ¸)

    íˆ¬ì ì¶”ì²œì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤. ë°ì´í„° ê¸°ë°˜ì˜ ê´€ì°°ê³¼ ë¶„ì„ì— ì§‘ì¤‘í•´ì£¼ì„¸ìš”.
    """
    
    system_prompt = "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ê°€ì´ë©°, ìš”ì²­ëœ JSON í˜•ì‹ì— ë§ì¶° ì‘ë‹µí•©ë‹ˆë‹¤."
    
    try:
        response_str = _chat(system_prompt, prompt)
        match = re.search(r'```json\n({.*?})\n```', response_str, re.DOTALL)
        if match:
            response_str = match.group(1)
        return json.loads(response_str)
    except Exception as e:
        print(f"âŒ LLM ì½”ë©˜í„°ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"title": f"Signalist Weekly ({ref_date})", "summary": "AI ì½”ë©˜íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "stock_comments": {}}

def create_weekly_report_md(ref_date: str, s3: S3Manager) -> str:
    """ì£¼ê°„ ë¦¬í¬íŠ¸ ë§ˆí¬ë‹¤ìš´ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    log_key = "iceage/data/processed/signalist_today_log.csv"
    try:
        csv_content = s3.get_text_content(log_key)
        if not csv_content: raise FileNotFoundError("Log file is empty.")
        df = pd.read_csv(StringIO(csv_content))
    except Exception as e:
        return f"# ì—ëŸ¬\n\nì‹œê·¸ë„ ë¡œê·¸ íŒŒì¼({log_key})ì„ S3ì—ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"

    analysis = analyze_weekly_signals(df, datetime.strptime(ref_date, "%Y-%m-%d"))
    llm_content = generate_llm_commentary(analysis, ref_date)

    title = llm_content.get("title", f"Signalist Weekly ({ref_date})")
    summary = llm_content.get("summary", "")
    stock_comments = llm_content.get("stock_comments", {})

    lines = [f"# {title}", f"_{ref_date} ê¸°ì¤€ ì§€ë‚œ 7ì¼ê°„ì˜ ê¸°ë¡_"]
    if summary: lines.extend(["\n## ğŸ” Analyst's View", summary])

    if "top_stocks" in analysis:
        lines.append("\n## ğŸ“¡ ì´ë²ˆ ì£¼ ë ˆì´ë”ì— ê°€ì¥ ë§ì´ ì¡íŒ ì¢…ëª©")
        lines.append("| ìˆœìœ„ | ì¢…ëª©ëª… | í¬ì°© íšŸìˆ˜ | AI ì½”ë©˜íŠ¸ |")
        lines.append("|:---:|:---|:---:|:---|")
        for i, (name, count) in enumerate(analysis["top_stocks"].items(), 1):
            comment = stock_comments.get(name, "íŠ¹ì´ ìˆ˜ê¸‰ ë°˜ë³µ í¬ì°©.")
            lines.append(f"| {i} | **{name}** | {count}íšŒ | {comment} |")

    lines.append("\n---\n_ë³¸ ë¦¬í¬íŠ¸ëŠ” ê³¼ê±° ë°ì´í„°ì˜ í†µê³„ì´ë©°, ë¯¸ë˜ ìˆ˜ìµì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤._")
    return "\n".join(lines)

def main():
    """ìŠ¤í¬ë¦½íŠ¸ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    ref_date = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    print(f"ğŸ“… ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ (ê¸°ì¤€ì¼: {ref_date})")

    s3 = S3Manager(bucket_name="fincore-output-storage")
    md_content = create_weekly_report_md(ref_date, s3)
    
    out_key = f"iceage/out/weekly/Signalist_Weekly_{ref_date}.md"
    
    # S3Managerì— put_text_contentê°€ ì—†ìœ¼ë¯€ë¡œ boto3 ì§ì ‘ ì‚¬ìš©
    s3_client = boto3.client("s3", region_name="ap-northeast-2")
    s3_client.put_object(
        Bucket="fincore-output-storage",
        Key=out_key,
        Body=md_content.encode('utf-8'),
        ContentType="text/markdown; charset=utf-8"
    )
    print(f"âœ… ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ë° S3 ì—…ë¡œë“œ ì™„ë£Œ: {out_key}")

if __name__ == "__main__":
    main()